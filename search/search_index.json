{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ryan's Documentation","text":"<p>Notes for stuff.</p>"},{"location":"reference/","title":"Reference","text":"<p>Markdown &amp; Latex</p> <p>This project provides CSS files and a template for using Pandoc[^pandoc] to generate standalone HTML files. It supports most features Pandoc Markdown has to offer, and some extras. The default look can be tweaked via CSS variables, and it does not need JavaScript, even for side notes.</p>"},{"location":"reference/#features","title":"Features","text":"<p>A short list of headline features:</p> <p>[^pandoc]:   {-} Pandoc is a \"universal document converter.\" It is particularly good at   generating HTML and \\(\\LaTeX\\) from Markdown.</p> <ul> <li>Code blocks, including:</li> <li>Syntax themes</li> <li>Line numbers and line highlights</li> <li>Extra wide and full-width options</li> <li>Captions</li> <li>Images and tables,   including:</li> <li>Extra wide and full-width options</li> <li>Captions</li> <li>Side notes and margin notes</li> <li>Floating table of contents</li> <li>\\(LaTeX\\) math, rendered via \\(KaTeX\\) in   the browser</li> <li>Dark mode, based on the user's default color scheme preference</li> </ul> <p>For the complete feature set, see the documentation. You might also want to view the \"kitchen sink\" page that is useful when developing, or the source code:</p> <p>\u2192 Documentation\\ \u2192 Kitchen Sink\\ \u2192 Source on GitHub</p> <p>The theme is fully responsive, including phones, tablets, laptops, and wide desktop screens. Side notes and the table of contents display inline on small screen sizes, and in the margins on wide enough screens. Extra wide images, tables, and code blocks shrink when space isn't available. CSS <code>@media print</code> styles declare first-class print styles.</p> <p>:::{.wide .extra-wide .only-light-mode}</p> <p></p> <p>:::</p> <p>:::{.wide .extra-wide .only-dark-mode}</p> <p></p> <p>:::</p> <p>The source code is extremely tweakable.[^tweakable] A small set of CSS variables control a large number of font and color settings: you don't have to hunt down all the places that need to be changed to tweak the design. As a proof of concept, see this page, which tweaks the default theme slightly. These same CSS variables power the light- and dark-mode versions of the theme. Of course, the code is open source and you're welcome to copy the theme files and completely overhaul them if desired.</p> <p>[^tweakable]:   {-} When changing things like the font family or font size, the thing that   matters is to pay special attention to alignment. Different fonts have   different x-heights and widths. Most layouting can be agnostic of these   things, but there are explicit variables for places where it matters.</p> <p>And finally, there's basically only HTML and CSS. The theme doesn't use custom fonts by default, and only uses JavaScript for two things:</p> <ul> <li>Rendering math (via \\(\\KaTeX\\)), only if used.</li> <li>Slightly tweaking the appearance of checklist items. (Pandoc emits them as   disabled, but they look better when enabled in my opinion.) This is entirely   presentational.</li> </ul> <p>Placement of side notes, the table of contents, and code block line highlights are all controlled with CSS. See the credits below for more background on the techniques used.</p>"},{"location":"reference/#usage","title":"Usage","text":"<p>This project merely provides a CSS files and a standalone HTML template to give to Pandoc.  The imporant files that you might want to copy out to start your own project:</p> <ul> <li>[<code>public/css/theme.css</code>], the core CSS implementing theme</li> <li>[<code>template.html5</code>], the Pandoc template that renders Markdown to HTML</li> <li>[<code>Makefile</code>], showcasing the Pandoc flags required to get things to build</li> <li>[<code>src/index.md</code>], the source code for this page</li> </ul> <p>To see things in action, try rebuilding this site locally. First, you'll need a few command line programs:</p> <ul> <li> </li> <li>[ ] [<code>pandoc-sidenote</code>]</li> <li>[ ] <code>realpath</code> from GNU coreutils</li> <li>[ ] (optional) [<code>watchman</code>], for rebuilding when files change</li> </ul> <p>Follow the installation instructions for your platform. If you're using macOS, installation is as easy as:</p> <pre><code>brew install pandoc coreutils\nbrew tap jez/formulae\nbrew install pandoc-sidenote\n</code></pre> <p>Then you can clone this project and run <code>make watch</code>:</p> <pre><code>git clone https://github.com/jez/pandoc-markdown-css-theme\ncd pandoc-markdown-css-theme\n\n# Test everything by forcing a clean build\n# (the generated comes with the clone)\nmake clean\nmake\n\n# If you installed watchman\nmake watch\n</code></pre> <p>Running <code>make</code> will build everything in the site.</p> <p>Running <code>make watch</code> will start a webserver at http://127.0.0.1:8000/, open that URL in a web browser, and watch files for changes in the background.</p>"},{"location":"reference/#usage-with-jekyll","title":"Usage with Jekyll","text":"<p>While the core theme is just a handful of static files that can be copied into any project, using this theme with Jekyll is as easy as installing a theme:</p> <p>\u2192 [Pandoc Markdown Jekyll Theme][<code>pandoc-markdown-jekyll-theme</code>]</p> <p>Check the project above for installation and usage instructions with Jekyll.</p>"},{"location":"reference/#credits","title":"Credits","text":"<p>First, thanks to Pandoc, by John MacFarlane, for being an all-around awesome tool, especially for Markdown.</p> <p>The core technique for laying out side notes[^gwern] I learned from Tufte CSS, by Dave Liepmann. The technique is described in detail here. Tufte CSS suggests writing the HTML for sidenotes by hand, but I wanted to use Markdown. I wrote [<code>pandoc-sidenote</code>], a Pandoc filter that traverses Pandoc's internal AST and converts footnote nodes into the HTML side note markup for Tufte CSS-style side notes.</p> <p>[^gwern]:   {-} Gwern has a great survey post that discusses Sidenotes In Web Design,   covering the techniques in Tufte CSS as well as the limitations, and many   alternatives.</p> <p>While the idea for side notes comes entirely from Tufte CSS, the implementation at this point is almost completely different. Tufte CSS uses relative widths everywhere, but I wanted a body with a constant width at all but the smallest screen sizes. Tufte CSS renders the main body off center. Rendering centered when possible and off center when not adds complexity in the implementation.</p> <p>The inspiration for code block line highlights comes from a change I contributed to [<code>pandoc-emphasize-code</code>], by Oskar Wickstr\u00f6m (another Pandoc filter). I decided against using it for this project because it forces a choice of either line highlights or syntax highlighting per code block (unless you tack on a JavaScript-based syntax highlighter, like Highlight.js). I thought of a clever technique using CSS clases to avoid this.</p> <p>Considerable design inspiration comes from Dropbox Paper, a gorgeous and powerful tool. (In fact, the theme is customizable enough to recreate the look of Paper. This is provided for educational purposes only, under Fair Use.)</p>"},{"location":"reference/#see-also","title":"See also","text":"<p>If you'd like to use Tufte CSS with Pandoc in your own project, feel free to use my Tufte Pandoc CSS project.</p> <p>If you'd like to use this theme in a Jekyll project, I have already packaged these files as a Jekyll theme: [<code>pandoc-markdown-jekyll-theme</code>].</p> <p> \u2191 Back to the top </p>"},{"location":"214/","title":"Topics","text":"<ul> <li>Algebraic Tricks</li> <li>Sequences</li> <li>Sequences and Limits</li> </ul>"},{"location":"214/algebraicTricks/","title":"Algebraic Tricks","text":""},{"location":"214/algebraicTricks/#find-limit-of-an-equation-without-a-denominator","title":"Find limit of an equation without a denominator","text":"<p>Some of the equations that we need to find limits for can be difficult to determine if there is no denominator since we can't easily apply some of our existing tricks. We can use an equivalence to reinterpret the equation so we can work with it.</p> \\[ \\begin{align*}      a - b = \\frac{a^2-b^2}{a+b} &amp;&amp; \\text{the basic identity} \\\\     \\lim_{n \\to \\infty} \\sqrt{n^2 + 5n} - \\sqrt{n^2 -5n} \\\\      a = \\sqrt{n^2 + 5n} \\\\      b = \\sqrt{n^2 - 5n} \\\\      \\lim\\_{n \\to \\infty} \\frac{0}{\\sqrt{n^2 + 5n} - \\sqrt{n^2 - 5n}} &amp;&amp; \\text{after applying identity}  \\end{align*} \\]"},{"location":"214/algebraicTricks/#factor-out-dominant-terms","title":"Factor out dominant terms","text":"<p>To find the limit of: $$ \\lim_{n \\to \\infty}\\frac{\\ln{2n}}{\\ln{5n}} $$</p> <p>We can use rules about logarithms to rewrite it as a sum of the logs products.</p> \\[ \\frac{\\ln{2} + ln{n}}{\\ln{5} + \\ln{n}} \\] <p>From there we can factor out the dominant term \\(\\ln{n} \\)</p> \\[ \\frac{\\ln{n}(\\frac{\\ln{2}}{\\ln{n}} + 1)}{\\ln{n}(\\frac{\\ln{5}}{\\ln{n}} + 1)} \\] <p>Now it's easier to see what happens as n approaches infinity. </p>"},{"location":"214/limits/","title":"Limits","text":"\\[ \\lim\\limits_{n \\to \\infty} \\frac{n+1}{n} = 1 \\] \\[ \\lim\\limits_{n \\to \\infty} (1 + \\frac{x}{n})^n = e^x \\]"},{"location":"214/power_series/","title":"Power Series","text":""},{"location":"214/power_series/#what-they-is","title":"What they is...","text":"<p>The first thing that separates power series from what we have seen with  sequences and series is the presence of a new variable \\(x\\) (or something like it). A power series has the general form of:</p> \\[ \\begin{align*} \\sum_{n=0}^\\infty a_n (x-c)^n = a_1 + a_2 (x-c)^1 + a_2 (x-c)^2 + ... + a_n (x-c)^n + ... \\end{align*} \\] <p>We say that the above is a power series in \\(x\\) centered at \\(c\\). </p> <p>The presence of \\(x\\) here is what makes a power series a function and you can see that is has this sort of neverending polynomial format as $ n \\to \\infty $.</p> <p>When we discuss convegence of power series we will find that the series may only converge for certain values of x and for other values the series would diverge. </p>"},{"location":"214/power_series/#interval-of-convergence","title":"Interval of Convergence","text":"<p>This defines the values of x for which the power series will converge. The  bounds themselves need a convergence test to indicate if they will converge,  but all points in between will converge for the given interval.</p>"},{"location":"214/power_series/#radius-of-convergence","title":"Radius of Convergence","text":"<p>The radius defines the bound within which the power series will converge:  $ | x-a | &lt; R $</p>"},{"location":"214/sequence_limits/","title":"Limits","text":"<p>In the past we have considered limits for functions as the input approaches some finite or infinite value. Does the limit exist? If it does, what is the value?</p> <p>The exploration of the limit gives us information about where the terms of the sequence are tending towards. Do they move towards the same value? Or do they not move towards the same value?</p> <p>Sequences that move towards a limit demonstrate convergence, and those that do not are divergent.</p>"},{"location":"214/sequence_limits/#strategies","title":"Strategies","text":""},{"location":"214/sequences/","title":"Sequences","text":"<p>Sequences are ordered lists of numbers that may be finite or infinite. When we study Series, they are the sums of the terms of the sequence.</p> <p>A sequence may be described as a function that maps natural numbers to the real number system.</p> \\[ \\begin{align*}     f: \\mathbb{N} \\to \\mathbb{R} \\quad &amp; \\text{leads to} \\\\     a_n = f(n)&amp; \\end{align*} \\] <p>The sequence may start at any integer.</p> \\[  \\begin{align*}     \\{{2n}\\}^\\infty_{n=-3} = a_{-3},a_{-2}, ... = \\\\     -6, -4, -2, ... \\end{align*} \\]"},{"location":"214/sequences/#properties","title":"Properties","text":""},{"location":"214/sequences/#increasing-or-decreasing","title":"Increasing or Decreasing","text":"<p>Will a sequence continually rise in value as you go to the next term, or will it get lower? We can examine the relative adjacent terms to try to discover whether a sequence is \"increasing\" or \"decreasing\". We can also perform a first derivative test and and examine the values there to see if they are +'ve or -'ve. </p> <p>An increasing sequence should have terms such that:</p> \\[a_n &lt; a_{n+1} \\] <p>A decreasing sequence should have terms such that:</p> \\[a_n &gt; a_{n+1} \\]"},{"location":"214/sequences/#strategies","title":"Strategies","text":"<p>Use the first derivative test to inspect where the function is decreasing/increasing.</p> <p>Compare the nth term to the n+1th term. </p> <p>Compare the ratio of the n+1th term to the nth term which follows from. The setup below is for a decreasing examination. $$ a_n \\ge a_{n+1} \\ a_{n+1} \\le a_n \\ \\frac{a_{n+1}}{a_n} \\ge 1 $$</p>"},{"location":"214/sequences/#monotonocity","title":"Monotonocity","text":"<p>A function will be monotonic if it has the property of entirely increasing or decreasing for all elements in the domain.</p>"},{"location":"214/sequences/#bounding","title":"Bounding","text":"<p>A sequence may never surpass a certain value, or it may never be lower than a certain value, or it may be contained between two numbers. If any of those are true, then the sequence may be \"bounded above\", \"bounded below\", \"bounded between\", or \"not bounded\". </p> \\[ \\begin{align*}     If a_n \\leq M  \\quad &amp;\\textbf{Bounded Above}. \\\\     If a_n \\geq m  \\quad &amp;\\textbf{Bounded Below}. \\\\     If m \\leq a_n \\leq M  \\quad &amp;\\textbf{Bounded}. \\\\ \\end{align*} \\]"},{"location":"214/sequences/#limit","title":"Limit","text":""},{"location":"214/sequences/#convergence","title":"Convergence","text":"<p>The property of convergence relates to a sequence as it tends to infinity and whether the value of \\(a_n\\) seems to go to a certain stable value. If that is  not the case, then the sequence diverges. </p>"},{"location":"214/series/","title":"Series","text":""},{"location":"214/series/#what-they-is","title":"What they is...","text":"<p>The concept of a series is tightly coupled to sequences. They are simply the summation of all of the terms of sequence.</p> \\[ \\begin{align*} a_n = \\{n\\} &amp;&amp; \\text{a sequence} \\\\ \\sum_{n=1}^\\infty a_n &amp;&amp; \\text{a series} \\end{align*} \\]"},{"location":"214/series/#properties","title":"Properties","text":""},{"location":"214/series/#convergence","title":"Convergence","text":"<p>The idea of convergence foxr a series is different notion than convergence with a sequence. The idea is best examined through the idea of partial sums. If a series is the sum of all of the sequence terms, then a partial sum is the sum of the first N terms $ S_N $. We can begin with the first partial sum, the second partial sum, the third partial sum, and we can take that to the limit of infinity. </p> \\[ \\begin{align} &amp;S = \\sum_{n=1}^\\infty a_n &amp;&amp; \\\\ &amp;S_n = \\sum_{n=1}^N a_n &amp;&amp; \\\\ &amp;\\{ S_n \\}^\\infty_{N=1} &amp;&amp; \\\\ &amp;S = L = \\lim_{n \\to \\infty} S_n \\end{align} \\] <ol> <li>a series</li> <li>a partial sum. The sum of the first N terms of $ { a_n }$</li> <li>a sequence of partial sums where each $ S_n $ is the sum of the first  n terms of the original sequence $ { a_n }$</li> <li>the sum is the limit from n to $ \\infty $ of the sequence of partial  sums $ { S_n } $. In #2,     $ S_n $ is a partial sum, but when written  here, we are referring to the previous sentences understanding. </li> </ol> <p>Imagine that we have pebbles and that we add them one by one to a scale and  record the weight as we add each one (the $ S_N $ value). If as we record the  weight it settles to a number, then we say that the series converges.  (analogy idea from ChatGPT)</p>"},{"location":"214/series/#absolute-convergence","title":"Absolute Convergence","text":"<p>A series that is the sum of all of the absolute terms of its sequence  ( $ \\sum | a_n | $ ), and is convergent, is so called absolutely  convergent.</p> <p>If a series is absolutely convergent, then it is also convergent. </p>"},{"location":"214/series/#conditional-convergence","title":"Conditional Convergence","text":"<p>If the series is convergent, but the absolute series is not, then it is called  conditionally convergent. </p>"},{"location":"214/series/#tests","title":"Tests","text":""},{"location":"214/series/#divergency-test","title":"Divergency Test","text":"<p>It is impossible for a series to converge if the sequence of the terms does not approach 0. For example, if it approaches 1, then every term we continue to add in the series will continue to increase and the limit of the series won't  settle down. </p> \\[ \\lim\\limits_{n \\to \\infty} a_n \\neq 0 \\rightarrow \\sum a_n \\text{ will diverge} \\] <p>The ratio test, root test, integral test could be used as well to show divergence. </p>"},{"location":"214/series/#application","title":"Application","text":"<p>Take the limit of the sequence. </p>"},{"location":"214/series/#integral-test","title":"Integral Test","text":"<p>Show decreasing.</p>"},{"location":"214/series/#comparison-test","title":"Comparison Test","text":"<p>What's bigger than it. </p>"},{"location":"214/series/#limit-comparison-test","title":"Limit Comparison Test","text":"<p>Show decreasing.</p>"},{"location":"214/series/#alternating-series-test","title":"Alternating Series Test","text":""},{"location":"214/series/#ratio-test","title":"Ratio Test","text":"<p>Tend to be used when we see factorials or things to the power of n  Shows absolute convegence.</p>"},{"location":"214/series/#root-test","title":"Root Test","text":"<p>Shows absolute convegence.</p>"},{"location":"214/series/#general-test-strategy","title":"General Test Strategy","text":""},{"location":"214/series/#check-for-divergence","title":"Check for divergence","text":"<p>For a series to converge, the terms of the sequence must approach zero;  otherwise, the series will continue to grow and will be divergent. To check for this we will take the limit of the sequence and see if it is zero. If it is, then it's possible that the series may converge, if it does not equal zero then the series definietely diverges. </p>"},{"location":"214/series/#check-for-type-of-series","title":"Check for type of series","text":""},{"location":"214/series/#harmonic-series","title":"Harmonic series","text":"<p>We know harmonic series are divergent.</p>"},{"location":"214/series/#hyperharmonic-p-series","title":"Hyperharmonic (p-series)","text":"<p>We know hyperharmonic or p-series are convergent.</p>"},{"location":"214/series/#geometric-series","title":"Geometric series","text":"<p>Geometric series will converge under special conditions. A geometric series \\(\\sum_{n=0}^{\\infty} ar^n\\) will:</p> <ul> <li> <p>Converge if the common ratio, \\(|r| &lt; 1\\). The sum of the series in this case is given by:</p> <ul> <li>\\( S = \\frac{a}{1 - r} \\) where \\(S\\) is the sum of the series, \\(a\\) is  the first term, and \\(r\\) is the common ratio.</li> </ul> </li> <li> <p>Diverge if the common ratio, \\(|r| \\geq 1\\). This includes:</p> <ul> <li>\\(r = 1\\), where the series becomes \\(\\sum_{n=0}^{\\infty} a\\) which clearly diverges as it sums to infinity.</li> <li>\\(r &gt; 1\\) or \\(r \\leq -1\\), where the terms of the series grow without bound in absolute value.</li> </ul> </li> </ul>"},{"location":"214/series/#telescoping-series","title":"Telescoping series","text":""},{"location":"214/series/#descending-and-positive","title":"Descending and positive","text":""},{"location":"214/series/#evaluate-limit-of-ratio-or-root","title":"Evaluate limit of ratio or root","text":""},{"location":"214/series/#rational-function","title":"Rational function","text":""},{"location":"214/series/#alternating-series","title":"Alternating series","text":""},{"location":"214/series/#remember-the-comparison-test","title":"Remember the comparison test","text":""},{"location":"214/series_special/","title":"Special Series","text":""},{"location":"214/series_special/#geometric-series","title":"Geometric Series","text":"<p>A geometric series is the summation of increasingly diminishing terms. $ a $ is the first term of the sequence, and $ r $ is the common ratio of the series.</p> \\[ S = \\sum_{n=1}^{\\infty} ar^{n-1} = a + ar + ar^2 + ar^3 + ... \\] <p>The sum of a convergent geometric series is:</p> \\[ S = a_1 \\cdot \\frac{1 - q^n}{1 -  q} \\] <p></p>"},{"location":"214/series_special/#harmonic-series","title":"Harmonic Series","text":"<p>The harmonic series has the form of: $$ \\sum_{n=1}^{\\infty} \\frac{1}{n} $$ A harmonic series does not converge. </p>"},{"location":"214/series_special/#hyperharmonic-p-series","title":"Hyperharmonic (p-series)","text":"<p>The hyperharmonic or p-series has the form of $$ \\sum_{n=1}^{\\infty} \\frac{1}{n^p} $$ If $ p &gt; 1 $ then the series will converge. We say that a series converges by the p-test. </p>"},{"location":"214/series_special/#telescoping-series","title":"Telescoping Series","text":""},{"location":"333/Block%20Chain/merkleTree/","title":"Merkle Tree","text":"<p>A merkle tree is a binary tree where the root node of the tree is a hash that represents block chain transactions that are stored as the leaf nodes.</p> <p>A block may contain thousands of transactions and it would be very inefficient to store all of the hashes of each transaction. Instead a single transaction is stored with the block and it is computed from the concatenation of hashes from the leaf nodes of the tree that contain the transactions.</p> <p></p> <p>Note</p> <p>We can determine if a transaction is a member of a block by checking a few things. First we need several pieces of information to do this: we need  all of the off-path hashes. These are in bold red in the graphic. With the off path hashes we can compute the root hash and compare against the known root hash. </p>"},{"location":"333/Block%20Chain/proofOfWork/","title":"Proof of Work","text":"<p>Proof of work can be used to slow down the rate at which connections can be  made by requiring clients to do some sort of intensive computational task. It should not be so slow that a user would really notice, but that it would  hinder an attacker from attacking in bulk. </p>"},{"location":"333/Block%20Chain/proofOfWork/#hash-based-proof-of-work","title":"Hash Based Proof of Work","text":"<p>A simple proof of work would be to find some input $ x $ that when hashed produces 64 bits, and the 12 most significant bits are all 0s. Someone could presumably store all the outputs for future reuse, so...</p> <p>Another one would be to do something similar but hash the concentation of  some message, $ m $, and an input $ H(m||x) $. Now the attacker couldn't use pre-stored results when the message is changed on every request. </p>"},{"location":"333/Block%20Chain/proofOfWork/#relation-to-bitcoin","title":"Relation to Bitcoin","text":"<p>Miners must produce an acceptable hash based on several different factors  including a growing difficulty factor. </p>"},{"location":"333/Encryption/","title":"Encryption","text":"<p>Encryption covers many sub topics such as ciphers, key generation and  management, and secure data transmission protocol. </p> <pre><code>graph TD\n    A[Encryption] --&gt; B[Cipher]\n    B --&gt;|Type| C[Symmetric-key Cipher]\n    B --&gt;|Type| D[Asymmetric-key Cipher]\n    C --&gt;|Example| E[AES, DES]\n    D --&gt;|Example| F[RSA, ECC]\n    D --&gt;|Subtype| G[Public Key Encryption]\n    G --&gt;|Example| J[PGP, SSL/TLS]\n    A --&gt; H[Key Generation and Management]\n    H --&gt;|Methods| I[Random Number Generation&lt;/br&gt; Key Exchange Algorithms]\n    H --&gt;|Practices| K[Key Rotation&lt;/br&gt;Key Storage Security]\n    A --&gt; L[Secure Data Transmission Protocol]\n    L --&gt;|Examples| M[HTTPS, SSH, VPN]\n    L --&gt;|Features| N[Handshake Protocols&lt;/br&gt;End-to-End Encryption]\n</code></pre>"},{"location":"333/Encryption/ciphers/","title":"Ciphers","text":""},{"location":"333/Encryption/ciphers/#what-are-those-things","title":"What are those things?","text":"<p>Ciphers are pairs of algorithms that take some kind of message and create a confidential message. A plaintext message and a key are given to an  encryption function and ciphertext is produced from it. Ciphertext and a key are given to the decryption function and the plaintext is recovered.</p> <p>Ciphers help prevent eavesdropping. </p> <p>Common generic notation for ciphers is noted below. </p> \\[ \\begin{align*} c = E_k(m) &amp;&amp; \\text{Encrypt function takes plaintext and key}\\\\  m = D_{k'}(c) &amp;&amp; \\text{Decrypt function takes ciphertext and key} \\end{align*} \\]"},{"location":"333/Encryption/ciphers/#disambiguation","title":"Disambiguation","text":""},{"location":"333/Encryption/ciphers/#stream-cipher-vs-block-cipher","title":"Stream Cipher vs Block Cipher","text":"<p>Stream ciphers and block ciphers differ in the amount of key and plaintext that are handled at any given time. A block tends to work with a fixed-length chunk  of bits. A stream will handle bits one at a time with the key a bit at a time.</p> <p>A weakness in a naively designed block cipher algorithms is when an attacker  can see blocks that have been duplicatly encoded which reveals more information than we want to the attacker. A stream cipher wouldn't necessarily have the  same problem because the symmetric key is turned into a arbitrary-length secret cipher stream.</p> <p>The block cipher will also have to be padded if it isn't the correct length.</p>"},{"location":"333/Encryption/ciphers/#symmetric-encryption-vs-asymmetric-ecryption","title":"Symmetric Encryption vs Asymmetric Ecryption","text":"<p>In symmetric encryption, the parties share the same key. </p> <p>In asymmetric encryption, the parties each have a key pair. They have an encryption public key, and a decryption private key.</p>"},{"location":"333/Encryption/ciphers/#cipher-types","title":"Cipher Types","text":""},{"location":"333/Encryption/ciphers/#vernam-cipher-stream","title":"Vernam Cipher (stream)","text":"<p>The vernam cipher has four streams. It begins with a message stream and a key stream that are xor'd together to form the cipher stream. Then the cipher  stream is again xor'd with the key stream to recover the output stream which should be the same as the original input message. </p>"},{"location":"333/Encryption/ciphers/#electronic-cookbook-block","title":"Electronic Cookbook (block)","text":"<p>This is the simplist of the block cipher approaches, and we've seen this in use by AES where it has it as a mode. </p> <p>Each block and key are given to the encryption function to generate a  ciphertext block and then that block and the key are given to the decryption function to recover the original block.</p> <p>One of the benefits of this approach is that even if one of the blocks is lost we can still recover most of the message. When we look at the other chaining  methods, we see they are not so lucky.</p> \\[ \\begin{align*} c_i &amp;= E_k(m_i) &amp; m_i &amp;= D_k(c_i) \\end{align*} \\]"},{"location":"333/Encryption/ciphers/#cipher-block-chaining-block","title":"Cipher Block Chaining (block)","text":"<p>The chaining part of the name indicates that the input and output are  connected in some way. </p> <p>For Cipiher Block Chaining, the original message is XOR'd with the previous cipher text block or the initialization vector if it's the first block, and  then the XOR'd block is passed into the encryption function.</p> <p>In the opposite fashion, the cipher text block is passed to the decryption  function and that output must be XOR'd with the previous cipher text block to then recover the original plain text.</p> <p>Because the ciphertext is used during decryption it will affect the current  block and the next block.</p> \\[ \\begin{align*} c_i &amp;= E_k(m_i \\oplus c_{i-1}) &amp; m_i &amp;= D_k(c_i) \\oplus c_{i-1} \\end{align*} \\] <p>Note</p> <p>Needs an Initialization Vector to start. </p>"},{"location":"333/Encryption/ciphers/#output-feedback-block","title":"Output Feedback (block)","text":"<p>For Output Feedback, the output of the encryption function  can be precomputed ahead of time. For Output Feedback these outputs are passed  to the next encryption block before being XORd with the plaintext to produce  the ciphertext.</p> \\[ \\begin{align*} c_i &amp;= m_i \\oplus E_k^{i}(\\text{IV}) &amp; m_i &amp;= c_i \\oplus E_k^{i}(\\text{IV}) \\end{align*} \\] <p>Note</p> <p>Initialization vector is required.</p>"},{"location":"333/Encryption/ciphers/#cipher-feedback-block","title":"Cipher Feedback (block)","text":"<p>For Cipher Feedback these outputs are first XORd with the plaintext message to produce the cipher text and then also used as input to the next encryption call</p> \\[ \\begin{align*} c_i &amp;= m_i \\oplus E_k(c_{i-1}) &amp; m_i &amp;= c_i \\oplus E_k(c_{i-1}) \\end{align*} \\] <p>Note</p> <p>Initialization vector is required.</p>"},{"location":"333/Encryption/ciphers/#counter-mode","title":"Counter Mode","text":""},{"location":"333/Encryption/ciphers/#non-repudiation","title":"Non-repudiation","text":""},{"location":"333/Encryption/ciphers/#a-look-at-the-function-space","title":"A Look at the Function Space","text":"<p> In the simple example above, we want to encode 2 bits. We see that the two bits can have 4 different permutations \\( 2^\\text{message length}\\). As we map from the 4 inputs to the 4 outputs, there are \\(perm!\\) possible functions. To  create a key that can map to all of those functions we would need \\( log_2(perm!) \\) bits.  When we map this information into the space we see two subsets that exist. One is the subset of weak keys that would be easily crackable like an identify function, or the caeser shift function. If the functions encoded by our key intersect with that set then we have some risky keys in our system that an attacker could use. We should enhance our design to remove this risk in some way. </p>"},{"location":"333/Encryption/definitions/","title":"Definitions","text":""},{"location":"333/Encryption/definitions/#non-repudiation","title":"Non-repudiation","text":""},{"location":"333/Encryption/designPrinciples/","title":"Design Principles","text":""},{"location":"333/Encryption/designPrinciples/#access-control-and-privilege-management","title":"Access Control and Privilege Management","text":""},{"location":"333/Encryption/designPrinciples/#complete-mediation","title":"Complete-Mediation","text":"<p>Whenever we are accessing objects we should verify that the proper authority to do so exists. When we verify the authority we will need to authenticate an identity to make sure they are who they say they are and then check their authorization before granting access, and finally ensuring that the request has not been tampered with. </p>"},{"location":"333/Encryption/designPrinciples/#independent-confirmation","title":"Independent-Confirmation","text":"<p>Find a way to independently confirm the integrity of recieved information.  Hashing is commonly used to verify file contents are what they are supposed to be. Though you would need to trust that the listed hash hasn't been tampered with. </p>"},{"location":"333/Encryption/designPrinciples/#least-privilege","title":"Least-Privilege","text":"<p>Give as little access as possible. Only what is required to carry out the users tasks.</p>"},{"location":"333/Encryption/designPrinciples/#safe-defaults","title":"Safe-Defaults","text":"<p>Create good, safe default settings, so that when things fail - they fail in a way that leaves the system in a secure state. </p>"},{"location":"333/Encryption/designPrinciples/#trust-anchor-justification","title":"Trust-Anchor-Justification","text":"<p>Justify why you are trusting anchors of trust like a certificate authority.  They represent the foundation of what you are building on and you should be confident that they can be trusted.</p>"},{"location":"333/Encryption/designPrinciples/#verify-first","title":"Verify-First","text":"<p>Make sure they are who they say they are before you do anything.</p>"},{"location":"333/Encryption/designPrinciples/#user-interaction-and-expectations","title":"User Interaction and Expectations","text":""},{"location":"333/Encryption/designPrinciples/#least-surprise","title":"Least-Surprise","text":"<p>Design your user interactions in line with what the user might expect. You want to avoid building a system that relies on experts where ordinary users might make a mistake using it. </p>"},{"location":"333/Encryption/designPrinciples/#user-buy-in","title":"User-Buy-In","text":"<p>Build something the user will want to use. We want to encourage them to use it, so that they don't try to bypass it.</p>"},{"location":"333/Encryption/designPrinciples/#system-design","title":"System Design","text":""},{"location":"333/Encryption/designPrinciples/#design-for-evolution","title":"Design-For-Evolution","text":"<p>Build a system that can grow with new crypto algorithms for encyryption or hashing. Build in automated updates to ensure that deployments maintain  alignment with new releases and fixes. </p>"},{"location":"333/Encryption/designPrinciples/#isolated-compartments","title":"Isolated-Compartments","text":"<p>Similar to modular design, we design the product such that the components are as isolated as possible to reduce any failure in one of them from causing failures in the other components. </p>"},{"location":"333/Encryption/designPrinciples/#modular-design","title":"Modular-Design","text":"<p>Build modular systems where access is distributed across it and avoid  consolidating access into large singular monolithic applications where a breach would give full access.</p>"},{"location":"333/Encryption/designPrinciples/#open-design","title":"Open-Design","text":"<p>Systems that have some openness to them mean that vulrabilities can be  identified sooner, and that we don't overly rely on our own secret scheming to protect us. We have robust code that has been socially reviewed and evolved.</p> <p>Pairs with Time Tested Tools</p>"},{"location":"333/Encryption/designPrinciples/#security-by-design","title":"Security-By-Design","text":"<p>Think about security from the beginning so that you're not playing catch up later on.</p>"},{"location":"333/Encryption/designPrinciples/#simplicity-and-necessity","title":"Simplicity-and-Necessity","text":"<p>Keep it simple stupid. Reducing complexity helps minimize attack surface. This often conflicts with the desire to build big large piece of software. </p>"},{"location":"333/Encryption/designPrinciples/#small-trusted-bases","title":"Small-Trusted-Bases","text":"<p>Avoid depending on complex larger codebases. A smaller size will be easier to  analyze for security and ensure that you aren't majorly open to attack.</p> <p>We could think of the bases here as support areas that your application  interacts with, and if they are overly large and complicated it will be  difficult to decide they are safe to interact with.</p>"},{"location":"333/Encryption/designPrinciples/#time-tested-tools","title":"Time-Tested-Tools","text":"<p>Use tools that you and the community at large trust. They have been vetted better than newer, cutting edge tech that may have overlooked design flaws.</p>"},{"location":"333/Encryption/designPrinciples/#defense-design","title":"Defense Design","text":""},{"location":"333/Encryption/designPrinciples/#defense-in-depth","title":"Defense-In-Depth","text":"<p>We want to avoid single points of failure, and try to by providing defense in multiple layers as back up. Any one piece that is weak should be improved since attackers will target the weakest link. </p> <p>Layers provide backup for human errors in design, or some defenses that were  more easy to bypass than expected. </p>"},{"location":"333/Encryption/designPrinciples/#datatype-validation","title":"Datatype-Validation","text":"<p>Be sure that you're receiving what you expect to receiving and check for that to be true.</p> <p>Watch out for code injection or command injection attacks. </p>"},{"location":"333/Encryption/designPrinciples/#evidence-production","title":"Evidence-Production","text":"<p>Leave a bread crumb trail. The more data that you have, the better you can  analyze an attack and repair the problem.</p>"},{"location":"333/Encryption/designPrinciples/#relucant-allocation","title":"Relucant-Allocation","text":"<p>Be cautious to allow full access to any visitor. This is often about preventing denial of service attacks that would occur if unmitigated access is allowed. </p>"},{"location":"333/Encryption/designPrinciples/#remnant-removal","title":"Remnant-Removal","text":"<p>Clean up your garbage in case you kept any secrets in there. </p>"},{"location":"333/Encryption/designPrinciples/#request-response-integrity","title":"Request-Response-Integrity","text":"<p>When something has been requested, make sure that the response matches what is expected to have arrived based on the request. Designs should ensure that  transactions or protocols have integrity checks built in so the contents of any part of the chain of communication is in question.</p>"},{"location":"333/Encryption/designPrinciples/#sufficient-work-factor","title":"Sufficient-Work-Factor","text":"<p>There may be parts of your system that you want the user to do a certain amount of work before allowing them access. This prevents a bad actor from trying to brute force their way into the system through that access point.</p>"},{"location":"333/Encryption/hashing/","title":"Hashing","text":"<p>We use hashing to produce some fixed size output of some length we chose.  Hashes are meant to be easy to compute since we need them all the time. Their computation time is proportional to the input to the hash function.</p> <p>Hashing can be used as a checksum where the $ H(f) = c $ is passed along with the message and the client can check on their end if $ H(f') = c $ (for some  arbitrary file f).</p>"},{"location":"333/Encryption/hashing/#properties","title":"Properties","text":""},{"location":"333/Encryption/hashing/#one-way-property-preimage-resistance","title":"One-way property (preimage resistance)","text":"<p>It's really really really hard to find the message from the hash.  $$ \\text{Very hard to find a function f such that:} \\quad f(h)= m $$</p>"},{"location":"333/Encryption/hashing/#second-preimage-resistance","title":"Second preimage resistance","text":"<p>If I have some message, its very hard to find another message so that their hashes are equal.  $$ h(m) = h(m') $$</p>"},{"location":"333/Encryption/hashing/#collision-resistance","title":"Collision resistance","text":"<p>Two hashes may result from two different messages, but it is very very very  hard to find any two that do.  $$ H(m_1) = H(m_2) \\quad \\text{is very hard to find} $$</p> <p>Modern hashing techniques are still bound by the pigeonhole principle. We have an infinite number of messages that are bound to some expression of a hash. For example, we have a hash that outputs a 512 bit hash. We have $ 2^{512} $  possible messages that we can encode, which is a lot, but there are more than  $ 2^{512} $ message in existence and some of them will have to map to the same  hash. </p>"},{"location":"333/Encryption/hashing/#basic-login-with-a-hash","title":"Basic login with a hash","text":"<pre><code>                        # without salt\ncheckpass(u):           # u: username\n    pc = getString()    # get password\n    h = lookup(pc)      # get stored hash\n    hc = H(pc)          # get the hash of the provided password\n    return hc == h\n\n                        # with salt\ncheckpass(u):           # u: username\n    pc = getString()    # get password\n    h, s = lookup(pc)   # get stored salt, hash\n    hc = cat(s, H(pc))  # get the hash of the provided password, concat w/ salt\n    return hc == h\n</code></pre> <p>The hash must have strong preimage resistance so that if an attacker were to  gain access to a hash they would not be able to derive the password.</p>"},{"location":"333/Encryption/hashing/#hashing-in-signatures","title":"Hashing in Signatures","text":"<p>Collision resistance is essential when hashing is used to produce a tag for signing. If this property fails, then more than one person could be a valid sender for a signed file which would mean non-repudiation could not be  guaranteed. </p>"},{"location":"333/Encryption/hashing/#salt","title":"Salt","text":"<p>Salts are added to hashes to increase their complexity. This makes a brute force attack that much less likely to succeed. The user themselves don't need to know the salt, and it can be stored at the host side (wouldn't be effective anymore if it was leaked). </p> <p>The salts are stored as plaintext in the server database, and their function is  to make it more difficult to guess the passwords by basically make them more  complex. </p>"},{"location":"333/Encryption/hashing/#pepper","title":"Pepper","text":"<p>Pepper is a version of salt that is not stored. Instead it is generated from  $ 0 \\quad \\text{to} \\quad 2^q-1 $, (assuming q bits for the pepper) and the  host tries out values until it finds the shared hash. It's almost like brute forcing on the host side, and is mostly intended as an exercise to slow down the attacker and introduce further complexity to the hash. </p>"},{"location":"333/Encryption/hashing/#lamport-hashes","title":"Lamport Hashes","text":"<p>Lamport hashes are used for one-time passwords. More info &gt;</p>"},{"location":"333/Encryption/password/","title":"Password","text":"<p>Authenticating is about trying to prove who you are. This is typically  accomplished by relying on something that the user owns or something that the user knows. Commonly what the user knows is a password. </p> <p>There are some problems with passwords. They are susceptible to eavesdropping  where an attacker may be able to learn them, and the are subject to replay where the attacker may be able to continually access the system after the password has become known. Changing passwords frequently can help minimize this threat (although that doesn't minimize the amount of damage if a breach  occurs).</p>"},{"location":"333/Encryption/password/#one-time-passwords","title":"One-Time Passwords","text":"<p>These passwords may be produced ahead of time and given to the user so that they can authenticate into the system. This may look like the host generating a list of passwords, printing them out, and the user going through the list one by one. The host removing the password from the system as it is used.</p>"},{"location":"333/Encryption/password/#lamport-hashing","title":"Lamport Hashing","text":"<p>The system will precompute a series of hashes as one-time passwords based on a users provided password. </p> \\[ \\begin{align*} h_1 = H(p), h_2 = H(h_1), h_3 = H(h_2), h_4 = H(h_3), ..., h_k = H(h_{k-1}) \\\\ \\text{collection of tuples} &lt;k-1, h_{k-1}&gt;, &lt;k-2, h_{k-2}&gt;, ..., &lt;3, h_3&gt;, &lt;2, h_2&gt;, &lt;1, h_1&gt; \\end{align*} \\] <p>This list is then provided to the user in reverse order. As the user provides them to the host they are removed from the system. The user is not given  \\( &lt;k, h_k&gt; \\), it is stored on the host and when the user sends  \\( &lt;k-1, h_{k-1}&gt; \\) the host will hash it to then compare against \\( h_k \\).  When it matches, the host will then store the hash that the user sent and  decrement its counter.</p>"},{"location":"333/Encryption/random/","title":"Random","text":"<p>To generate keys, salts, and other cryptographic features we often need access to randomness to be able to create them in a non-deterministic way. To do so, we need cryptographically secure pseudo random number generators. </p> <pre><code>                # pseudo random generator (not secure)\nS = g(seed)     # get a seed\n(U, S') = f(S)  # random number function generates num U and new seed state S'\nS = S'          # seed is updated to new state\nreturn U        # return random value\n</code></pre> <p>The problem with the above code is that the seeds will cycle. At some point there is some \\(S' == S_0 \\), and then the sequence will cycle. Give the best performane of the f function, you would see a cycle after \\( 2^{seed bits}\\).</p> <p>To break this cycle we need to introduce a source of true randomness. Often we may need to combine several sources to create a random pool that we can draw from. We can gather them from some proprietary random-purpose hardware device, from the mouse, the keyboard, or from disk i/o and trying to gather noisy data from those sources. </p>"},{"location":"333/Encryption/random/#extra-random-numbers-hash-chaining","title":"Extra random numbers (hash chaining)","text":"<p>The pool of random numbers can be exhausted and one of the ways to extend it is to hash previously produced values. Since the hash produces a fixed size output we can feed it a smaller input to extend our random bits. </p>"},{"location":"333/Encryption/securityConcepts/","title":"Security Concepts","text":"<p>The acronym CIA stands for confidentiality, integrity, and  availability. </p> <p>Note</p> <p>Messages may be data, code and the whole computation device as a whole.</p> <p>Confidential: we only want the people that we want to to be able to read our messages. May apply to things that are at rest like storage, or things that are in motion like network traffic. We are concerned with the ability authenticate and have the user be someone we can trust, the ability to authorize and grant them only the necessary privileges, and to create privacy so that outside  actors can't eavesdrop on communication.</p> <p>Integrity: we want to insure that our messages haven't been tampered with. We use things like cryptographic checksums to help ensure that the contents of  files are what we expect them to be. We want messages to be correct and know that they are from a certain source. We want to know our messages were received and we want to have some confidence on the flow of transactions. </p> <p>Availability: the message is available when needed. Includes protection against  denial of service attacks. We want to ensure our service uninterupted and we want to design fairness so that the access to the system is equally  distributed.</p>"},{"location":"333/Encryption/signatures/","title":"Signatures","text":"<p>Digital signatures get sent along with messages. They let you know </p> <ul> <li>who signed the message (authentication)</li> <li>the message is the same as the one that was signed (integrity)</li> <li>very good evidence of where it originated (non-repudiation)</li> </ul> <p>Signatures are tags that go along with the message. The tag is produced by a mathematical function that takes the message and the senders private key as arguments.</p> <p> We can see that the signing and encrypting processes differ:</p> <ul> <li>Signing sends the message (could be in ciphertext or plaintext) along with the tag.</li> <li>The tag is produced by the senders private key which is opposite of public  key encryption where the receivers public key is used to encrypt the message.</li> <li>Instead of encryption and decryption functions to encode ciphertext and  recover plaintext, we have signing and verification functions to produce  a tag and to indicate if the message was validly signed. </li> </ul>"},{"location":"333/Encryption/signatures/#hashing-the-message-before-signing","title":"Hashing the Message before Signing","text":"<p>A performance improvement can be made by hashing the message before it is sent. Hashes are typically much shorter than the message that will be sent, and so it will be less computationally intense to easily generate a hash, and then use the hash to produce the tag. </p>"},{"location":"333/Encryption/stories/","title":"Stories","text":""},{"location":"333/Encryption/stories/#unix-using-encryption-to-hash-passwords","title":"Unix using encryption to \"hash\" passwords","text":"<p>One of the problems with this was that they used a symmetric cipher scheme called DES to encrypt the passwords, but DES also has a decryption function and if the key is compromised then the attacker could access all of the passwords.  This is a big oversight where we want something to behave as a \"hashing\" function where we have preimage resistance, now it's not so hard to potentially recover the original password once the key is broken. </p>"},{"location":"333/Networking/Data%20Link%20Layer/bridges/","title":"Bridges","text":"<p>Bridges aren't as commonly seen as routers are in our day to day lives, but we may run into them in larger networks where different LANs are connected like  a large network at an office. </p> <p>Bridges operate at the Data Link layer which is the 2nd level of the OSI stack,  the Network Interace layer of the TCP/IP stack.</p> <p>At this layer, communication is completed in frames and the standard that  defines the frame depends on the media. For example, there is an Ethernet frame , token ring frame, wireless LAN frame, and more. Communication is addressed using MAC addresses. </p> <p>When a host is initially connected to a bridge, they have no information  about other hosts that may be connected to the bridge, and the bridge has no information about what is connected to it. As hosts begin to transmit, the  bridge can learn (and hosts on the same broadcast domain) which hosts are  located on which broadcast domains. </p>"},{"location":"333/Networking/Data%20Link%20Layer/bridges/#addresses","title":"Addresses","text":"<p>Addresses are 12 hexadecimal characters and are 6 bytes long. </p> <p>Info</p> <p>Hexadecimal ranges from 0 -15, and we need 4 bits to encode each character.  4 bits * 12 characters = 48 bits / (8 bits/byte) = 6 bytes</p> <p>Addresses can be locally unique or globally unique.</p> <p>You can broadcast by using all 1s: FF:FF:FF:FF:FF:FF. </p> <p>Each of the interfaces on a device (ethernet port, wifi port, bluetooth port,  etc) will have its own addresse, so device may have multiple addresses. </p>"},{"location":"333/Networking/Data%20Link%20Layer/bridges/#backward-learning-bridges","title":"Backward Learning Bridges","text":"<p>Bridges broadcast by default at start up. As they receive frames from hosts they learn which segment that host is on. This is stored in a forwarding table.  If the destination address is not known, then the frame must be broadcast to all segments on the bridge.</p>"},{"location":"333/Networking/Data%20Link%20Layer/bridges/#weaknesses","title":"Weaknesses","text":""},{"location":"333/Networking/Data%20Link%20Layer/bridges/#silent-hosts-are-not-discovered","title":"Silent hosts are not discovered","text":"<p>If a host never transmits, then the bridge will not be able to add them to the bridges forwarding table, and any inbound traffic to that host will always broadcasted to all segments/broadcast domains.</p>"},{"location":"333/Networking/Data%20Link%20Layer/bridges/#limited-forwarding-tables","title":"Limited Forwarding Tables","text":"<p>The memory available to store forwarding information is limited, and entries  will be cleared out according to the eviction policy.</p>"},{"location":"333/Networking/Data%20Link%20Layer/bridges/#broadcast-by-default","title":"Broadcast by default","text":"<p>When a bridge is booted up, its forwarding tables are empty, so as it begins to learn who is on what host it needs to broadcast to all the segments until the forwarding table is populated. </p>"},{"location":"333/Networking/Data%20Link%20Layer/bridges/#attacks","title":"Attacks","text":""},{"location":"333/Networking/Data%20Link%20Layer/bridges/#dos-attack-by-overloading-forwarding-table","title":"DOS Attack by Overloading Forwarding Table","text":"<p>The attackers aim is to generate a large amount of broadcast traffic over the bridge network. They can utilize the limited space on the forwarding tables by sending spoofed source and destination MAC addresses. The spoofed source  addresses will eventually cause the forwarding table to lose its existing  entries, and the spoofed destination addresses will mean the frame will need to be broadcasted to all of the segments.</p>"},{"location":"333/Networking/Data%20Link%20Layer/bridges/#eavesdropping","title":"Eavesdropping","text":"<p>If you are on the same segment as the host you wish to eavedrop on, then you only need to set your device to promiscuous mode to receive any traffic, and if you want to see traffic from other segments, then you can also do a similar attack to the above to flush the forwarding table. </p>"},{"location":"333/Networking/Data%20Link%20Layer/bridges/#impersonation","title":"Impersonation","text":"<p>You can change your MAC address to pretend to be a different host. </p>"},{"location":"333/Networking/Network%20Layer/routers/","title":"Routers","text":"<p>Routers work one level up from where bridges work on the Network layer on the OSI model, and on the IP layer on the TCP/IP model. </p>"},{"location":"333/Networking/Network%20Layer/routers/#addresses","title":"Addresses","text":"<p>IP addresses are 32 bits long and commonly displayed as 8 bit numbers in base 10 eg. $ 128.15.0.1 = 10000000.00001111.00000000.00000001 $ </p> <p>A slash on a network such as $ 128.10.0.0/16 $ indicates the networks prefix size. In this case, the first two base 10 numbers identify the network segment  and then hosts could be addressed from $ 128.10.0.1 - 128.10.255.254 $. The  last $ .255 $ is reserved for broadcast traffic.</p>"},{"location":"333/Networking/Network%20Layer/routers/#ip-forwarding","title":"IP Forwarding","text":"<p>IP packets are forwarded differently depending on if it is the host sending it,  or if it is the router sending it. </p> <p>Forwarding rules do not depend on the source address. Other Network layer  applications like firewalls may add additional rules based on source address to  help address this \"oversight\". </p> <p>If a host is sending it, it will generally  use ARP to discover the IP address if it doesn't already know it and then send  the packet. If it, it isn't on the same subnet then it will send it to the  default gateway. </p> <pre><code>sequenceDiagram\n    autonumber\n    participant Host as IPv4 Host\n    participant Network as Network/Subnet\n    participant Gateway as Gateway (Router)\n\n    Host-&gt;&gt;Host: Check if destination D is in a directly attached subnet\n    alt is in directly attached subnet\n        Host-&gt;&gt;Network: Determine host's MAC address with ARP\n        Host-&gt;&gt;Network: Encapsulate packet in MAC frame\n        Host-&gt;&gt;Network: Send packet directly\n    else not in directly attached subnet\n        Host-&gt;&gt;Host: Determine which gateway to use\n        Note right of Host: Usually one default gateway\n        Host-&gt;&gt;Gateway: Forward packet to gateway\n    end</code></pre> <p>When you need to send it from the router, the router will check it if the  packet matches any of its known subnets and route to them; otherwise, it will check the prefix to see the longest prefix match and route to it. If there are  still no matches the packet may be dropped or routed to a default gateway. </p> <pre><code>sequenceDiagram\n    autonumber\n    participant Router as IPv4 Router\n    participant SubnetA as Subnet A\n    participant SubnetB as Subnet B\n\n    Router-&gt;&gt;Router: Check if destination D belongs to known subnets\n    alt belongs to one subnet\n        Router-&gt;&gt;SubnetA: Route to the link for Subnet A\n    else belongs to multiple subnets\n        Router-&gt;&gt;Router: Identify longest prefix match to D\n        alt longest prefix match is Subnet A\n            Router-&gt;&gt;SubnetA: Route to the link for Subnet A\n        else longest prefix match is Subnet B\n            Router-&gt;&gt;SubnetB: Route to the link for Subnet B\n        end\n    else does not belong to any subnet\n        Router-&gt;&gt;Router: Use default route or drop packet\n    end</code></pre>"},{"location":"333/Networking/Network%20Layer/routers/#protocols","title":"Protocols","text":""},{"location":"333/Networking/Network%20Layer/routers/#arp","title":"ARP","text":"<p>Even if two hosts on the same Ethernet LAN know each others IP addresses, the  Ethernet frames that are ultimately sent must have source/destination MAC  addresses within them. </p> <p>The host will maintain a table of IP-to-MAC mappings, and these tend to expire  to help ensure they stay accurate. The ARP protocol will broadcast on the  network segment which lets the destination know the sources MAC/IP, and then the destination will respond with their MAC/IP which will let the source know. If a host is set to promiscuous mode, they may also collect this information.</p> <p>After that the source can send Ethernet frames with IP content directed at the  destination. </p> <pre><code>sequenceDiagram\n    participant A as Host A\n    participant B as Promiscuous&lt;br/&gt;Host B\n    participant C as Host C\n\n    A-&gt;&gt;B: ARP Request for Host C's MAC\n    Note over A,B: Host B records Host A IP &amp; MAC\n    A-&gt;&gt;C: ARP Request for Host C's MAC\n    Note over B,C: ARP Request received\n    Note over B,C: Host C records Host A IP &amp; MAC\n\n    C-&gt;&gt;A: ARP Reply with C's MAC\n\n    A-&gt;&gt;C: Send frame with IP packet to C's MAC\n</code></pre>"},{"location":"333/Networking/Network%20Layer/routers/#proxy-arp","title":"Proxy ARP","text":"<p>Routers will often pretend to be a host on a LAN so that they may forward  traffic intended for that host to a remote LAN. This is helpful to connect  LANs that whose subnets are physically separated. </p>"},{"location":"333/Networking/Network%20Layer/routers/#gratuitous-arp","title":"Gratuitous ARP","text":"<p>This is sent as a frame broadcast so the host can announce its IP/MAC mapping  to the network segment. </p> <p>This also can be used in failover situations when a host pretends to be the IP/ MAC mapping for a host that has gone down and broadcasts this out. This has  some problems where it can be used as a man-in-the-middle attack. </p>"},{"location":"333/Networking/Network%20Layer/routers/#weaknesses","title":"Weaknesses","text":""},{"location":"333/Networking/Network%20Layer/routers/#_1","title":"Routers","text":""},{"location":"333/Networking/Network%20Layer/routers/#attacks","title":"Attacks","text":""},{"location":"333/Networking/Network%20Layer/routers/#impersonation-via-arp-spoofing","title":"Impersonation via ARP Spoofing","text":"<p>Any host may be in promiscuous mode and then take a MAC address that is in  traffic, copy it, and then pretend to be that host. Can happen anywhere on the  segment or over bridged segments. </p>"},{"location":"333/Networking/Transport/TCP/","title":"TCP","text":"<p>TCP is an IP communication protocol to send data to another host. The TCP  protocol takes place on the Transport layer of the OSI model, and the TCP/IP  layer of the TCP/IP model. After hosts and routers have figured out via ARP how to communicate with other hosts on the segment, and routers know how to  route IP traffic, then we can set up a connection between two hosts with their IP addresses and ports. Ports are typically mapped to a process. </p>"},{"location":"333/Networking/Transport/TCP/#tcp-handshake","title":"TCP Handshake","text":"<p>To begin a connection with another host: 1. the client sends a SYN (synchronize), and CSEQ (client sequence number). 2. the destination responds with a SYN, ACK (acknowledgement), CSEQ+1, and SSEQ. 3. the client sends ACK, SSEQ+1, and CSEQ+1 (and optionally data).</p> <pre><code>sequenceDiagram\n    participant Client\n    participant Server\n\n    Client-&gt;&gt;+Server: SYN, CSEQ\n    Note right of Server: Server allocates memory to preserve state.\n    Server--&gt;&gt;-Client: SYN, ACK, CSEQ+1, SSEQ\n    Client-&gt;&gt;Server: ACK, SSEQ+1, CSEQ+1\n    Note left of Client: Client could send data here.\n    Note right of Server: After session is made, SEQ is only incremented with data being sent.\n    Note right of Server: SEQ will eventually wrap around.</code></pre>"},{"location":"333/Networking/Transport/TCP/#syn-cookie","title":"SYN Cookie","text":"<p>In the weaknesses listed below, we mention that the server must allocate space  during the handshake process and that this exposes an attack vector for a large  number of attacks to deplete the space on the server. </p> <p>SYN Cookies are an approach to make the connection stateless so that the server  can not be exhausted. The server encodes state information when it responds to  the clients SYN request. </p> <pre><code>sequenceDiagram\n    participant C as Client\n    participant S as Server\n\n    Note over C,S: TCP Three-Way Handshake with SYN Cookies\n\n    C-&gt;&gt;S: SYN, CSEQ (Client initiates connection)\n    Note over S: Server calculates SYN cookie: time, max segment size,&lt;br/&gt;and hash of (client's IP, port, server IP, port, and a timestamp)\n    S-&gt;&gt;C: SYN, ACK, CSEQ+1, SSEQ&lt;br/&gt;(Server responds with SYN cookie as sequence number)\n    Note right of S: Server does not store any&lt;br/&gt;connection state.\n\n    Note over C: Client increments the SSEQ number.\n    C-&gt;&gt;S: ACK, SSEQ+1, CSEQ+1 (Client acknowledges, includes SYN cookie)\n    Note over S: Server verifies SYN cookie.\n    Note right of S: If valid, server reconstructs&lt;br/&gt;connection state and proceeds.\n\n    Note over S,C: Connection Established</code></pre> <p>When the server does receive the packet, it can inspect the time embedded in  the cookie to see if the cookie has expired, and it can recompute the hash of  the IPs/ports/time. </p>"},{"location":"333/Networking/Transport/TCP/#weaknesses","title":"Weaknesses","text":""},{"location":"333/Networking/Transport/TCP/#handshake-allocates-state-space-at-destination","title":"Handshake allocates state space at destination","text":"<p>Whenever the TCP handshake is initiated the destination will set aside some  space to store state information. Under great load this may deplete the space available at the destination device.    </p>"},{"location":"333/Networking/Transport/TCP/#port-probing","title":"Port probing","text":"<p>Requests can be sent to any port address to determine if those services are  available/online, and then an attack could be tailored to the service at the port. </p>"},{"location":"333/Networking/Transport/TCP/#sequence-number-predictability","title":"Sequence Number Predictability","text":"<p>If an attacker can determine the sequence numbers, they can impersonate the  client and send information. </p>"},{"location":"333/Networking/Transport/TCP/#attacks","title":"Attacks","text":""},{"location":"333/Networking/Transport/TCP/#syn-flood","title":"SYN Flood","text":"<p>Since we have servers that will allocate space from clients initiating  connections, we can rotate in a large load of connection requests from spoofed  IPs and deplete the space that is allocated for connections.</p>"},{"location":"333/Networking/Transport/TCP/#session-hijacking-via-initial-sequence-number-impersonation","title":"Session Hijacking via Initial Sequence Number Impersonation","text":"<p>If these numbers can be guessed then an attacker can impersonate the host and send traffic to the destination. The attack begins as one way as the attacker tries to send malicous data that will allow them to gain further control such  as trying to overwrite the targets login details. </p> <pre><code>sequenceDiagram\n    participant C as Client\n    participant S as Server\n    participant A as Attacker\n\n    A-&gt;&gt;+S: Make handshake connections to determine&lt;br/&gt;SSEQ generation algorithm at server\n    A-&gt;&gt;+S: SYN[Src=C, Dst=S, CSEQ=X]\n    Note over S, A: Attacker impersonates C.\n    S--&gt;&gt;-C: SYN/ACK [Src=S, Dst=C, CSEQ=X+1, SSEQ=Y]\n    A-&gt;&gt;+C: Bogus SYN DDOS attack to have client miss the server&lt;br/&gt;SYN/ACK backscatter and prevent Client from issuing RST\n    Note over S, A: Attacker attempts to guess SSEQ\n    A-&gt;&gt;S: ACK [Src=C, Dst=S, CSEQ=X+1, SSEQ=Y+1] w/malicious data payload\n    Note over C, A: Attacker continues to send to&lt;br/&gt;server until payload is successful and continues DDOSing client to prevent the connection from closing.</code></pre>"},{"location":"366/","title":"CMPUT 366 Notes","text":""},{"location":"366/#search-problem-formation","title":"Search Problem Formation","text":"<p>To formulate a search problem in a state space, we need to have several  parameters.</p> <ul> <li>$ G = (S, A) $ A graph with a set of states for the nodes, and edges that define the      relations between the nodes.</li> <li>$ s_o $ the starting state</li> <li>$ s_g $ the goal state</li> <li>$ T(s_n) $ the transition function which returns what other states are      connected to the input state. </li> <li>$ C(s_n, s_m) $ the cost state which accepts two states and returns the cost     to connect them. </li> </ul> <p>When we have this information, we can use various algorithms to search for a  solution to the problem.</p>"},{"location":"366/#state-space-vs-search-space","title":"State Space vs Search Space","text":"<pre><code>graph LR\n    A[City A] -- 10 --&gt; B[City B]\n    A -- 20 --&gt; C[City C]\n    B -- 30 --&gt; D[City D]\n    B -- 25 --&gt; C\n    C -- 15 --&gt; D\n    D -- 50 --&gt; E[City E]\n    A -- 60 --&gt; E</code></pre> <p>The above diagram depicts the state space. It shows all of the various the  different cities you can be in which represent the different states, and it  shows the edges that relate one state to another. </p> <pre><code>graph TD\n    A[City A] --&gt;|10| B[ B]\n    A --&gt;|20| C[ C]\n    A --&gt;|60| E1[ E]\n    B --&gt;|30| D1[ D]\n    B --&gt;|25| C1[ C]\n    C --&gt;|15| D2[ D]\n    D1 --&gt;|50| E2[ E]\n    C1 --&gt;|15| D3[ D]\n    D2 --&gt;|50| E3[ E]\n    D3 --&gt;|50| E4[ E]</code></pre> <p>We have a search tree above by selecting City A as the start position and then calling the transition function recursively until we arrive at a leaf node.  This could be part of a search problem where we have our state space with nodes and edges, start node (City A), and goal node (could be City D), and transition and cost functions. </p>"},{"location":"366/#search-space-size","title":"Search Space Size","text":""},{"location":"366/#branching-factor","title":"Branching Factor","text":"<p>Part of determining the search space size is related to determining the  number of children a node may have. This is known as the branching factor.  For example, if we say that generally nodes have 5 child nodes, then the branching factor is 5. It's typically denoted with $ b $.</p> <p></p>"},{"location":"366/#calculating-search-space-size","title":"Calculating Search Space Size","text":"<p>We can see from the above search tree that we have: $$ 3^0 + 3^1 + 3^2 + 3^3 + ... + 3^d $$</p> <p>And $ 3^d $ is the dominant term which gives the big oh size of the size  $ O(3^d) $.</p>"},{"location":"366/data_structures/","title":"Priority Queue with heapq","text":"<p>We use the heapq library in Python as our base class for a priority queue.</p>"},{"location":"366/data_structures/#methods","title":"Methods","text":"<ul> <li>.heappush - add an item to the heap. </li> <li>.heappop - removes the item at the top of the heap.</li> </ul>"},{"location":"366/data_structures/#indexing","title":"Indexing","text":"<p>You can index into the heap the same way you can for other collections;  however, the only thing that is guaranteed is that the min/max will be in the  zero position [0]. </p>"},{"location":"366/general_properties/","title":"General Properties","text":"<p>There are several properties of search algorithms that are of interest to us. </p>"},{"location":"366/general_properties/#complete","title":"Complete","text":"<p>For an algorithm to be complete, it must always be able to find a solution if a solution exists for a problem. </p>"},{"location":"366/general_properties/#optimal","title":"Optimal","text":"<p>An algorithm may find many candidate solutions to a problem, but it must be  able to determine which one is the best of all the possible solutions. We are often looking for the presence of the shortest path, and an optimal algorithm will find it. </p> <p>Suboptimal algorithms will be useful to us when an optimal algorithm exists,  but its implementation is too costly. </p>"},{"location":"366/general_properties/#space-complexity","title":"Space Complexity","text":"<p>Search algorithms need to open up nodes as they explore their neighbours and  this takes up space. See the branching diagram on the main page.</p>"},{"location":"366/general_properties/#time-complexity","title":"Time Complexity","text":"<p>The amount of time it will take us to search also depends on the number of  nodes that are opened up/expanded. See the same branching diagram. </p>"},{"location":"366/Artifacts/","title":"Artifacts","text":""},{"location":"366/Artifacts/#trees","title":"Trees","text":"<p>Cycles Transpositions</p>"},{"location":"366/Classical%20Planning/","title":"Index","text":"<p>Classical planning leverages a solver that can take a formalized description of a planning problem and return a plan that solves the problem. The solver can be applied generically to many different problems as long as we adhere to describing the problem in the formalized language.</p>"},{"location":"366/Classical%20Planning/delete_relaxation_heuristics/","title":"Delete relaxation heuristics","text":"<p>To be able to use A* and other informed search algorithms, we will need to have a heuristic function that can give us a guess at what the cost to reach the  goal is. </p> <p>Most of the previous heuristics we have seen have involved a relaxation or  simplification of the problem. STRIPS formalism has several characteristics:  the propositions, initial state, goal state, actions (preconditions, add effect and delete effect), and a cost function. What of these could we adjust to create our heuristic function? The approach we took in class was to remove the delete effects, so that when we solve the heuristic problem, everything is always true from our propositions and we only add more true things. This leads to rather illogical actions in the search tree, but it gives us a heuristic that we can use with our informed search algorithms.</p>"},{"location":"366/Classical%20Planning/delete_relaxation_heuristics/#properties-of-h","title":"Properties of h+","text":"<p>This heuristic function is both consistent (won't re-open nodes) and admissible (can find the  optimal path). However the problem of finding h+ at every node is NP-hard. There are three simplifications that can be made to find a simpler heuristic: - $ h^{add} $ - add up the sub goal costs - $ h^{max} $ - take the maximum sub goal cost - $ h^{ff} $ - (fast-forward) - extracts a relaxed plan from the problem and      uses the cost of the plan as the heuristic value.</p>"},{"location":"366/Classical%20Planning/delete_relaxation_heuristics/#subgoal-tree-for-hmax-and-hadd","title":"Subgoal Tree for $ h^{max} $ and $ h^{add} $","text":""},{"location":"366/Classical%20Planning/delete_relaxation_heuristics/#general-idea","title":"General Idea","text":"<p>We take our goal state and make that our root node, and then from there we  expand to the subgoals. We expand the sub goals of those subgoals, until we  reach the base case where we are at a terminal node which is contained within our initial state. Most expansions should have another node which represents  the cost of reaching that subgoal from its parent. Then we either take the  maximum or sum of these costs to get our heuristic value at each parent node</p>"},{"location":"366/Classical%20Planning/strips_formalism/","title":"Strips formalism","text":"<p>The Stanford Research Institute Problem Solver (STRIPS) formalism is a formal way of stating a planning problem for solving by the solver.</p> <p>The problem must be described with several parts:</p> <ul> <li>Finite set of propositions $ P $ - defines what is true in this world</li> <li>Initial state $ I \\subseteq P $ - the starting state of the world</li> <li>Goal state $ G \\subseteq P $ - the desired state of the world</li> <li>Actions $ A $ - a set of actions that can be taken. Each action has a     pre-condition and effect (additions and deletions). ($ pre_a, add_a, del_a     $)<ul> <li>$ pre_a $ - a set of propositions that must be true for the action to be     taken</li> <li>$ add_a $ - a set of propositions that will be true after the action is     taken</li> <li>$ del_a $ - a set of propositions that will be false after the action is     taken</li> </ul> </li> <li>Cost function $ c: A \\rightarrow \\mathbb{R}_0^+ $ - a function that     assigns a cost to each action</li> </ul> <p>A problem is solvable if there is a set of actions that transform the initial state into the goal state. </p> <p>The combination of propositions form a state space. One of the combinations is our initial state, and then we need to search from there to find a path to the goal state. However, the state space contains all of the combinations and so there can be states in the space that do not make sense to the solving of the problem. </p>"},{"location":"366/Constraint%20Satisfaction/","title":"Index","text":"<p>Search tree comparisons:  (re: quiz 8)  - </p> <p>Constraint satisfaction problems have factored states where there is additional information available about a given state and this lets us do more than just search blindly. We can use this information to guide our search. </p> <p>Constraint satisfaction problems are defined as:</p> <ul> <li>Variables</li> <li>Domain for the variables</li> <li>Constraints that limit the domain values for the variables (unary, binary,   global)</li> </ul> <p>One powerful concept that emerges from CSP problems is using the constraints to minimize the search space. Constraints eliminate possible domain values for some variables and this means the search trees branching factor is reduced.</p>"},{"location":"366/Constraint%20Satisfaction/arc_consistency/","title":"Arc consistency","text":"<p>We use arc consistency in constraint satisfaction problems to be able to reduce the domain of the variables. This can be applied in backtracking algorithm before it runs, or while it runs. </p> <p>The problem can be pre-processed to make the problem arc-consistent before running backtracking. You can also run AC3 or forward checking while in the backtracking algorithm as you check each of the domain values. This step is usually called inference. </p> <p>Forward checking only checks the neighbours of the currently selected variable, whereas AC3 will check all the variables in the problem. </p>"},{"location":"366/Constraint%20Satisfaction/arc_consistency/#mac-maintaining-arc-consistency-ac3-algorithm-applied-in-backtracking","title":"MAC (Maintaining Arc Consistency) (AC3 Algorithm applied in backtracking)","text":""},{"location":"366/Constraint%20Satisfaction/arc_consistency/#forward-checking","title":"Forward Checking","text":""},{"location":"366/Constraint%20Satisfaction/backtracking/","title":"Backtracking","text":""},{"location":"366/Constraint%20Satisfaction/backtracking/#main-idea","title":"Main Idea","text":"<ul> <li>Base case: if A is complete, return A.</li> <li>Select a variable (FA, MRV, etc)</li> <li>Loop for the domain of the variable<ul> <li>Check if the value is consistent with the constraints</li> <li>Assign variable to the value</li> <li>Recursively call backtracking (now has that variable assigned)</li> <li>if it didn't fail, return the assignment</li> </ul> </li> </ul> <p>The algorithm loops over domain values and recursively explores their  assignment. If nothing in the domain worked, it backtracks to the previous variable and tries a different value. </p>"},{"location":"366/Constraint%20Satisfaction/backtracking/#backjumping","title":"Backjumping","text":"<p>Backjumping is an intelligent variation of backtracking </p>"},{"location":"366/Constraint%20Satisfaction/backtracking/#conflict-directed-backjumping","title":"Conflict-Directed Backjumping","text":""},{"location":"366/Informed%20Search/","title":"Informed Search","text":"<p>Search algorithms such as Dijkstra and Breadth-First Search never have any information about the end state other than that is what they are looking for.  An informed search algorithm uses a heuristic function to \"inform\" the  algorithm, and in doing so can minimize the time and space complexity to do so.</p>"},{"location":"366/Informed%20Search/a_star/","title":"A* Search","text":"<p>A* Search is an improvement on Dijkstra's algorithm to help increase the speed of the search by creating a focused search frontier. </p> <p>The priority queue receives a different cost value. Dijkstra's algorithm only adds the current cost leading up to the particular node, but A* adds an additional heuristic cost between the current node and the end node. </p> <p>A* follows the same algorithm as Dijkstra's with a couple of exceptions. We have access to the g-value and h-value[^ghvalues].</p> <p>Note</p> <ul> <li>The g-value is the calculated cost from the start node to a node. The </li> <li> <p>h-value is the heuristic derived cost from the node to the finish.</p> </li> <li> <p>We use the f cost to sort the priority queue \\(f = g + h\\)</p> </li> <li>Nodes that are expanded with a sub-optimal cost will eventually be re-opened however many times until the optimal cost is found.</li> </ul> <p>In Dijkstra we made updates when we found a better g-value for a given node. For A*, we will update this when we find a better f-value. </p>"},{"location":"366/Informed%20Search/a_star/#weighted-a","title":"Weighted A*","text":"<p>The heuristic function is multiplied by a scalar value to put more emphasis on the heuristic rather than the cost back to the start (g value). </p> \\[ f(s) = g(s) + w \\dot h(s) \\quad w &gt; 1 \\]"},{"location":"366/Informed%20Search/a_star/#astar-nuances","title":"AStar Nuances","text":"<p>A can run out of memory when the state space is very large. In these instances we can use a technique called iterative deepening A (IDA*). This is similar to iterative deepening depth-first search. Iterative algorithms suffer from  transpositions, and so we need to keep track of them using a transposition  table. </p>"},{"location":"366/Informed%20Search/bidirectionalAStar/","title":"Bidirectional A*","text":"<p>This builds upon what we have see with Bidirectional Brute Force with  Dijkstra'a algorithm, but also makes use of A heuristic functions. The  downside to this is that the opening of nodes may not be balanced between the forward and backward lists, and the whole point of bidirectional search is to  ideally cut the search space in half. This is solved in  Meet in the Middle. In general, Bidirectional A does  meet in the middle, but if you need to be certain use MM. </p>"},{"location":"366/Informed%20Search/greedyBestFirstSearch/","title":"Greedy Best First Search","text":"<p>There are a few ways to modulate the heuristic function to different effect  such as in weighted A*. Another way is to totally discard the g-cost in the computation of the f-value and use only the h-value to guide the search.</p> <p>This algorithm is complete, but sub-optimal. It could find an optimal solution  but it is not guaranteed to. </p> \\[ f(n) = h(n) \\]"},{"location":"366/Informed%20Search/heuristics/","title":"Heuristics","text":""},{"location":"366/Informed%20Search/heuristics/#properties","title":"Properties","text":""},{"location":"366/Informed%20Search/heuristics/#admissible","title":"Admissible","text":"<p>An admissible heuristic function will provide some value $ h(n) $ related to a given state and the goal state, and that value must not exceed the true optimal path cost from the given state to the goal state. Admissible heuristics are able to find the optimal path to the goal state if it exists.</p> \\[ h(n) \\leq h^*(n) \\]"},{"location":"366/Informed%20Search/heuristics/#consistent","title":"Consistent","text":"<p>The use of a queueing structure and the fact that we have to deal with  transpositions (where multiple pathes may lead to the same state), mean that it can be possible for an algorithm to try to re-open nodes that have already been added to the OPEN list. A heuristic that is consistent will never re-open nodes.</p>"},{"location":"366/Informed%20Search/heuristics/#functions","title":"Functions","text":""},{"location":"366/Informed%20Search/heuristics/#number-of-tiles-out-of-place","title":"Number of Tiles Out of Place","text":"<p>This heuristic is used in the sliding tiles game. The heuristic function will count the number of tiles that are not in their correct position. </p>"},{"location":"366/Informed%20Search/heuristics/#manhattan-distance","title":"Manhattan Distance","text":""},{"location":"366/Informed%20Search/heuristics/#octile-distance","title":"Octile Distance","text":""},{"location":"366/Informed%20Search/heuristics/#tiles-out-of-place","title":"Tiles Out of Place","text":""},{"location":"366/Informed%20Search/heuristics/#pattern-databases","title":"Pattern Databases","text":"<p>This heuristic is applied in a sliding tiles game and could be used in other combinatorial problems. The basic idea is to simplify the game into a goal state mask and then apply your actions to this mask. This forms its own state space and the costs related to arriving at each state from the series of actions. Those costs can be used as your heuristic values in your main search. </p>"},{"location":"366/Informed%20Search/iterativeDeepeningAStar/","title":"Iterative Deepening A*","text":"<p>This is a modification to Iterative Deepening Depth First Search to improve  the time complexity of the search. IDDFS moves somewhat slow as it increments  its d values. Iterative Deepening A* uses a heuristic to guide the next d-value. </p> <p>The heuristic chooses the next d-value based on the smallest f-value that was  pruned from the last iteration. </p>"},{"location":"366/Informed%20Search/meetInTheMiddle/","title":"Meet in the Middle","text":"<p>This is a variation of the Bidirectional A so that we can guarantee* that  the forward and backward searches will open to the same cost. The values in the priority queue are sorted according to their p-value given by the below  formula. $$ p(n) = max(f(n), 2 \\cdot g(n)) $$</p> <p>Note</p> <p>Nodes are sorted in the list according to the above equation where we take the max of the $ f(n) = g(n) + h(n) $ or $ 2 \\cdot g(n) $. The 2nd terms  job is to prevent the search from crossing the mid point of cost. </p> <p>The stopping condition for MM is a little more complex. You can use just the 4th option by itself. $ U $ is the cost of the candidate solution, and it will stop searching when U meets the below criteria. </p> <ol> <li>\\( U \\leq g_{\\text{minf}} + g_{\\text{minb}} + \\varepsilon \\)</li> <li>\\( U \\leq f_{\\text{minf}} \\)</li> <li>\\( U \\leq f_{\\text{minb}} \\)</li> <li>\\( U \\leq \\min(p_{\\text{minf}}, p_{\\text{minb}}) \\)</li> </ol>"},{"location":"366/Informed%20Search/transpositionTables/","title":"Transposition Tables","text":"<p>A transposition table is used to store some information about seen states to  help prevent transpositions. IDDFP suffers from an inability to detect  transpositions and this can greatly increase the time taken for it to do its search. </p>"},{"location":"366/Informed%20Search/weightedAStar/","title":"Weighted A*","text":"<p>In Weighted A* we inflate the effect of the heuristic. Sometimes this algorithm may expand less states than A* or IDA*, and you can experiment to see if it works well for your problem space. </p> \\[ \\begin{aligned}     &amp; w &gt; 1 \\\\     &amp; f(n) = g(n) + w \\cdot h(n) \\end{aligned} \\]"},{"location":"366/Informed%20Search/weightedIterativeDeepeningAStar/","title":"Weighted Iterative Deepening A*","text":"<p>The best of both worlds. See:</p> <ul> <li>Weighted A*</li> <li>Iterative Deepening A*</li> </ul>"},{"location":"366/Informed%20Search/Multi%20Agent%20Search/","title":"Multi Agent Search","text":""},{"location":"366/Informed%20Search/Multi%20Agent%20Search/#multi-agent-heuristics","title":"Multi Agent Heuristics","text":""},{"location":"366/Informed%20Search/Multi%20Agent%20Search/#makespan","title":"Makespan","text":"<p>The heuristic is guided by the maximum cost present for all of the agents. $$ h(s) = max_{a_i \\in S}(MD(a_i, g)) $$</p> \\[ h(s) = max_{a_i \\in S}(a^*(a_i, g)) \\]"},{"location":"366/Informed%20Search/Multi%20Agent%20Search/#sum-of-the-costs","title":"Sum of the Costs","text":"<p>The heuristic is guided by the summation of costs for all of the agents.  $$ h(s) = \\sum_{a_i \\in S} (a^*(a_i, g)) $$</p>"},{"location":"366/Informed%20Search/Multi%20Agent%20Search/conflictBasedSearch/","title":"Conflict Based Search","text":"<p>This approach fixes the problems of Cooperative A*. </p> <p>CBS builds a tree of constraints and solutions. A solution exists when  there is no conflict in the proposed agent paths.</p>"},{"location":"366/Informed%20Search/Multi%20Agent%20Search/cooperativeAStar/","title":"Cooperative A*","text":"<p>Basically the agents take turns to solve the problem. Constraints are placed as each agent runs so that no agent can conflict with an already taken state. </p> <p>This approach is not optimal or complete.</p>"},{"location":"366/Local%20Search/","title":"Local Search","text":"<p> The goal of Local Search is to find a goal configuration and we do not need a path to reach that goal. Games like n-queens want to know what configuration of queens will be valid, and problems like the Travelling Salesman Problem just  needs a set of cities to visit. n-queens is a pure-search problem because  any solution is valid, but TSP is a pure-optimization problem because  although we may have many different solutions - we want the one that is  optimal (or close to optimal) so the salesman doesn't have to drive so far. </p> <p>Local Search problems aren't about actions taken as a pathfinding problem might reach through a transition function. Instead we look at neighborhoods  candidates of a given configuration. </p> <p>Combinatorial search problems are defined as:</p> <ul> <li>C is a set of candidates</li> <li>$ S \\subseteq C $ is a subset of candidates that is a solution</li> <li>$ opt \\in { min, max } $ is the type of optimization we are looking for</li> <li>$ v $ is an objective function mapping the candidate to $ \\R $</li> </ul>"},{"location":"366/Local%20Search/beam_search/","title":"Beam search","text":"<p>Simulated annealing is limited in that it is only looking at one candidate at a time. If the simulated annealing heuristic is wrong, then it will take longer to find some solution. </p> <p>Beam search can keep more than one candidate at a time. If it keeps only 1  candidate then it is equivalent to simulated annealing. If it keeps a very  large number of candidates then it is equivalent to breadth-first search.  Adjusting this hyperparameter will depend on the problem at hand.</p> <ul> <li>$ B $ - set of candidates</li> <li>$ K $ - number of candidate solutions to use</li> </ul> <p>As we vary K from 1 to the maximum, we see the transition from hill climbing to breadth-first search. </p> <p></p>"},{"location":"366/Local%20Search/program_synthesis/","title":"Program synthesis","text":"<p>What could we write here as the topic is kind of deep?</p>"},{"location":"366/Local%20Search/simulated_annealing/","title":"Simulated annealing","text":"<p>Simulated annealing combines the ideas of hill climbing and random walks. Hill climbings efficacy depends on the region of the search space it starts in, and random walks have no guidance at all if they do land in an optimal region. </p> <p>Simulated annealing is typically paired with random restarts to avoid getting stuck in local minima and explore the search space more effectively.</p> <p>Search is set according to a schedule and the random walks have higher  probability, and then the schedule is adjusted towards more hill climbing. </p>"},{"location":"366/Local%20Search/simulated_annealing/#simulated-annealing-parameters","title":"Simulated Annealing Parameters","text":"<ul> <li>Beta - puts focus on the hill climbing</li> <li>Temperature - puts focus on the random walk</li> </ul>"},{"location":"366/Local%20Search/simulated_annealing/#temperature-schedule","title":"Temperature Schedule","text":"<ul> <li>Initial Temperature - $ T_0 $</li> <li>Iteration adjustment - $ \\alpha * i $</li> <li>Formula: $ T_i = \\frac{T_0}{1 + \\alpha * i} $</li> </ul>"},{"location":"366/Multi%20Agent%20Search/","title":"Index","text":"<p>In the Informed Search section we looked at Conflict Based Search and  Cooperative A* which are examples of multi-agent search algorithms. However they differ from the algorithms in this section as they have central control where each agent isn't reasoning individually about how to act. Here the agents are reasoning individually. </p> <p>To reason about how agents should make decisions, we have some concepts from Game Theory that we discuss.</p>"},{"location":"366/Multi%20Agent%20Search/game_theory/","title":"Game theory","text":"<ul> <li>Dominance<ul> <li>Strict Dominance</li> <li>Weak Dominance</li> </ul> </li> <li>Best Response</li> <li>Nash Equilibrium</li> <li>Mixed Strategy</li> </ul>"},{"location":"366/Multi%20Agent%20Search/game_theory/#dominance","title":"Dominance","text":"<p>The idea of dominance is to do with the selection of a strategy based on the its outcome versus the other players strategies. If a strategy is always better than another strategy, then it is said to strictly dominate that strategy. If it is sometimes better, then it is said to weakly dominate that strategy.</p>"},{"location":"366/Multi%20Agent%20Search/game_theory/#best-response","title":"Best Response","text":"<p>When dominance isn't found in the strategies we next look at best response. The player selects the stragegy that maximises their utility given the other players strategy. </p>"},{"location":"366/Multi%20Agent%20Search/game_theory/#nash-equilibrium","title":"Nash Equilibrium","text":"<p>A nash equilibrium is a pair of strategies where no player has an incentive to change their strategy. It's easiest identified by looking at the best response for each player. If they are both playing their best response in a given cell then it is a nash equilibrium.</p>"},{"location":"366/Multi%20Agent%20Search/game_theory/#mixed-strategy","title":"Mixed Strategy","text":"<p>A pure strategy is one that we can find from playing a single strategy, but  a nash equilibrium may not exist. Instead we have to take a mix of strategies  to find a nash equilibrium. </p>"},{"location":"366/Multi%20Agent%20Search/games/","title":"Games","text":"<p>Multi agent games can be represented in different ways. Two of the ways we will look at are: </p> <ul> <li>Normal-Form Game</li> <li>Extensive-Form Game</li> </ul>"},{"location":"366/Multi%20Agent%20Search/games/#normal-form-game","title":"Normal-Form Game","text":"<p>This represents the game in a grid where each cell represents the utility of  the players. One player is the \"row player\", and the other player is the  \"column player\". The actions that each player can take are above or beside the column/row. </p>"},{"location":"366/Multi%20Agent%20Search/games/#extensive-form-game","title":"Extensive-Form Game","text":"<p>Games are represented as a tree of decisions. Each node represents some  configuration of the game where the agent must act. </p>"},{"location":"366/Multi%20Agent%20Search/games/#information","title":"Information","text":"<p>Agents in multi player games may have perfect or imperfect information. Perfect information is when all players know the state of the game, and this would be seen in a game of chess where both players can see the board. Imperfect information is when players don't know the full state of the game, and this would be found in a game of poker. </p>"},{"location":"366/Uninformed%20Search/","title":"Uninformed Search","text":"<p>With uninformed search, we don't have information about the goal state, so we must explore the state space to find the goal. </p> <p>Breadth First Search and Dijkstra are similar; however, Dijkstra implements a priority queue to sort the cost of the nodes whereas BFS only works optimally  if there are only unit costs. </p> <p>Depth First Search and Iterative Deepening Depth First Search are helpful to  have a smaller memory footprint. Dijkstra and BFS both can take up a lot of  memory to store states in the CLOSED and OPEN lists. Howevwer DFS and IDDFS  both suffer from a problem with transpositions. </p>"},{"location":"366/Uninformed%20Search/bidirectionalBruteForceSearch/","title":"Bidirectional Brute Force Search","text":"<p>The benefit of bidirectional search is that we can try to cut the search space  in half which gives us big improvements in time and space. We search from the start to the goal, and from the goal to the start. This particular one is  implemented with as a variant of Dijkstra's algorithm.</p> <p>The algorithms are similar except we add the goal to the OPEN and CLOSED lists. We can stop when we've found the same state in both forward and backward  search AND!:</p> \\[ \\begin{align*}     n' \\text{ the same state in both forward/backward lists} \\\\         g_f(n')+g_b(n') \\leq g_{minf} + g_{minb} + \\epsilon \\end{align*} \\] <p>Which is to say that the state that the sum of the forward and backward costs to arrive at that node n is less than or equal to the sum of the smallest  cost to any node in the forward list and the smallest cost to any node in the  backward list plus epsilon which is the smallest cost we can incur to move.</p>"},{"location":"366/Uninformed%20Search/dijkstra/","title":"Dijkstra","text":""},{"location":"366/Uninformed%20Search/dijkstra/#algorithm","title":"Algorithm","text":"<pre><code>def dijkstra(s0, sg, T):\n    OPEN.append(s0)\n    CLOSED.add(s0)\n    while not OPEN.empty():\n        n = OPEN.pop()\n        if n == sg:\n            return path from s0 to n\n        for n\u2032 in T(n): \n            if n\u2032 not in CLOSED:\n                OPEN.append(n\u2032)\n                CLOSED.add(n\u2032)\n            # if it has found better path\n            if n\u2032 is in CLOSED and g(n\u2032) &lt; CLOSED[n\u2032].g_value:\n                update g(n\u2032) in OPEN and CLOSED\n                update parent of n\u2032in CLOSED\n                #reconstruct entire heap\n                heapify OPEN\n</code></pre>"},{"location":"366/Uninformed%20Search/dijkstra/#details","title":"Details","text":"<p>The main function if the inner loop has two parts: - if the child wasn't in the CLOSED list (if we haven't seen it before). Then add it to the CLOSED list. - if that child has a cheaper cost than the current version in the CLOSED list, then update it to that value. </p>"},{"location":"366/Uninformed%20Search/dijkstra/#definitions","title":"Definitions","text":"<p>g(node): gets the code from the start to the node.</p> <p>g_value: the cost to travel from the start to the node.</p> <p>T(node): gets the children of a node.</p>"},{"location":"366/Uninformed%20Search/iterativeDeepeningDepthFirstSearch/","title":"Iterative Deepening Depth First Search","text":"<p>IDDFS resolves the problems with Depth First Search where DFS goes further  than the depth at where the solution state is. It does this by incrementing the depth of its search and doing all of the expansions until this limit.  That way we can be sure to  find an optimal solution. </p>"},{"location":"402/","title":"CMPUT 402","text":""},{"location":"402/#topics","title":"Topics","text":"<ul> <li>[ ] first lecture</li> <li>software quality</li> <li>definitions<ul> <li>mccall</li> <li>boehm</li> <li>25010</li> </ul> </li> <li>[x] black box testing</li> <li>test values<ul> <li>boundary value testing</li> <li>boundary value analysis</li> <li>robustness testing</li> <li>partition testing</li> </ul> </li> <li>finite state machines</li> <li>fuzz testing</li> <li>[x] white box testing</li> <li>statement coverage</li> <li>control flow graphs</li> <li>branch coverage</li> <li>\"subsume\"</li> <li>condition coverage</li> <li>branch and condition coverage</li> <li>(MC/DC) modified conditoin/decision coverage</li> <li>path coverage</li> <li>data-flow coverage</li> <li>mutation testing</li> <li>test oracle</li> <li>[x] tdd</li> <li>red-green-refactor</li> <li>benefits</li> <li>[x] code review</li> <li>code review</li> <li>inspections</li> <li>walk through</li> <li>[x] testing distributed systems</li> <li>Reliability measures</li> <li>robustness</li> <li>testing distributed systems<ul> <li>stubs</li> <li>mocks</li> <li>fakes</li> </ul> </li> <li>chaos engineering<ul> <li>challenges</li> <li>purpose</li> </ul> </li> <li> <p>[x] test smells</p> </li> <li> <p>test code duplication</p> </li> <li>test logic in production</li> <li>erratic tests</li> <li>obscure tests</li> <li>assertion roulette</li> <li>condition logic in test</li> <li>slow tests</li> <li>mystery guest</li> <li>resource optimism</li> <li>test run war</li> <li>general fixture</li> <li>lazy test</li> <li>indirect test</li> <li>sensitive equality</li> </ul> <p>## Summary</p> <ul> <li>[x] black box testing</li> <li>[x] white box testing</li> <li>[x] tdd</li> <li>[x] code review</li> <li>[x] testing distributed systems</li> <li>[x] test smells</li> <li>[8] software quality</li> <li>[x] intro to software quality</li> </ul>"},{"location":"402/#topics-for-midterm-2","title":"Topics For Midterm 2","text":"<ul> <li>[x] Measurement</li> <li>[x] DevOps</li> <li>[x] Static Analysis</li> <li>[x] Design Quality</li> <li>[x] Performance</li> <li>[x] Security</li> <li> <p>[ ] Technical Debt</p> </li> <li> <p>Measurement</p> </li> <li>maintainability index</li> <li>halstead volume</li> <li>cyclomatic complexity</li> <li>measurement</li> <li>develop a measure<ul> <li>goal question metric</li> </ul> </li> <li>measurement scales</li> <li>measurement validation</li> <li>problems<ul> <li>correlations</li> <li>confounding variables</li> </ul> </li> <li>Devops</li> <li>Goals</li> <li>CI</li> <li>Continuous Delivery</li> <li>Continuous Deployment</li> <li>Costs</li> <li>Tools</li> <li>Config Management</li> <li>Monitoring</li> <li>A/B Testing</li> <li>Release Management</li> <li>Feature flags</li> <li>Prod tests</li> <li>Static Analysis</li> <li>dynamic verification vs static verification<ul> <li>pro / con</li> </ul> </li> <li>for any interesting property Pr...</li> <li>types<ul> <li>control-flow analysis</li> <li>data-flow analysis</li> <li>typestate analysis</li> <li>type checking</li> </ul> </li> <li>IRs</li> <li>data flow<ul> <li>constant prop</li> <li>taint analysis</li> </ul> </li> <li>trade offs<ul> <li>inter vs intra</li> <li>context sensitivty</li> <li>aliasing</li> </ul> </li> <li>tools</li> <li>Design Quality</li> <li>maintainability &amp; design quality<ul> <li>analysis</li> <li>SQALE</li> </ul> </li> <li>design principles<ul> <li>design for change</li> <li>design for reuse</li> <li>coupling</li> <li>cohesion</li> </ul> </li> <li>Performance</li> <li>KPI</li> <li>performance testing<ul> <li>baseline testing</li> <li>load testing</li> <li>stress testing</li> <li>soak testing</li> <li>spike testing</li> </ul> </li> <li>process</li> <li>profiling</li> <li>code review</li> <li>Security</li> <li>info sec aspects</li> <li>stride<ul> <li>threat modeling</li> <li>dread</li> </ul> </li> <li>tools/techniques<ul> <li>fuzz testing</li> <li>secure code review</li> <li>security static analysis</li> </ul> </li> <li>secure design principles</li> <li>Technical Debt</li> <li>cruft</li> <li>non debt</li> <li>types of debt</li> <li>management</li> <li>SQALE</li> <li>calculating</li> <li>non-remediation costs</li> </ul>"},{"location":"402/Black%20Box%20Testing/","title":"Black Box Testing","text":"<p>Blackbox testing treats the application under test as an opaque object that we can't see the internal workings of. When we design tests from a black box approach we have to think of the requirements made on the system, and exercise the system from tests upon those requirements.</p> <pre><code>graph TD\n    A[Requirements] --&gt; B[Testable Features]\n    B --&gt; C[Relevant Inputs]\n    C --&gt; D[Test Case Specs]\n    D --&gt; E[Test Cases]</code></pre>"},{"location":"402/Black%20Box%20Testing/#relevant-inputs","title":"Relevant Inputs","text":""},{"location":"402/Black%20Box%20Testing/#random-testing","title":"Random testing","text":"<p>The interesting values that we would want to test may not be uniformally  distributed, and random testing would possible miss these values.</p>"},{"location":"402/Black%20Box%20Testing/#boundary-value-testing","title":"Boundary Value Testing","text":"<p>We select values that are on the boundary of the input domain or sub-domain. </p>"},{"location":"402/Black%20Box%20Testing/#boundary-value-analysis","title":"Boundary Value Analysis","text":"<p>Select boundary values at the minimum, just above the minimum, nominal (mid),  just below the maximum, and at the maximum.</p>"},{"location":"402/Black%20Box%20Testing/#robustness-testing","title":"Robustness Testing","text":"<p>Same as boundary value analysis, but include values just outside the boundary.  This means the minimum value minus one, and the maximum value plus one.</p>"},{"location":"402/Black%20Box%20Testing/#partition-testing","title":"Partition Testing","text":"<p>The input domain may be divisible into partitions where values in each partition behave the same. We can then select values from each partition to test instead  of having to test across the entire domain. </p>"},{"location":"402/Black%20Box%20Testing/#weak-equivalence-classes","title":"Weak equivalence classes","text":"<p>Weak equivalence testing is done by selecting a value from each class so that  all classes are covered.</p> <p>The number of tests needed is defined by the largest number of classes for any of the variables.</p> \\[ \\text{Number of test cases} = \\max(|A|, |B|, ..., |Z|) \\]"},{"location":"402/Black%20Box%20Testing/#strong-equivalence-classes","title":"Strong equivalence classes","text":"<p>Strong equivalence testing is done by selecting a value from each class and creating the cartesian product of all values. </p> <p>The number of tests needed is defined by the product of the number of classes for each variable.</p> \\[ \\text{Number of test cases} = |A| \\times |B| \\times ... \\times |Z| \\]"},{"location":"402/Black%20Box%20Testing/#examples","title":"Examples","text":"<p>Date can be split up day, month, and year. </p> <p>Days depend on the month and on leap years, so we have: - 1 - 28 days - 29 days - 30 days - 31 days</p> <p>Months have different day counts: - month has 31 days - month has 30 days - month is february</p> <p>Year depends on leap years: - year is not a leap year - year is a century leap year - year is a non-century leap year</p>"},{"location":"402/Black%20Box%20Testing/#categrory-partition","title":"Categrory Partition","text":"<p>This is a similar idea to partition testing (partition is used differently here and not with relation to equivalence classes), where we divide each of the input domain into interested categories, and then assign restrictions where possible to prevent invalid combinations and reduce the number of tests needed.</p> <p>Each category is subdivided into choices. Those choices may be assigned a property annotation that restricts the choices that can be made. A value may be annotated with <code>[property Empty]</code>, and then other values can depend on  whether the property is empty or not. </p>"},{"location":"402/Black%20Box%20Testing/#reduce-combinations","title":"Reduce Combinations","text":"<ul> <li>Property ... if<ul> <li>First we mark some category values with a property annotation.</li> <li>Then we can mark other values to depend on that value. <ul> <li><code>[property HasQuoteMarks]</code></li> <li><code>[property Empty]</code></li> <li><code>[property HasSpecialChars]</code></li> <li><code>[property HasLetters]</code></li> </ul> </li> </ul> </li> <li>Error<ul> <li>This marks a value that will be tested once for an error condition.</li> </ul> </li> <li>Single<ul> <li>This marks a value that will be tested once for a single condition.</li> </ul> </li> </ul>"},{"location":"402/Black%20Box%20Testing/#example","title":"Example","text":"<p><pre><code>Paramters:\n    Quoting:\n        - string does not contain quotes\n        - string has one quote\n        - string contains more than one quote\n    Blanks:\n        - string does not contain blanks\n        - string contains blanks\n    Special Characters:\n        - string does not contain special characters\n        - string contains special characters\nEnvironment:\n    Location:\n        - ran on a local machine\n        - ran on a remote machine\n</code></pre> At first edit, this would require <code>3 * 2 * 2 * 2 = 24</code> test cases, but could quickly grow to a much larger size with more parameters or values. We can use the properties to reduce the total test count.</p>"},{"location":"402/Black%20Box%20Testing/#finite-state-machines-state-diagram","title":"Finite State Machines State Diagram","text":"<p>A finite state machine state diagram models the nodes (for states) and edges (for transitions) of a system. </p> <p>A diagram can be used to derive test cases by creating paths through all of the states and transitions in the machine. </p>"},{"location":"402/Black%20Box%20Testing/#fuzz-testing","title":"Fuzz Testing","text":"<p>Automated testing to feed in invalid, unexpected, or random data to the system with the goal of finding bugs that challenge system robustness.</p>"},{"location":"402/Code%20Review/","title":"Code Review","text":""},{"location":"402/Code%20Review/#code-review","title":"Code Review","text":"<p>Another pair of eyes will review the code to look for errors or room for  improvement in code design.</p>"},{"location":"402/Code%20Review/#inspections","title":"Inspections","text":"<p>This is a more formal, and more rigorous form of a code review that involves several different stages. </p>"},{"location":"402/Code%20Review/#walkthroughs","title":"Walkthroughs","text":"<p>Author walks participants through the code. Goal is to inform others rather than to get corrections on the code.</p>"},{"location":"402/Design%20Quality/","title":"Design Quality","text":"<ul> <li>Design Quality</li> <li>maintainability &amp; design quality<ul> <li>analysis</li> <li>SQALE</li> </ul> </li> <li>design principles<ul> <li>design for change</li> <li>design for reuse</li> <li>coupling</li> <li>cohesion</li> </ul> </li> </ul> <p>We can approximate the quality of the program design by examining quality measures, performing static analysis, and analyzing the code structure to review coupling and cohesion.</p> <p>It's important that the program be well designed because it may affect the future maintenance of the program, and the cost of adding new features. Developers may require more time to understand poorly designed systems, or be at risk of introducing more errors.</p>"},{"location":"402/Design%20Quality/#analysis","title":"Analysis","text":""},{"location":"402/Design%20Quality/#maintainabilty-index","title":"Maintainabilty Index","text":"<p>The MI gives us some indication of how the system is doing in terms of the Halstead volume (gives an idea of the size and complexity of the program), cyclomatic complexity, and lines of code.</p>"},{"location":"402/Design%20Quality/#sqale-software-quality-assessment-based-on-lifecycle-expectations","title":"SQALE (Software Quality Assessment based on Lifecycle Expectations)","text":"<p>This is an opinionated framework for evaluting code quality.</p> <p>Takes the quality values from 25010 and derives measures to assess them.</p>"},{"location":"402/Design%20Quality/#design-principles","title":"Design Principles","text":""},{"location":"402/Design%20Quality/#design-for-change","title":"Design for Change","text":"<p>We can use information hiding and encapulation to prevent our implementation details from restricting the future changes to the system. By operating with a strict interface, it's much easier for us to change the internal workings without impacting the system.</p> <p>We can rely on interfaces about what a thing does without having to worry about how it does it.</p>"},{"location":"402/Design%20Quality/#design-for-reuse","title":"Design for Reuse","text":"<p>Avoid deep inheritance hierarchies. The hierarchy itself has internal coupling between the classes, and this coupling extends to classes that use the classes from the hierarchy. Inheritance should be used in moderation.</p> <p>Alternatively, we can choose to use composition to build up the classes by adding in what we need. We can also use delegation to rely on another object for some of the functionality. Preferably delegating to an interface rather than a concrete class.</p>"},{"location":"402/Design%20Quality/#design-for-robustness","title":"Design for robustness","text":""},{"location":"402/Design%20Quality/#design-for-testability","title":"Design for testability","text":""},{"location":"402/Design%20Quality/#low-coupling","title":"Low coupling","text":"<p>As the graph of connections between classes increases, so does the risk of any change to one of those classes causing a problems in some other class.</p> <p>Classes must be coupled to create complex behaviour, but we want to strive for low coupling to minimize the risk. Low coupled classes are easier to test, and easier to reuse since there is less dependent requirements to satsify.</p> <p>Some code smells of high coupling include:</p> <ul> <li>changing class X requires changes in class Y</li> <li>having direct dependencies on objects rather than interfaces</li> </ul>"},{"location":"402/Design%20Quality/#high-cohesion","title":"High cohesion","text":"<p>Cohesion is all about whether the class is doing the same kinds of things, or different things. A highly cohesive class will be focused on something, and a low cohesive class will be doing a bunch of different things. A common low cohesive smell is a god-class that just does everything.</p> <p>Reducing cohesion in a class may involve grouping together methods and pulling them into new classes. This can help improve cohesion in the existing class.</p>"},{"location":"402/DevOps/","title":"DevOps","text":"<ul> <li>DevOps</li> <li>[x] Goals</li> <li>[x] CI</li> <li>[x] Continuous Delivery</li> <li>[x] Continuous Deployment</li> <li>[ ] Costs</li> <li>[ ] Tools</li> <li>[x] Config Management</li> <li>[x] Monitoring</li> <li>[x] A/B Testing</li> <li>[ ] Release Management</li> <li>[x] Feature flags</li> <li>[x] Prod tests</li> </ul> <p>DevOps includes all of the work after the code is written. Once it needs to enter the CI pipeline or the CD pipeline - or both! DevOps helps to make things easier between developers and infrastructure. Has a focus on automation, scaling, monitoring, and pipelining.</p>"},{"location":"402/DevOps/#continuous-integration-ci","title":"Continuous Integration (CI)","text":"<p>Basically automated building and testing of the code. Let's you know if after any commit there is an issue in the code, but it relies on having good static or dynamic tests in place. Helps you to get more feedback on failures or errors in the system and give some confidence around robustness of the code.</p>"},{"location":"402/DevOps/#continuous-delivery-continuous-deployment","title":"Continuous Delivery &amp; Continuous Deployment","text":"<p>CDel gets the code ready to be deployed, but does not deploy it. CDep does deploy the code.</p> <p>It takes a lot of tooling and work to get CD to work, and cost to support the infrastructure to home the deployments, but you get constant feedback on knowing that the code will work. The feedback leads to general faster agility on releases where you don't have to wait for a release cycle to complete before learning about any issues.</p>"},{"location":"402/DevOps/#infrastructure-configuration-management","title":"Infrastructure Configuration Management","text":"<p>Infrastructure as code is an approach to script the creation of infrastructure projects. In CMPUT 402, this was most closely reflected by the use of Docker and Github Actions.</p>"},{"location":"402/DevOps/#monitoring","title":"Monitoring","text":"<p>Monitoring is very important to help support quality objectives for robustness, reliability, performance and security. Clues can exist in the system logs that enable developers to see what has happened when it is not easy or possible to debug a running process, or when things happen in production or outside working hours.</p>"},{"location":"402/DevOps/#ab-testing","title":"A/B Testing","text":"<p>This is typically an approach used to expose different versions of the system to different audiences. It's probably more closely related to chaos engineering than testing, because it's usually an experiment to collect some kind of measure to then decide which version to use.</p>"},{"location":"402/DevOps/#feature-flags","title":"Feature Flags","text":"<p>Feature flags can also be an easy way to enable A/B testing because you can program in the ability to easily enable or disable features on the fly.</p>"},{"location":"402/DevOps/#release-management","title":"Release Management","text":""},{"location":"402/DevOps/#majorminorpatch","title":"Major/Minor/Patch","text":"<p>Major releases introduce breaking changes to the API. Minor releases add features that must be backwards compatible without breaking the API. Patches are compatible bug fixes.</p>"},{"location":"402/DevOps/#testing-in-prod","title":"Testing in Prod","text":"<p>Beta tests, AB Tests, tests across devices/regions</p> <p>It's important to collect real world information on real world systems using real world data. There are blind spots when we are only in test environments and using staged data.</p> <p>There's a bigger focus on monitoring here since production shouldn't be stopped and interfering with the process through debugging may not be possible, or may put the system at unreasonable risk.</p>"},{"location":"402/Intro%20to%20Software%20Quality/","title":"Introduction to Software Quality","text":""},{"location":"402/Intro%20to%20Software%20Quality/#definitions","title":"Definitions","text":"<ul> <li>failure: observable incorrect behaviour from the program</li> <li>fault (bug): something in the code that causes a failure.</li> <li>error (mistake): the cause of a fault. typically this is a human error.</li> </ul> <p>We may write our code with some problem inside of it that causes a fault. That fault may cause a failure. </p> <pre><code>graph TD\n    A[Error] --&gt; B[Fault]\n    B --&gt; C[Failure]</code></pre> <p>Though a failure may happen without a fault. </p>"},{"location":"402/Intro%20to%20Software%20Quality/#confirmation","title":"Confirmation","text":""},{"location":"402/Intro%20to%20Software%20Quality/#validation","title":"Validation","text":"<p>(Most of) testing can't help with this. Some limited testing can be done through acceptance testing.</p> <p>Validations is about building the right system. Rightness is discovered by communication with client and evaluating whether or not they are getting what they have asked for. This is approximated by acceptance testing. </p>"},{"location":"402/Intro%20to%20Software%20Quality/#verification","title":"Verification","text":"<p>Testing can help with this. Are we building what we've specified?</p> <p>We can have a high quality system through verifying it as best as possible, but it may not be useful. That is the realm of validation - ensuring that we build the right thing.</p>"},{"location":"402/Intro%20to%20Software%20Quality/#approaches-to-verification","title":"Approaches to Verification","text":""},{"location":"402/Intro%20to%20Software%20Quality/#testing","title":"Testing","text":""},{"location":"402/Intro%20to%20Software%20Quality/#static-analysis","title":"Static Analysis","text":"<p>Verifying with out running the code. We can explore the system for faults by  looking at the code itself. </p>"},{"location":"402/Intro%20to%20Software%20Quality/#code-inspection","title":"Code Inspection","text":"<p>When we as a group or individually review our code.</p>"},{"location":"402/Intro%20to%20Software%20Quality/#formal-proof","title":"Formal Proof","text":"<p>Using math.</p>"},{"location":"402/Intro%20to%20Software%20Quality/#testing-motivations","title":"Testing Motivations","text":""},{"location":"402/Intro%20to%20Software%20Quality/#what-is-testing-and-why-do-we-test","title":"What is testing and why do we test?","text":"<p>Running the program with some data.</p> <p>It helps: - give us some confidence about the system - think about the software in terms of concrete behaviour - help reveal failures - help assess quality through verification - learn how the program behaves</p> <p>Testing does not necessarily reveal correctness, because it is possible we have programmed the system incorrectly. </p>"},{"location":"402/Intro%20to%20Software%20Quality/#what-do-we-test","title":"What do we test?","text":"<p>We may want to investigate many things through testing: - functionality - performance - robustness and reliability - security - usability</p>"},{"location":"402/Intro%20to%20Software%20Quality/#unit-testing","title":"Unit testing","text":"<p>Testing small individual units of code.</p>"},{"location":"402/Intro%20to%20Software%20Quality/#integration-testing","title":"Integration testing","text":"<p>Testing more than one thing and their interactions.</p>"},{"location":"402/Intro%20to%20Software%20Quality/#system-testing","title":"System testing","text":"<p>Typically from the users point of view, these tests should exercise the whole system.</p>"},{"location":"402/Intro%20to%20Software%20Quality/#acceptance-testing","title":"Acceptance testing","text":"<p>Involve the customer to see if we built what they wanted. </p>"},{"location":"402/Intro%20to%20Software%20Quality/#regression-testing","title":"Regression testing","text":"<p>Checking to see if our changes broke anything.</p>"},{"location":"402/Intro%20to%20Software%20Quality/#where-do-we-test","title":"Where do we test?","text":"<p>Alpha testing is done within the company and beta testing is done outside of the company. </p> <p></p>"},{"location":"402/Intro%20to%20Software%20Quality/#how-do-we-select-good-tests","title":"How do we select good tests?","text":"<p>We prioritize: - can it find a bug? - can it find severe issues? - can it find common problems? - does it find distinct issues?</p>"},{"location":"402/Intro%20to%20Software%20Quality/#how-do-we-know-when-were-done","title":"How do we know when we're done?","text":"<p>We can use coverage criteria to get an idea of our doneness - although it has to be taken with a grain of salt because acheiving 100% may not be a good goal.</p> <p>We can pursue: - statement coverage - branch coverage - condition coverage - etc...</p>"},{"location":"402/Intro%20to%20Software%20Quality/#when-can-we-stop","title":"When can we stop?","text":"<p>When we're out of time, budget or resources. When we've met our goals. Based on statistical or historical guidance. </p>"},{"location":"402/Intro%20to%20Software%20Quality/#what-are-practical-concerns-with-testing","title":"What are practical concerns with testing?","text":"<ul> <li>race conditions</li> <li>human behaviour</li> <li>performance bottlenecks</li> <li>physical resource issues</li> </ul>"},{"location":"402/Measurement/","title":"Index","text":""},{"location":"402/Measurement/#title-measurement","title":"title: Measurement","text":"<p>Measurements provide ideas about the current state of quality in a system, and can help inform decisions about investing more or less in quality.</p> <p>However, it's not always easy to measure, and the measurements may not be as objective as we would like.</p>"},{"location":"402/Measurement/#measurement","title":"Measurement","text":"<p>What is this dang thing?</p> <p>Info and data go in, and a number comes out. This number reflects some aspect of the system.</p>"},{"location":"402/Measurement/#why-do-we-care","title":"Why do we care?","text":"<p>Helps us to:</p> <ul> <li>fund the project by understanding resourcing to deliver our desired quality.</li> <li>conduct more testing when we have identified a weakness in our robustness.</li> <li>focus on performance when we the system isn't fast enough.</li> </ul>"},{"location":"402/Measurement/#building-measures","title":"Building measures","text":"<ul> <li>Decide on the measure. (what thing to measure)</li> <li>Operationalize the measure (figure out how to measure the thing)</li> <li>Implement the measure (measure the thing)</li> <li>Validate the measure (are we measuring the right thing)</li> </ul>"},{"location":"402/Measurement/#goal-question-metric","title":"Goal Question Metric","text":"<p>This is an algorithm for finding things to measure based on goals -&gt; questions -&gt; metrics.</p> <p>Goals and questions provide a kind of parent/child way of distilling some more granular questions from the bigger level goals. From the question, we can find metrics that can be used to measure the question. Goals may share questions and questions may share metrics.</p>"},{"location":"402/Measurement/#operationalize-implement","title":"Operationalize &amp; Implement","text":"<p>This is usually automated and may be a part of the CI process.</p>"},{"location":"402/Measurement/#validate","title":"Validate","text":"<p>Different types of measures to have to validate:</p> <ul> <li>quantitative</li> <li>ratio: size, time, cost</li> <li>interval: termpature, marks,</li> <li>qualitative</li> <li>ordinal: complexity classes</li> <li>nominal: feature availability</li> </ul> <p>Construct validity: are we measuring what we intended to measure? Predictive validity: can the measure tell us something about some other measure? External validity: can we generalize the measure to other systems?</p>"},{"location":"402/Measurement/#problems","title":"Problems","text":"<p>Correlation Confounding variables</p>"},{"location":"402/Measurement/#maintainability-indices","title":"Maintainability Indices","text":"<p>These are proprietary ways of calculating how maintainable a project.</p> \\[ MI = MAX(0, (171 - 5.2 \\times \\log*{10}(HalsteadVolume) - 0.23 \\times CyclomaticComplexity - 16.2 \\times \\log*{10}(LOC)) \\* 100 / 171) \\] <p>These measures are dated and based on older studies, so their relevance may be out of touch.</p>"},{"location":"402/Measurement/#halstead-volume","title":"Halstead Volume","text":"<p>This attempts to approximate the size and complexity of the program.</p> \\[ Halstead Volume = Num of Operators + Num of Operands \\times \\log_2(Distinct(Num of Operators + Num of Operands)) \\]"},{"location":"402/Measurement/#cyclomatic-complexity","title":"Cyclomatic Complexity","text":"<p>Cyclomatic complexity gives a measure of the number of independent paths through a program.</p> \\[ Cyclomatic Complexity = edges - nodes + 2 \\* endpoints \\]"},{"location":"402/Performance/","title":"Performance","text":"<ul> <li>Performance</li> <li>KPI</li> <li>performance testing<ul> <li>baseline testing</li> <li>load testing</li> <li>stress testing</li> <li>soak testing</li> <li>spike testing</li> </ul> </li> <li>process</li> <li>profiling</li> <li>code review</li> </ul>"},{"location":"402/Performance/#performance-kpis","title":"Performance KPIs","text":""},{"location":"402/Performance/#service-oriented","title":"Service-oriented","text":""},{"location":"402/Performance/#availability","title":"Availability","text":"<p>Making sure the application is up and running, and available to users.</p>"},{"location":"402/Performance/#response-time","title":"Response Time","text":"<p>How long it takes the application to respond to a user request.</p>"},{"location":"402/Performance/#efficiency-oriented","title":"Efficiency-oriented","text":""},{"location":"402/Performance/#throughput","title":"Throughput","text":"<p>Number of events that can be processed in a given time.</p>"},{"location":"402/Performance/#capacity-utilization","title":"Capacity Utilization","text":"<p>How much of a resource is being used.</p>"},{"location":"402/Performance/#performance-tests","title":"Performance Tests","text":""},{"location":"402/Performance/#baseline-testing","title":"Baseline Testing","text":"<p>Tests that get a baseline idea of how the system performs under normal conditions.</p>"},{"location":"402/Performance/#load-testing","title":"Load Testing","text":"<p>Applying heavier loads to the system to see how it performs.</p>"},{"location":"402/Performance/#stress-testing","title":"Stress Testing","text":"<p>Applying loads to the system that are heavier than what it can handle. Tends to be about searching for the limit or range in which things come apart.</p> <p>May also include extended testing for robustness and ability to recover from error.</p>"},{"location":"402/Performance/#soak-testing","title":"Soak Testing","text":"<p>Long term testing.</p>"},{"location":"402/Performance/#spike-testing","title":"Spike Testing","text":"<p>Applying sudden spikes of load.</p>"},{"location":"402/Performance/#process","title":"Process","text":"<ol> <li>Decide on the testing environment.</li> <li>may want to model after production, or consider the meaning of the tests      if conducted in a sub-production environment.</li> <li>Identify performance metrics.</li> <li>decide which of the KPIs you want to investigate.</li> <li>Plan and design performance tests (considering different user types, data, scenarios, etc.).</li> <li>check an endpoint</li> <li>build a flow. log in, find something, add to cart, check out.</li> <li>Configure the test environment.</li> <li>automate set up and teardown</li> <li>Implement the tests.</li> <li>Execute the tests.</li> <li>Analyze results, report findings, and retest as needed.</li> <li>may not have clear pass/fail findings and may need further analysis to      determine the meaning of the results.</li> </ol>"},{"location":"402/Performance/#profiling","title":"Profiling","text":"<p>We can collect additional information during runtime to help analyze the performance of a program including the amount of time spent in certain classes/methods/functions, and the number of instances of classes that are created.</p>"},{"location":"402/Performance/#performance-code-review","title":"Performance Code Review","text":"<p>The team can have an eye on performance during code review to look out for common performance problems:</p> <ul> <li>inefficient algorithms</li> <li>slow data structures</li> <li>bad cachine techniques</li> <li>missed parallelism opportunities</li> </ul>"},{"location":"402/Security/","title":"Security","text":""},{"location":"402/Security/#information-security-aspects","title":"Information Security Aspects","text":"<ul> <li>Confidentiality</li> <li>make sure that other people can't see stuff they shouldn't see.</li> <li>Integrity</li> <li>make sure that data is what it's supposed to be and hasn't been tampered with.</li> <li>Availability</li> <li>users can get the data</li> <li>Authentication</li> <li>make sure you know who is who. don't confuse someone for anyone else.</li> <li>Non-repudiation</li> <li>make sure you know who did what.</li> <li>Authorization</li> <li>make sure users can only do what they are supposed to be able to do.</li> </ul>"},{"location":"402/Security/#microsoft-security-practices","title":"Microsoft Security Practices","text":"<ol> <li> <p>Train employees</p> </li> <li> <p>people are huge attack surface. make sure they have appropriate training.</p> </li> <li> <p>Define Security Requirements</p> </li> <li> <p>evalute the combination of security aspects and business requirements to   decide what your security requirements will be.</p> </li> <li> <p>Define Metrics &amp; Compliance Reporting</p> </li> <li> <p>figure out how to define priorities.</p> </li> <li>set up compliance rules around actions to take</li> <li> <p>e.g. all critical bugs must be fixed in 8 hours.</p> </li> <li> <p>Perform Threat Modeling</p> </li> <li> <p>brainstorming security problems, triaging, and plans</p> </li> <li> <p>Microsoft follows their STRIDE process for this process.</p> </li> <li> <p>Establish Design Requirements</p> </li> <li> <p>how to deal with cryptography</p> </li> <li>how to deal with authentication</li> <li>how to deal with authorization</li> <li> <p>how to deal with logging</p> </li> <li> <p>Define and Use Cryptography Standards</p> </li> <li> <p>pick a standard that meets your needs. choosing a weak standard will   be catastrophic.</p> </li> <li> <p>Manage the Security Risk of Using Third-Party Components</p> </li> <li> <p>third party components are another attack surface. checks for vulnerabilities   and keep things up to date.</p> </li> <li> <p>Use Approved Tools</p> </li> <li> <p>unapproved tools are an attack surface</p> </li> <li> <p>Perform Static Analysis Security Testing (SAST)</p> </li> <li> <p>linting for security problems</p> </li> <li>follow secure coding standards</li> <li> <p>security code review</p> </li> <li> <p>Perform Dynamic Analysis Security Testing (DAST)</p> </li> <li> <p>fuzz testing</p> </li> <li> <p>Perform Penetration Testing</p> </li> <li> <p>have third party testers try to break the system.</p> </li> <li> <p>Establish a Standard Incident Response Process</p> </li> <li> <p>emergency response plan.</p> </li> </ol>"},{"location":"402/Security/#stride","title":"STRIDE","text":"<p>Microsoft's own threat modeling process reviews several different threats.</p> <p>(S)poofing, (T)ampering, (R)epudiation, (I)nformation Disclosure, (D)enial of Service, (E)levation of Privilege</p> <ul> <li>Spoofing: trying to impersonate someone else. (attack on authentication)</li> <li>Tampering: trying to change data (attack on integrity)</li> <li>Repudiation: trying to deny that you did something (attack on non-repudiation)</li> <li>Information Disclosure: trying to get information you shouldn't have (attack on   confidentiality)</li> <li>Denial of Service: trying to make a service unavailable (attack on   availability)</li> <li>Elevation of Privilege: trying to get access to something you shouldn't have   (attack on authorization)</li> </ul> <p>STRIDE threat modeling uses a five step process to discover threats,</p> <ol> <li>Identify Security Objectives</li> <li>brainstorm what you must protect, what you must comply with, what you      must follow.</li> <li>can think in lense of STRIDE, or in terms of the security aspects and how      aspects of your application may be vulnerable to attacks from them.</li> <li>Create data flow diagram</li> <li>consider how data moves through your system</li> <li>model as a flowchart</li> <li>to be used as a tool to find possible threat vectors</li> <li>Identify threats</li> <li>make a list of threats</li> <li>Annotate threats</li> <li>organize threats with STRIDE category and mitigation strategy per threat.</li> <li>Rate threats</li> <li>determine how to rank what you should work on</li> <li>could use high, medium, low</li> <li>could use DREAD</li> </ol>"},{"location":"402/Security/#dread","title":"DREAD","text":"<p>A rating system for 5 different aspects of a threat and a value of high, medium, or low.</p> <ul> <li>Damage potential</li> <li>how bad will it be?</li> <li>Reproducibility</li> <li>will it happen every time you do it?</li> <li>Exploitability</li> <li>how easy is it to do?</li> <li>Affected users</li> <li>how many people will be affected?</li> <li>Discoverability</li> <li>how well known is it?</li> </ul>"},{"location":"402/Security/#secure-design-principle","title":"Secure Design Principle","text":"<ul> <li>Minimize Attack Surface</li> <li>anything that an attacker can interface with</li> <li>Establish secure defaults</li> <li>ensure that defaults are provided and are a secure choice</li> <li>Least Privilege</li> <li>users should only have the minimum privileges necessary to do their job</li> <li>Defense in Depth</li> <li>provide multiple layers of security</li> <li>Fail Securely</li> <li>on failure, don't reveal anything more than necessary. give as little as     possible.</li> <li>Separation of Duties</li> <li>use roles to split up user groups for different types of authorizations</li> <li>Avoid Security by Obscurity</li> <li>just hiding something won't stop someone from finding it.</li> <li>Keep Security Simple</li> <li>a complicated security architecture is easy to introduce bugs into</li> <li>Fix root causes</li> <li>research and fix issues at the root to ensure a proper fix</li> </ul>"},{"location":"402/Software%20Quality/","title":"Software Quality","text":"<p>There are several frameworks that define many quality characteristics that can be used to talk about quality. </p>"},{"location":"402/Software%20Quality/#boehm","title":"Boehm","text":""},{"location":"402/Software%20Quality/#mccall","title":"McCall","text":""},{"location":"402/Software%20Quality/#25010","title":"25010","text":""},{"location":"402/Static%20Analysis/","title":"Static Analysis","text":"<ul> <li>[ ] Static Analysis</li> <li>[x] dynamic verification vs static verification<ul> <li>[x] pro / con</li> </ul> </li> <li>[x] for any interesting property Pr...</li> <li>[ ] types<ul> <li>[x] control-flow analysis</li> <li>[x] data-flow analysis</li> <li>[x] typestate analysis</li> <li>[x] type checking</li> </ul> </li> <li>[x] IRs</li> <li>[x] data flow<ul> <li>[x] constant prop</li> <li>[x] taint analysis</li> </ul> </li> <li>[x] trade offs<ul> <li>[x] inter vs intra</li> <li>[x] context sensitivity</li> <li>[x] aliasing</li> </ul> </li> <li>[ ] tools</li> </ul>"},{"location":"402/Static%20Analysis/#dynamic-vs-static","title":"Dynamic vs Static","text":"<p>The first types of tests we looked at in the course focused on dynamic verification where we used a live system and moved it in and out of certains states to see what would happen to it and if it met assertions that we set.</p> <p>Static analysis does not involve running the program, but instead looks at what the code might do from examining it. This includes some previously discussed topiocs like code reviews, walkthroughs, and inspections, but typically we are discussing automated static analysis.</p> Static Verification Tools Dynamic Verification Tools \u274c Having a precise &amp; sound static analysis is hard/expensive \u274c Run-time overhead \u2705 Relatively cheap when compared to running thousands of tests \u274c Depends on the quality of inputs \u274c Can have false positives \u2705 Usually precise \u2014 an observed failure is a failure \u274c Can have false negatives"},{"location":"402/Static%20Analysis/#undecidability-of-static-analysis","title":"Undecidability of Static Analysis","text":"<p>A problem with static analysis is that for anything interesting that you might want to examine, it's impossible to write some analysis that would work for every program. This means that we tend to approximate the analysis to make it work.</p>"},{"location":"402/Static%20Analysis/#code-representation","title":"Code Representation","text":"<p>Source code is too verbose and too plain English to be able to analyze it directly. The code must be converted into one or more intermediate representations (IRs) that are more machine friendly for analysis.</p> High-Level IR Low-Level IR language-specific language-independent machine-independent machine-specific tree/graph instruction sequence control-flow gotos compound expressions simple expressions high-level constructs expanded constructs"},{"location":"402/Static%20Analysis/#abstract-syntax-tree","title":"Abstract Syntax Tree","text":"<p>The code is modelled as a tree.</p>"},{"location":"402/Static%20Analysis/#3-address-code","title":"3-Address Code","text":"<p>This version looks a lot closer to assembly code. Three addresses is representative of two operands and the result.</p>"},{"location":"402/Static%20Analysis/#control-flow-graph","title":"Control Flow Graph","text":"<p>The code is modeled as a graph where each edge is usually some conditional branching, and each node is a block of code or a single instruction.</p>"},{"location":"402/Static%20Analysis/#static-analysis-types","title":"Static Analysis Types","text":""},{"location":"402/Static%20Analysis/#control-flow-analysis","title":"Control-Flow Analysis","text":"<p>This uses a control flow graph created from the source code or partially compiled code and analyses all of the paths through the code.</p> <p>It can't distinguish between different paths that could be exclusive under examination. if(p) and if(!p) would clearly be exclusive, but the analysis could not know what p will resolve to.</p> <p>This can lead to some problems with false positives.</p> <p>Graphs can be unsound if they don't include all paths such as those that occur with exceptions.</p>"},{"location":"402/Static%20Analysis/#data-flow-analysis","title":"Data-Flow Analysis","text":"<p>Here we can analyze the flow of values through the code.</p> <p>Constant propagation can be used to promote values further in the code when there is no interceding logic that may affect the value. This could be applied in dead code elimination to propagate a value forward to the point that it is used in a conditional that would clearly never run it's body.</p> <p>Taint analysis involves sources and sinks. Sources generate some value that could be problematic if it arrives at a sink. We need to be sure to sanitize values from sources before they reach sinks. This can be a common concern in security when handling passwords, or receiving user input. A common problem in this domain is SQL injection where user input is not properly sanitized.</p> <p>Data flow analysis helps us find unused variables, uninitialized variables, and variables reassigned before being used.</p>"},{"location":"402/Static%20Analysis/#typestate-analysis","title":"Typestate Analysis","text":"<p>Checks for valid sequences of operations are made on an object.</p>"},{"location":"402/Static%20Analysis/#type-checking","title":"Type Checking","text":"<p>Check for mismatches in expected types.</p>"},{"location":"402/Static%20Analysis/#trade-offs","title":"Trade Offs","text":"<p>The complexity of static analysis increases as the scope of what is being included increases. If we analyze a singular function, then we can be very fast and precise.</p> <p>If we analyze the whole program, we can see more interactions between classes, methods, and functions, but it comes at a greater cost for the analysis.</p> <p>We refer to this local view as intra-procedural analysis and the wider view as inter-procedural analysis.</p> <p>Context sensitive analysis includes temporal coupling to remember when a method was called versus context insensitive analysis which does not remember the context of the call.</p> <p>Aliasing is required to know about variable or reference renaming.</p>"},{"location":"402/Technical%20Debt/","title":"Technical Debt","text":"<p>- - Technical Debt   - cruft   - non debt   - types of debt   - management   - SQALE   - calculating   - non-remediation costs</p> <p>While building a project and satisfying the functional requirements, we may have let things slide on the non-functional side. This accruing mass of is referred to as technical debt.</p> <p>Technical debt tends to have a multiplicate effect on efforts to remediate it, the longer that it is put off.</p> <p>Future development can also be impacted by technical debt, as poorly constructed systems may take longer to build a feature in versus a well-constructed system.</p> <p>The feature backlog, or anything else that you want to extend the system with are not considered techncial debt.</p> <p>Some debt is intentional when a compromise is made to save on time or money, but some debt is unintentional when we perform unknowingly low quality work.</p>"},{"location":"402/Technical%20Debt/#how-to-manage-this-dang-debt","title":"How to manage this dang debt?","text":""},{"location":"402/Technical%20Debt/#sqale-model","title":"SQALE Model","text":"<p>Pairs up the quality values we know and love with some metrics.</p> <p>SCALE really likes this stack and supposes that each one builds on the other.</p> <pre><code>Reusability\n-----------------\n    Portability\n---------------------\n        Maintainability\n-------------------------\n            Security\n-----------------------------\n                Usability\n---------------------------------\n                    Efficiency\n-------------------------------------\n                        Changeability\n-----------------------------------------\n                            Reliability\n---------------------------------------------\n                                Testability\n</code></pre> <p>Each of this quality characteristics may have many sub-characteristics which can have a requirement upon the source code to be measured.</p> <p>We typically focus on remediation costs for things that we know how to fix. Trying to calculate non-remediation, which is basically the future cost of not fixing it now, is much harder to calculate (and kind of the more interesting dimension).</p>"},{"location":"402/Technical%20Debt/#sonar","title":"Sonar","text":"<p>SonarQube gives you remediation costs for technical debt.</p>"},{"location":"402/Test%20Driven%20Development/","title":"Test Driven Development","text":"<p>Changes the paradigm from direct implementation to preparing tests before  the implementation code. </p> <ul> <li>[ ] Red-Green-Refactor<ul> <li>Write a failing test</li> <li>Write the minimum amount of code to pass the test</li> <li>Refactor the code</li> </ul> </li> </ul> <p>Since there is no implementation to write tests for, the only thing that we can use to write the tests is the requirements. This means our TDD test writing process may more closely align with the requirements than writing tests in a white box manner where we have intimate knowledge of the code. </p> <p>Writing a test first, gives us a client of that code. It gives us an idea of how we'll need to interact with the code to be able to use it. It gives us documentation of how to do that. What it takes to provide pre-conditions before you can use your class or method. </p> <p>You get faster feedback with each testing cycle rather than writing a large chunk of untested code and testing it at the end.</p> <p>You'll have to think about coupling because it may be difficult for you to test your class if it depends on too much which may be a hint to refactor.</p>"},{"location":"402/Test%20Driven%20Development/#what-does-the-research-say","title":"What does the research say?","text":"<p>Mixed. Some studies show that TDD can give code with less defects, and less time spend debugging. Other studies show no difference in code quality.</p> <p>Benefit may not result from the tests themselves, but the process surrounding writing the tests - a slow, methodical approach to converting requirements into code.</p>"},{"location":"402/Test%20Smells/","title":"Test Smells","text":"<p>Tests have a familiar set up.</p> <ol> <li>Arrange (fixtures, mocks, etc.)</li> <li>Act (run the test)</li> <li>Assert (check the results)</li> </ol> <p>Fixtures can be shared between tests for the arrange phase when there is common setup to be performed.</p>"},{"location":"402/Test%20Smells/#test-code-duplication","title":"Test Code Duplication","text":"<p>This is a violation of DRY in test code.</p>"},{"location":"402/Test%20Smells/#test-logic-in-production","title":"Test Logic in Production","text":"<p>Instead of using a test object like a stub, mock or double. The production code is directly modified with a \"feature flag\" approach for testing.</p>"},{"location":"402/Test%20Smells/#erratic-tests","title":"Erratic Tests","text":"<p>Tests should be deterministic. If the test depends on something that may not always provide the same response, then the test may fail intermittently.</p>"},{"location":"402/Test%20Smells/#resource-optimism","title":"Resource Optimism","text":"<p>Depending on external resources will have non-deterministic results depending on when and where the test is executed. On a different day, at a different time.  On a CI environment, on a local environment. </p>"},{"location":"402/Test%20Smells/#obscure-tests","title":"Obscure Tests","text":"<p>This is a test that is hard to understand what is going on. There may be overwhelming complication in the arrange, act or assert stages. </p>"},{"location":"402/Test%20Smells/#assertion-roulette","title":"Assertion Roulette","text":"<p>When it's hard to determine which assertion failed in a test. </p>"},{"location":"402/Test%20Smells/#condition-logic-in-test","title":"Condition Logic in Test","text":"<p>A test should do one thing, and if there is conditional logic inside the test it may be trying to do too much, and it may be hard to get consistent results from a test that does things differently depending on its inputs.</p>"},{"location":"402/Test%20Smells/#slow-tests","title":"Slow Tests","text":"<p>These just reduce the productivity of the team.</p>"},{"location":"402/Test%20Smells/#mystery-guest","title":"Mystery Guest","text":"<p>When we make use of test fixtures and @BeforeTest annotations, they can hide  errors in the system because part of the work is done outside of the test.</p>"},{"location":"402/Test%20Smells/#test-run-war","title":"Test Run War","text":"<p>Race conditions between tests running at the same time due to parallelism, or multiple actors executing the test suite.</p>"},{"location":"402/Test%20Smells/#general-fixture","title":"General Fixture","text":"<p>A fixture has been set up to be shared between tests but it does too much to try to cover all the cases, and that means that it can take too long to set it up.</p>"},{"location":"402/Test%20Smells/#lazy-test","title":"Lazy Test","text":"<p>Not sure where the name comes from, but this is when there are multiple tests that use the same fixture to test the same method.</p>"},{"location":"402/Test%20Smells/#indirect-testing","title":"Indirect Testing","text":"<p>Test invokes another test.</p>"},{"location":"402/Test%20Smells/#sensitive-equality","title":"Sensitive Equality","text":"<p>When comparing things, we should have a very clear, reususable, and robust  equivalence mechanism. Relying on something like <code>toString()</code> could be very brittle since the underlying string serialization could change.</p>"},{"location":"402/Testing%20Distributed%20Systems/","title":"Testing Distributed Systems","text":""},{"location":"402/Testing%20Distributed%20Systems/#reliability-measures","title":"Reliability measures","text":"<p>We define several metrics for reliability to understand our system reliability.</p>"},{"location":"402/Testing%20Distributed%20Systems/#mean-time-to-failure-mttf","title":"Mean Time to Failure (MTTF)","text":"<p>This stat is the least relevant to distributed systems because for the most part we can repair it and return it to service. It is more meant for systems that have a single lifetime. We sum those lifetimes and divide by the number of systems.</p> \\[ \\text{MTTF} = \\frac{\\sum \\text{Lifetime}}{\\text{Number of Systems}} \\]"},{"location":"402/Testing%20Distributed%20Systems/#mean-time-between-failures-mtbf","title":"Mean Time Between Failures (MTBF)","text":"<p>This is the average time between failures. It is the sum of the total  operational time less the downtime divided by the number of failures.</p> \\[ \\text{MTBF} = \\frac{\\text{Total Operational Time} - \\text{Downtime}}{\\text{Number of Failures}} \\]"},{"location":"402/Testing%20Distributed%20Systems/#mean-time-to-recover-mttr","title":"Mean Time to Recover (MTTR)","text":"<p>Average time that the repairs take.</p>"},{"location":"402/Testing%20Distributed%20Systems/#mean-time-to-resolve-mttr","title":"Mean Time To Resolve (MTTR)","text":"<p>Average time to fix and make sure it never happens again. </p>"},{"location":"402/Testing%20Distributed%20Systems/#robustness","title":"Robustness","text":"<p>How systems fail is very important. If we take a system like an elevator, when  it fails we want to ensure that the system has measures to prevent a  catastrophy, and can hopefully recover from the failure. </p> <p>In a way, this sets up stages of failiure where we can provide degraded service rather than no service at all. </p>"},{"location":"402/Testing%20Distributed%20Systems/#testing-dependent-systems","title":"Testing Dependent Systems","text":"<p>Coupled systems are hard to test because they rely on each other. We can make some tests that exercise large chunks of the system but those integration or system tests take much longer to run. </p> <p>We can get some ideas about how things would work together by simulating some part of the system.</p>"},{"location":"402/Testing%20Distributed%20Systems/#test-doubles","title":"Test Doubles","text":"<p>We use alternatives to the real thing where they are unavailable, expensive, opaque, or non-deterministic. </p>"},{"location":"402/Testing%20Distributed%20Systems/#stubs-data","title":"Stubs (data)","text":"<p>Provides some fake data that represents what a real provider would give us.</p>"},{"location":"402/Testing%20Distributed%20Systems/#mocks-behaviour","title":"Mocks (behaviour)","text":"<p>Begins as a blank copy of some kind of object and we configure it to behave in certain ways. </p>"},{"location":"402/Testing%20Distributed%20Systems/#fakes-databehaviour","title":"Fakes (data/behaviour)","text":"<p>Like a mock but with some real implementation. Provides some part of a real interface that it is faking, but does so through some simplified means.</p>"},{"location":"402/Testing%20Distributed%20Systems/#chaos-engineering","title":"Chaos Engineering","text":"<p>It's difficult to design test cases that can properly provide info that your system is robust - you may need to be playing with real world conditions to understand how your system performs. Testing up to this point has been  conducted in a controlled environment with unit, integration and system tests, but how will it perform in a live scenario?</p>"},{"location":"402/Testing%20Distributed%20Systems/#things-that-we-might-explore","title":"Things that we might explore","text":"<ul> <li>Human error</li> <li>Bottleneck </li> <li>Networking issues</li> <li>Hardware failure</li> <li>Resource exhaustion</li> <li>Improper configuration</li> <li>Environmental issues</li> </ul>"},{"location":"402/Testing%20Distributed%20Systems/#challenges","title":"Challenges","text":"<p>These experiments are likely to run in production. A main concern is minimizing impact to operations so that we can conduct the experiment without sacrificing the whole system.</p> <ul> <li>A/B testing</li> <li>Canary deployment</li> </ul>"},{"location":"402/Testing%20Distributed%20Systems/#purpose","title":"Purpose","text":""},{"location":"402/White%20Box%20Testing/","title":"White Box Testing","text":""},{"location":"402/White%20Box%20Testing/#coverage-subsummation","title":"Coverage subsummation","text":"<p>** INCLUDE DIAGRAM **</p>"},{"location":"402/White%20Box%20Testing/#statement-coverage","title":"Statement coverage","text":"<p>Statement coverage is defined as the number of tested lines divided by the tota number of lines in the code. </p> \\[ \\text{Coverage} = \\frac{\\text{Number of tested lines}}{\\text{Total number of lines}} \\] <p>Statement coverage will not account for branching logic, and it will not test the inner workings of conditional statements. It's the most primitive form of coverage. </p>"},{"location":"402/White%20Box%20Testing/#branch-coverage","title":"Branch coverage","text":"<p>Branch coverage is defined as the number of branches that have been tested  divided by the total number of branches in the code.</p> \\[ \\text{Coverage} = \\frac{\\text{Number of tested branches}}{\\text{Total number of branches}} \\] <p>Branch coverage subsumes statement coverage. </p>"},{"location":"402/White%20Box%20Testing/#condition-coverage","title":"Condition coverage","text":"<p>Condition coverage involves testing each condition individually to a true and false state. </p> \\[ \\text{Coverage} = \\frac{\\text{Number of boolean states tested for each condition}}{\\text{Total number of conditions} * 2} \\] <p>Since they are varied separately, the whole impact on the predicate is not  fully tested. Because of this, condition coverage does not subsume branch coverage, or statement coverage. </p> <p>For example,</p> <pre><code>if (a === 42 &amp;&amp; b === 42) {\n  // true\n} else {\n  // false\n}\n</code></pre> <p>We can apply full condition coverage with test cases of: -  <code>a = 42</code>, <code>b != 42</code> -  <code>a != 42</code>, <code>b = 42</code></p> <p>This will test each condition in the predicate, but it will not test the combination of the conditions. Further, it won't provide branch coverage as both test cases resolve to a false predicate.</p>"},{"location":"402/White%20Box%20Testing/#branch-and-condition-coverage-decision-coverage","title":"Branch and Condition coverage (Decision coverage)","text":"<p>This basically combines condition coverage and branch coverage. Define enough test cases so that each condition has been tested to both true and false, and each branch has been tested.</p>"},{"location":"402/White%20Box%20Testing/#modified-conditiondecision-coverage-mcdc","title":"Modified Condition/Decision Coverage (MC/DC)","text":"<p>This is a variation on condition coverage where we test important combinations of the conditions so that the whole predicate is tested. There is a weak form and a strong form of MC/DC. </p> <p>The algorithm for MC/DC is as follows:</p> <ol> <li>Sketch out a truth table with all the conditions and the outcomes.</li> <li>For each condition, vary it while holding the others constant, and inspect   the outcome where it varies from true to false.</li> <li>Note the outcomes where it swaps from T to F.</li> <li>Repeat for each condition.</li> </ol> <p>You need <code>N + 1</code> test cases to test <code>N</code> conditions.</p> <p>MC/DC subsumes branch and condition coverage, condition coverage branch  coverage, and statement coverage. </p>"},{"location":"402/White%20Box%20Testing/#multiple-condition-coverage","title":"Multiple Condition Coverage","text":"<p>A theoretical variant of MC/DC where interdependent reactions betweenconditions are tested.</p>"},{"location":"402/White%20Box%20Testing/#path-coverage","title":"Path Coverage","text":"<p>Path coverage is about walking through all possible paths in the code. At first, glance it doesn't seem to extensive, but the complexities of looping code make it very difficult to achieve. For example, a loop with a termination condition of i &lt;= 20 will have 21 paths to test. Add branching logic, and inner loops, and the number of paths to test can grow exponentially.</p>"},{"location":"402/White%20Box%20Testing/#mutation-testing","title":"Mutation Testing","text":"<p>Mutation testing introduces subtle errors in the production logic. If the  mutants have different test outcomes, then the mutants were removed. If the mutants have the same test outcomes, then the mutant survived. You need to  refactor or add additional tests to remove the mutant. </p> \\[ \\text{Mutation score} = \\frac{\\text{Number of mutants killed}}{\\text{Total number of mutants}} \\] <p>Some mutatations are: - conditional boundarys: changing equality operators - void method call: removes an invocation of a void method - negation: negate any numeric variable </p>"},{"location":"Books/PragmaticProgrammer/chapter1/","title":"Tips","text":"<ol> <li>Care about your craft</li> <li>Think! about your work</li> <li>You Have Agency</li> <li>Provide Options, Don't Make Lame Excuses</li> </ol>"},{"location":"Books/PragmaticProgrammer/chapter1/#challenges","title":"Challenges","text":"<ul> <li>How do you react when someone - such as a bank teller, an auto mechanic, or a clerk - comes to you with a lame excuse? What do you think of them and their company as a result?</li> </ul> <p>At first I find this is okay, but if they don't know what to do after that then I feel like I have to step in (if I can) and help them out. That approach isn't very easy because people often don't like having someone that is outside their professional circle, or below their hierarchy, challenge them.</p> <p>In any case, I can see that in those shoes, it's okay to briefly admit you may not know exactly what to do, but you should have any idea of what you're going to do next. Maybe you need some time to research the topic, or consult with experts. You need to demonstrate that you have a plan..</p> <ul> <li>When you find yourself saying, \"I don't know,\" be sure to follow it up with \"- but I'll find out.\" It's a great way to admit what you don't know, but then take responsibility like a pro.</li> </ul>"},{"location":"Books/PragmaticProgrammer/chapter1/#tips_1","title":"Tips","text":"<ol> <li>Don't Live with Broken Windows</li> </ol>"},{"location":"Books/PragmaticProgrammer/chapter1/#challenges_1","title":"Challenges","text":"<ul> <li>Help strengthen your team by surveying your project neighbourhood. Choose two or three broken windows and discuss with your colleagues what the problems are and what could be done to fix them.</li> </ul> <p>We don't have a lot of strength in testing in certains parts of our code, and we've seen some things go sideways where production deployments have some bugs that might have been caught in a more elaborate test set up. We could probably come up with some sort of E2E testing for our CLI tools so we know they are working well.</p> <p>Another is documentation. Sometimes the code itself is kind of light on comments, and things aren't necessarilly commented at the module or class level. Automatically linting might help a bit here (but might feel forced?), and generally advocating for increased clarity in code.</p> <ul> <li>Can you tell when a window first gets broken? What is your reaction? If it was the result of someone else's decision, or a management edict, what can you do about it?</li> </ul> <p>Sometimes I think my own inner sense of what is right or wrong might throw up a concern when I get a gut feeling on something. I usually think.. \"Oh. That's probably not good, or we should do something different\".</p> <p>When I decide what I want to do about it, I consider my position and my responsibilities - although generally I like to freely share my opinion knowing that they have no obligation to act on it. If there's room for change, then I would want to try to campaign for it.</p> <ol> <li>Be a Catalyst for Change</li> </ol>"},{"location":"Books/PragmaticProgrammer/chapter1/#challenges_2","title":"Challenges","text":""},{"location":"Books/PragmaticProgrammer/chapter1/#_1","title":"Tips","text":"<ol> <li>Remember the Big Picture</li> </ol>"},{"location":"Frameworks/nestjs/","title":"Nestjs","text":""},{"location":"Frameworks/nestjs/#what-is-nestjs","title":"What is Nest.js?","text":"<p>NestJS is a framework for developing server side Node.js applications. </p>"},{"location":"Frameworks/nestjs/#why-nestjs","title":"Why Nest.js?","text":"<p>ExpressJS is a barebones framework for designing server side applications. The way that you build an application in NestJS is opinionated and takes on a particular format. This has some pros in that it gives a consistent structure to an application, but can also be a con as soon as your app deviates from this structure.</p>"},{"location":"Frameworks/nestjs/#app-architecture","title":"App Architecture","text":""},{"location":"Frameworks/nestjs/#controllers","title":"Controllers","text":"<p>Controllers expose routes for the client to connect to the application. The incoming requests are handled by the controller and routed to the appropriate application logic. A controller may have one or more routes.</p>"},{"location":"Frameworks/nestjs/#modules","title":"Modules","text":"<p>Modules are used to modularize your application. You can abstract your application into different modules which helps prevent you from writing a large monolithic application. You end up with smaller and easier to manage modules. </p>"},{"location":"Frameworks/nestjs/#pipes","title":"Pipes","text":"<p>Pipes are used to ensure that the right kind of information is flowing into the application. We can control the flow of information into the application by performing validation and transformation of the data.</p>"},{"location":"Frameworks/nestjs/#decorators","title":"Decorators","text":"<p>Classes, methods and parameters are annotated with decorators to provide metadata to NestJS. </p>"},{"location":"Frameworks/nestjs/#class-level","title":"Class Level","text":"<p><code>@Controller('helloWorld')</code> is an example of a class level decorator. This decorator is used to define a controller. The string passed to the decorator is the route that the controller will be listening on.</p>"},{"location":"Frameworks/nestjs/#method-level","title":"Method Level","text":""},{"location":"Frameworks/nestjs/#parameter-level","title":"Parameter Level","text":""},{"location":"Frameworks/vue/","title":"Vue","text":""},{"location":"Frameworks/vue/#rough-outline","title":"Rough outline","text":"<p>Refine later. Capturing some possible concepts.</p>"},{"location":"Frameworks/vue/#rough-ideas","title":"ROUGH IDEAS","text":"<p>ref attribute: can be added to html elements to reference them in the DOM. We can use these references to access the element in the Vue instance as <code>this.$refs.refName</code>.</p> <p>virtual dom: Vue needs to know when to update the DOM, but reading the whole DOM is expensive. A virtual DOM is maintained by Vue and we compare to an old version of the virtual DOM to see what has changed. Then if differences are detected we update the parts in the real DOM where the change occurred.</p> <p>vue lifecycle hooks</p> <pre><code>graph TD\n    A[\"createApp( ... )\"] --&gt; B[\"beforeCreate()\"]\n    B --&gt; C[\"created()\"]\n    C --&gt; D[\"beforeMount()\"]\n    D --&gt; E[\"mounted()\"]\n    C --&gt; F[Compile template]\n    F --&gt; D\n    E --&gt; G[Mounted Vue Instance]</code></pre> <pre><code>graph TD\n    A[Mounted Vue Instance] --&gt; B[Data Changed]\n    B --&gt; C[\"beforeUpdate()\"]\n    C --&gt; D[\"updated()\"]</code></pre> <pre><code>graph TD\n    A[Mounted Vue Instance] --&gt; B[\"beforeUnmount()\"]\n    B --&gt; C[\"unmounted()\"]\n    C --&gt; D[Instance Unmounted]</code></pre> <p>Stuff to write about: sending info between comoponents parent to child props: child to parent emits: provide/inject:</p> <p>dollar methods $emit: sends an event to the parent component</p> <p>prop fallthrough:</p> <p>binding all props</p> <p>Emitting Passthrough Sometimes the child component may need to communicate to it's ancestor component that is several layers removed. We can use the $emit method to send an event to the parent component and then another event to the parent's parent component and so on.</p> <p>Provide and Inject for Values and Methods As an alternative to manually passing emits up the chain, we can use the provide and inject method to pass values directly from the descdendant to the ancestor. This is helpful because we don't have to worry about the relations inbetween, but it can be difficult to debug because the values are not directly passed.</p> <p>Global vs Local Components Components can be defined and exposed in the main app which makes the available globally everywhere within the hierarchy of the application, but it can be hard for Vue to determine what components are unused via it's \"tree-shaking\" approach. It also makes dependency relationships between components much less explicit which can make it harder for developers to maintain the codebase.</p> <p>Alternatively we can include components locally within the components that use them. This helps address the two issues mentioned above, but it takes away the ease of use that globally defined components provide.</p> <p>Scoped Style Unscoped style is applied globally to any matching tag. We can use the <code>scoped</code> attribute to limit the style to the component that it is defined in.</p> <p>Slots Slots allow us to pass through HTML/Vue content to a component. They are somewhat like a prop, but instead of passing a value, we are passing HTML content.</p> <p>default/named Slot content is automatically targetted to the default slot unless we specify a named slot. In the slot, we can use the <code>v-slot</code> directive, or the shorthand <code>#</code> to specify the slot name.</p> <p>$slots Vue exposes a $slots object that contains the content of the slots. This value can be used programmatically to determine how to render the content.</p> <p>scoped slots Sometimes we will want a way to pass data from the parent component to the slot content. We can use scoped slots to pass data from the parent to the slot content.</p> <p>Dynamic components  tag We can use the <code>&lt;component&gt;</code> tag to dynamically render whatever component we wish to display. This lets us get around a series of v-if statements to determine which component to display. <p> tag The <code>&lt;keep-alive&gt;</code> tag can be used in conjunction with the component tag so that we can keep the component in memory and not have to re-render it every time it is displayed. Without it, the component would be destroyed and recreated every time it is displayed. <p> tag The <code>&lt;teleport&gt;</code> tag allows us to move an element to a different part of the DOM. This can be helpful when we want to render a component in a different part of the DOM than where it is defined. Typically this could be used to help maintain a consistent and semantically correct DOM structure which can be very important to accessibility."},{"location":"Frameworks/vue/#instantiating-a-vue-app","title":"Instantiating a Vue App","text":"<pre><code>const app = Vue.createApp({\n    data() {\n        return {\n        message: 'Hello Vue!'\n        }\n    },\n    methods: {\n        reverseMessage() {\n        this.message = this.message\n            .split('')\n            .reverse()\n            .join('')\n        }\n\n})\n</code></pre> <p>The createApp method takes an object as an argument where it contains the data and methods for the Vue app.</p>"},{"location":"Frameworks/vue/#configuration-options","title":"Configuration Options","text":""},{"location":"Frameworks/vue/#data","title":"data","text":""},{"location":"Frameworks/vue/#methods","title":"methods","text":""},{"location":"Frameworks/vue/#computed","title":"computed","text":"<p>Computed properties can be helpful to limit the amount of logic that is used in our HTML code.&lt;</p>"},{"location":"Frameworks/vue/#watch","title":"watch","text":""},{"location":"Frameworks/vue/#interpolation","title":"Interpolation","text":""},{"location":"Frameworks/vue/#binding-attributes","title":"Binding Attributes","text":""},{"location":"Frameworks/vue/#working-with-data","title":"Working with data","text":""},{"location":"Frameworks/vue/#outputting-html-instead-of-text","title":"Outputting HTML instead of text","text":""},{"location":"Frameworks/vue/#working-with-functions","title":"Working with functions","text":""},{"location":"Frameworks/vue/#referencing-data-in-functions","title":"Referencing data in functions","text":""},{"location":"Frameworks/vue/#functions-and-dom-effect","title":"Functions and DOM Effect","text":"<p>Vue will automatically update the DOM when your data changes, but if you are using functions within your interpolations like <code>{{ foo() }}</code>, then those functions are always reevaluated any time Vue updates the DOM. This is because the data could be potentially have been updated and now the function needs to be reevaluated.</p> <p>We can use computed properties to cache the result of a function and only reevaluate it when the data it depends on changes. We can get better performance in general from using computed properties.</p>"},{"location":"Frameworks/vue/#declarative-vs-imperative","title":"Declarative vs Imperative","text":""},{"location":"Frameworks/vue/#event-object","title":"Event Object","text":""},{"location":"Frameworks/vue/#event-modifiers","title":"Event Modifiers","text":""},{"location":"Frameworks/vue/#stop","title":"stop","text":"<p>Prevents click propagation.</p>"},{"location":"Frameworks/vue/#directives","title":"Directives","text":"<p>Directives are Vue-specific HTML tag attributes. You can add them to an element to apply special behavior to it.</p>"},{"location":"Frameworks/vue/#v-once","title":"v-once","text":""},{"location":"Frameworks/vue/#v-on","title":"v-on","text":"<p>Used to listen to events. Can also connect to specific versions of the events by using modifiers like <code>v-on.keydown.enter</code> or <code>v-on.click.right</code>.</p> <p>There is a shorthand for v-on: <code>@</code>. So <code>v-on:click</code> can be written as <code>@click</code>.</p>"},{"location":"Frameworks/vue/#v-model","title":"v-model","text":"<p>This is a shorthand directive which manages two-way binding on an element so that you can bind a data property and update it when the element changes. It is a combination of <code>v-bind</code> and <code>v-on</code>.</p> <p>Instead of:</p> <pre><code>&lt;input v-bind:value=\"message\" v-on:input=\"message = $event.target.value\" /&gt;\n</code></pre> <p>We can do:</p> <pre><code>&lt;input v-model=\"message\" /&gt;\n</code></pre>"},{"location":"Frameworks/vue/#v-bind","title":"v-bind","text":"<p>Connects to a data property to a DOM attribute.</p> <p>There is a shorthand for v-bind: <code>:</code>. So <code>v-bind:href</code> can be written as <code>:href</code>.</p>"},{"location":"Frameworks/vue/#v-text","title":"v-text","text":"<p>Connects a data property to the inner text of an element. It is similar to <code>{{ }}</code> but it is more explicit.</p>"},{"location":"Frameworks/vue/#v-if","title":"v-if","text":""},{"location":"Frameworks/vue/#v-else","title":"v-else","text":"<p>Has to be used on a direct neighbour of an element that uses the v-if/v-elseif directive.</p>"},{"location":"Frameworks/vue/#v-elseif","title":"v-elseif","text":"<p>Has to be used on a direct neighbour of an element that uses the v-if directive.</p>"},{"location":"Frameworks/vue/#v-show","title":"v-show","text":"<p>Similar to v-if but without the benefit of v-else, v-elseif. This directive hides the element from the DOM versus v-if which has the element not attached to the DOM. Might want to use if you have an element that switches its visibility a lot.</p>"},{"location":"Frameworks/vue/#v-for","title":"v-for","text":"<p>Looping over array</p> <p>Looping over object</p> <p>Looping over range</p>"},{"location":"Frameworks/vue/#use-of-key","title":"Use of key","text":"<p>Vue reuses DOM elements when re-rendering to optimize performance. This can cause unexpected behaviour when adding/removing your data. You should use the key attribute to give a unique value to the element so that Vue knows to keep them separate.</p>"},{"location":"Frameworks/vue/#styling-and-classes","title":"Styling and Classes","text":"<p>Bind a data property to a style with.</p> <pre><code>:style=\"{ color: textColor }\"\n</code></pre> <p>Bind a data property to a class by v-binding to the class attribute and giving it an object, array, or string.</p> <pre><code>:class=\"{ active: isActive }\"\n:class=\"[activeClass, errorClass]\"\n:class=\"{ isSelected ? 'selected' : '' }\"\n</code></pre>"},{"location":"Frameworks/vue/#common-mistakes","title":"Common Mistakes","text":"<p>Forgetting to mount the app to an element in the DOM.</p>"},{"location":"Frameworks/vue/#single-curlies-or-double-curlies","title":"Single Curlies {} or Double Curlies {{}}","text":""},{"location":"Frameworks/vue/#under-the-hood","title":"Under the hood","text":""},{"location":"Frameworks/vue/#element-reuse","title":"Element reuse","text":""},{"location":"Frameworks/vue/#errors","title":"Errors","text":""},{"location":"Infrastructure/Docker/","title":"Docker","text":""},{"location":"Infrastructure/Docker/#useful-commands","title":"Useful commands","text":"<ul> <li> <p><code>docker compose build</code></p> <ul> <li>Description: Builds or rebuilds services defined in a <code>docker-compose.yml</code> file. It does not start the containers after building them.</li> </ul> </li> <li> <p><code>docker compose up -d</code></p> <ul> <li>Description: Starts the containers in detached mode, allowing you to continue using the terminal.</li> <li>Flags:</li> <li><code>-d</code>: Detached mode.</li> </ul> </li> <li> <p><code>docker compose -f docker-compose.dev.yml up --build -d</code></p> <ul> <li>Description: Uses a custom Docker compose file to start the containers, forcing a build of the images before starting, in detached mode.</li> <li>Flags:</li> <li><code>-f</code>: Specifies a custom file (in this case, <code>docker-compose.dev.yml</code>).</li> <li><code>--build</code>: Forces a build of the images.</li> <li><code>-d</code>: Detached mode.</li> </ul> </li> <li> <p><code>docker compose down -v</code></p> <ul> <li>Description: Stops and removes containers, networks, and the default network associated with the composition. Additionally, removes the volumes.</li> <li>Flags:<ul> <li><code>-v</code>: Removes the volumes.</li> </ul> </li> </ul> </li> <li> <p><code>docker compose -f docker-compose.dev.yml down -v</code></p> <ul> <li>Description: Stops and removes containers, networks, and volumes specified in a custom Docker compose file.</li> <li>Flags:</li> <li><code>-f</code>: Specifies a custom file (<code>docker-compose.dev.yml</code>).</li> <li><code>-v</code>: Removes the volumes.</li> </ul> </li> <li> <p><code>docker exec -it django-dev bash</code></p> <ul> <li>Description: Executes an interactive bash shell inside the running container named <code>django-dev</code>.</li> <li>Flags:<ul> <li><code>-it</code>: Interactive terminal.</li> </ul> </li> </ul> </li> <li> <p><code>docker build . -t api</code></p> <ul> <li>Description: Builds a Docker image from the Dockerfile in the current directory, tagging it as <code>api</code>.</li> <li>Flags:<ul> <li><code>-t</code>: Tag the image.</li> </ul> </li> </ul> </li> <li> <p><code>docker run -p 8000:8000 -e DJANGO_SECRET_KEY=$DJANGO_SECRET_KEY api</code></p> <ul> <li>Description: Runs a container from the <code>api</code> image, exposing port 8000 and setting the <code>DJANGO_SECRET_KEY</code> environment variable.</li> <li>Flags:<ul> <li><code>-p 8000:8000</code>: Maps port 8000 of the container to port 8000 on the host.</li> <li><code>-e DJANGO_SECRET_KEY=$DJANGO_SECRET_KEY</code>: Sets an environment variable inside the container.</li> </ul> </li> </ul> </li> <li> <p><code>docker image prune</code></p> <ul> <li>Description Removes dangling images. </li> </ul> </li> </ul>"},{"location":"Languages/Cpp/","title":"C++","text":""},{"location":"Languages/Cpp/#program-compilation","title":"Program Compilation","text":"<pre><code>c++ -o program program.cpp\n</code></pre>"},{"location":"Languages/Cpp/#class-layout","title":"Class Layout","text":"<p>Example show public and private members and methods of a class.</p> <pre><code>class MyClass {\n    public:\n        int publicMember;\n        void publicMethod();\n\n    private:\n        int privateMember;\n        void privateMethod();\n};\n</code></pre>"},{"location":"Languages/Cpp/#datatypes","title":"Datatypes","text":""},{"location":"Languages/Cpp/#strings","title":"Strings","text":"<pre><code>#include &lt;string&gt;\nstd::string myString = \"Hello, World!\";\n</code></pre>"},{"location":"Languages/Cpp/#structs-custom-compound-types","title":"Structs (Custom Compound Types)","text":"<p>It can be helpful to encapsulate related data into a singular container. Structs are a way to build up a custom compound type. We can build deeply nested structures by including structs within structs which allows us to make complex representations. We add instance variables to a struct to create the custom type. We can instantiate a struct by declaring a variable of that type, and access its members/fields/instance variables using the dot operator.</p> <pre><code>struct Person {\n    std::string name;\n    int age;\n    bool isStudent;\n};\n\nPerson person1;\nperson1.name = \"John Doe\";\nperson1.age = 25;\nperson1.isStudent = true;\n\nPerson person2 = {\"Jane Doe\", 23, false}; // Alternative way to initialize\n\nPerson person3 = Person(); // Initialize with default values\nperson3 = {\"Alice\", 30, true}; // BAD!! This form of initialization only works during declaration unless you add a typecast.\nperson3 = (Person){\"Alice\", 30, true}; // GOOD!! This form of initialization works after declaration.\n</code></pre> <p>We can define member functions for structs which can be invoked using the dot syntax.</p> <pre><code>void Person::sayHello() {\n    cout &lt;&lt; \"Hello\";\n}\n\nperson1.hello();\n</code></pre> <p>Classes are basically syntactic sugar to wrap up member properties and methods.</p>"},{"location":"Languages/Cpp/#operators","title":"Operators","text":""},{"location":"Languages/Cpp/#addressing-and-reference-operators","title":"Addressing and Reference Operators","text":"<pre><code>int x = 5;\nint *ptr = &amp;x; // Address of x\nint &amp;ref = x; // Reference to x\nn\n*ptr = 10; // x = 10\nref = 15; // x = 15\n\nstd::cout &lt;&lt; x &lt;&lt; std::endl; // 15\n</code></pre>"},{"location":"Languages/Cpp/#new-operator","title":"New operator","text":"<p>The new operator is used to allocate memory for a new object. It returns a pointer to the object.</p> <pre><code>class MyClass {\n    int value;\npublic:\n    MyClass(int val) : value(val) {}\n    int getValue() { return value; }\n};\n\nMyClass* obj = new MyClass(10);\nstd::cout &lt;&lt; obj-&gt;getValue() &lt;&lt; std::endl; // 10\ndelete obj; // Free memory\n</code></pre> <p>The <code>delete</code> operator must be used when we make allocations with <code>new</code>. This is because the memory is not automatically freed when the object goes out of scope. A few different problems may arise when we have not freed the memory.</p>"},{"location":"Languages/Cpp/#call-by-reference-and-call-by-value-reference-parameters-or-value-parameters","title":"Call by Reference and Call by Value (Reference parameters or value parameters)","text":"<p>Logic and data are often encapsulated by function calls. When we make a function call and pass in params, we are no longer refering to the original values and are now working with copies of those values.</p> <p>We have two approaches we can use when working with function calls. We can work with the value of the passed parameter, or we can use the address of the passed parameter. If we use the address, then we are able to refer to the location of the data from any scope and make changes to it.</p> <p>The below function takes two integers as arguments. When I call <code>add(i, j)</code> the values of i and j are copied into the scope of the function call and we are no longer working with i and j, but a and b.</p> <pre><code>int i = 1;\nint j = 10;\n\nvoid add(int a, int b) {\n    return a + b;\n}\n\nadd(i, j);\n</code></pre> <p>Alternatively, if I modify the argument signature of add(). We can specify that we want to use the addresses of the arguments. The ampersand says, \"can you please get me the address of the variable?\" and then in the body of the function, the asterisk operator says, \"lets use that address reference to get the actual value at that location\".</p> <pre><code>int i = 1;\nint j = 10\n\nvoid add(int &amp;a, int &amp;b) {\n    return *a + *b;\n}\n\nadd(i, j);\n</code></pre>"},{"location":"Languages/Cpp/#vectors","title":"Vectors","text":"<p>We can use vectors to create collections of primitives or objects. Generally, the collection is formed from the same type but you can use polymorphism to store collections of types inheriting from the same ancestry.</p> <p>The <code>apvector</code> header is needed to be able to make a vector of objects. These classes are not generally available and are from some advanced placement CS classes. Will need to find something that is more modern.</p> <pre><code>// not sure but the code to add the vector type to the header\nvector&lt;int&gt; numbers(4); // vector with 4 spots\nnumbers[0] = 123;\nnumbers[1] = 22;\nnumbers[2] = 23;\nnumbers[3] = 69;\nvector&lt;int&gt; twos(4, 2); // vector with 4 spots all filled with 2's.\n\n// make a copy\nvector&lt;int&gt; copyOfNumbers(numbers);\n//or\nvector&lt;int&gt; copyOfNumbers2 = numbers;\n\n// make a vector of objects\napvector&lt;Cards&gt; deck(52);\n</code></pre> <p>We can use <code>vectorname.size()</code> to get the count of items in a vector. We can use <code>vectorname.pushback(object)</code> to add a new item of the same type to the vector.</p>"},{"location":"Languages/Cpp/#objects-with-vectors","title":"Objects with vectors","text":"<p>When we create structs or classes, we may use vectors as member properties.</p> <pre><code>struct Citizen {\n    vector&lt;int&gt; votes (2)\n};\n</code></pre>"},{"location":"Languages/Cpp/#functions","title":"Functions","text":"<p>There are a few different ways of implementing functions that can be helpful to understand the difference about.</p>"},{"location":"Languages/Cpp/#pure-functions","title":"Pure functions","text":"<p>These functions do not modify their arguments, and will alsways return the same thing when given the same arguments.</p> <p>Pure functions are easier to test because of these deterministic pre-conditions.</p>"},{"location":"Languages/Cpp/#modifier-functions","title":"Modifier functions","text":"<p>Typically an argument is passed in by reference so that it can be modified in some way.</p>"},{"location":"Languages/Cpp/#fill-in-functions","title":"Fill in functions","text":"<p>This a more extensive variation of a modifer function, where an empty object is provided (or the expectation that an existing object will be overwritten), and then that object is prepared/filled in the function.</p>"},{"location":"Languages/Cpp/#parameter-notes","title":"Parameter Notes","text":"<p>Something like <code>const vector&lt;Point&gt;&amp; points</code> means that the vector is passed by reference, but the function will not modify the vector.</p> <p>The const keyword is used to indicate that the function will not modify the object, and attempts to will result in a compile time error.</p> <p>The ampersand is used to pass the object by reference, so that the function can refer to the original object.</p>"},{"location":"Languages/Cpp/#objects","title":"Objects","text":""},{"location":"Languages/Cpp/#object-initialization","title":"Object Initialization","text":"<p>I was generally considering only ever using <code>MyObj obj = MyObj()</code> to create my objects, but there are a few different ways to initialize objects. This way is called the <code>copy initialization</code> method. <code>MyObj()</code> creates a temporary object and then the copy constructor is invoked to create the object from the temporary object.</p> <p>There are many alternatives to this, and one of them is direct initialization which would be <code>MyObj obj()</code>.</p>"},{"location":"Languages/Cpp/#lambda-functions","title":"Lambda Functions","text":"<p>Lambda functions are a concise anonymous way to define functions and are used in multiple places as arguments to higher order functions. They are composed of a few pieces.</p> <ul> <li>The capture clause</li> <li>The capture clause defines what is pulled in from the outside scope. There are few syntatical sugar ways of defining a range of things to pull in.<ul> <li><code>[&amp;]</code> - Pull in everything by reference. This is not a pointer though, and is more of an alias to the original object.</li> <li><code>[=]</code> - Pull in everything by value</li> <li><code>[x, &amp;y]</code> - Pull in x by value and y by reference</li> </ul> </li> <li>The parameter list</li> <li>The parameters are defined in the same way as a normal function.</li> <li>The return type (optional)</li> <li>The body</li> </ul> <pre><code># To Write\n- [x] Structs\n- [x] Call by reference, call by value\n- [x] Vectors\n - [x] Vectors of objects\n - [x] Objects with vectors\n- [x] Classes\n- [x] Operators\n- [x] Functions (pure, modifier, fill in)(const params)\n</code></pre>"},{"location":"Languages/Cpp/debug/","title":"Debugging","text":"<p>When using <code>lldb</code> to debug you will need to run the compiler, g++ for me, with the <code>-g</code> flag to include debugging information in the binary.</p> <p>When you then run <code>lldb</code> you can use the <code>run</code> command to execute the binary.</p> <p>After a crash you can use the <code>bt</code> command to get a backtrace of the call stack.</p> <p>If you need to run with arguments you can use the <code>run</code> command with arguments.</p> <p><code>frame select [int]</code> (puts focus on a frame in the stack trace) <code>frame variable --show-types</code> (shows the vars in a frame)</p> <p><code>bt</code> - prints the backtrace <code>breakpoint set --file [filename] --line [lineNumber]</code> <code>breakpoint set --name [functionNameWithClass]</code> <code>breakpoint list</code> <code>step</code> / <code>s</code> - step into function <code>next</code> / <code>n</code> - next line <code>finish</code> / <code>f</code> - step out of func <code>continue</code> / <code>c</code> - go till next breakpoint</p>"},{"location":"Languages/Cpp/headers/","title":"Headers","text":"<p>There are many helpful functions that can be included in a program. </p>"},{"location":"Languages/Cpp/headers/#iostream","title":"iostream","text":"<ul> <li><code>cin</code> - input stream</li> <li><code>cout</code> - output stream</li> </ul>"},{"location":"Languages/Cpp/headers/#data-structures","title":"Data Structures","text":""},{"location":"Languages/Cpp/headers/#vector","title":"vector","text":""},{"location":"Languages/Cpp/headers/#set","title":"set","text":""},{"location":"Languages/Cpp/headers/#algorithms","title":"Algorithms","text":""},{"location":"Languages/Cpp/headers/#find","title":"Find","text":""},{"location":"Languages/Cuda/","title":"Index","text":""},{"location":"Languages/Cuda/#cuda-api","title":"Cuda API","text":"<p>CudaMalloc</p> <ul> <li>takes a pointer to a pointer of memory and the size of the memory to allocate. In the code that we got originally it was cast from something to void. But I came across some online threads talking about not needing to do that in modern CUDA.   CudaMemcpy   CudaFree</li> </ul>"},{"location":"Languages/Cuda/#cudagdb-commands","title":"cudagdb commands","text":""},{"location":"Languages/Cuda/#topics","title":"Topics","text":""},{"location":"Languages/Cuda/#cpu-vs-gpu","title":"cpu vs gpu","text":"<p>The biggest difference that we have is the number of processing units where calculations can be performed and the layout of memory. A modern CPU is more advanced than it's predecessors and has more than one core, but no large amount as it is designed for general purpose, but a GPU has thousands of cores and is designed for performing many parallel computations/instructions.</p> <p>Memory in the CPU is laid out as a cache hierarchy with a few caches. The GPU has a global memory and then shared memory that is shared between threads in a block. There is shared memory that is assigned to each streaming multiprocessor and it is logically subdivided into shared memory for each block.</p>"},{"location":"Languages/Cuda/#gpu-architecture","title":"gpu architecture","text":""},{"location":"Languages/Cuda/#streaming-multiprocessor-sm","title":"Streaming Multiprocessor (SM)","text":""},{"location":"Languages/Cuda/#processing-unit","title":"Processing Unit","text":"<p>A streaming multi processor has multiple streaming processing units that share control logic and an instruction cache. Each processing unit handles a thread, and the thread can handle a single point of data.</p>"},{"location":"Languages/Cuda/#shared-memory","title":"Shared Memory","text":"<p>Eac of the Streaming Multiprocessor units has memory that is assigned to it, and of that memory it is shared between the threads of a block, but not between blocks. The shared memory is faster than the global memory, but is limited in size.</p>"},{"location":"Languages/Cuda/#global-memory","title":"Global Memory","text":"<p>The global memory is the largest memory and is shared between all the streaming multiprocessors. It is the slowest memory.</p>"},{"location":"Languages/Cuda/#threads","title":"Threads","text":"<p>A thread is the smallest unit of execution. Threads are executed on a processing unit in the streaming multiprocessor. Threads are grouped into blocks. Each block shares memory and those threads can communicate with each other via this shared memory.</p>"},{"location":"Languages/Cuda/#blocks","title":"Blocks","text":"<p>A block is a collection of threads. It may be 1,2,3d in dimension. The dimensions tend to correspond to the dimensions of the data that is being processed. A streaming multiprocessor has a maximum number of blocks it may be assigned, and the blocks may be distributed between the SMs at a number up to the maximum number of blocks that may be assigned to the SM.</p>"},{"location":"Languages/Cuda/#grid","title":"Grid","text":"<p>A grid is connected to the kernel. It specifies a 1,2,3d dimension of blocks. It specifies a corresponding logical region in the GPU where the threads will be executed.</p>"},{"location":"Languages/Cuda/#warp","title":"Warp","text":"<p>Warps are another logical subdividing of threads AFTER a block has been assigned to a streaming multiprocessor. Typically the number of streaming processors is less than the number of threads in a block, so the threads are divided into warps. The threads in a warp are executed in lockstep.</p> <p>This was a point of confusion because I had imagined that as soon as a block was assigned to a streaming multiprocessor that they would all be executed together, but they aren't. They are divided into warps and executed depending on the GPU implementation. Some GPUs can process more than one warp at a time.</p> <p>This discrepancy allows for time to latency to be hidden since there is some delay in processing each of the warps. Accesses to global memory can be mitigated since only some of the warps are processed at a time out of the block.</p>"},{"location":"Languages/Javascript/","title":"Index","text":""},{"location":"Languages/Javascript/#arrays","title":"Arrays","text":""},{"location":"Languages/Javascript/#iteration-methods","title":"Iteration methods","text":""},{"location":"Languages/Javascript/#reduce","title":"reduce","text":""},{"location":"Languages/Javascript/#map","title":"map","text":""},{"location":"Languages/Javascript/#filter","title":"filter","text":""},{"location":"Languages/Javascript/#some","title":"some","text":"<p>Some returns true if at least one element in the array passes the test implemented by the provided function.</p> <pre><code>const numbers = [1, 2, 3, 4, 5];\nconst hasEven = numbers.some((number) =&gt; number % 2 === 0);\nconsole.log(hasEven); // true\n</code></pre>"},{"location":"Languages/Javascript/#splice","title":"splice","text":""},{"location":"Languages/Javascript/#operators","title":"Operators","text":""},{"location":"Languages/Javascript/#optional-chaining","title":"? optional chaining","text":"<p>If the method or property accessed does not exist, then <code>null</code> or <code>undefined</code> is returned instead of throwing an error.</p> <pre><code>const person = {\n  name: \"John\",\n  age: 30,\n};\n\nconst city = person.address.city; // Error: Cannot read property 'city' of undefined\n\nconst city = person.address?.city; // null\n</code></pre>"},{"location":"Languages/Javascript/#spread","title":"... spread","text":"<p>The spread operator takes an iterator (such as a string or array), and lets us expand it into individual elements where we can use it in a function that expects zero or more arguments, or where elements are expected.</p> <pre><code>const numbers = [1, 2, 3];\nconst newNumbers = [...numbers, 4];\nconsole.log(newNumbers); // [1, 2, 3, 4]\n</code></pre>"},{"location":"Languages/Javascript/#destructuring","title":"Destructuring","text":"<p>Destructuring allows us to extract multiple properties from an object or multiple elements from an array and assign them to variables.</p> <pre><code>const person = {\n  name: \"John\",\n  age: 30,\n  city: undefined,\n};\n\nconst { name, age, city = \"New York\" } = person; // city is undefined, so we can set a default value\nconsole.log(name, age); // John 30\n</code></pre> <pre><code>const numbers = [1, 2, 3];\nconst [a, b, c] = numbers;\nconsole.log(a, b, c); // 1 2 3\n</code></pre>"},{"location":"Languages/Javascript/asynchronous/","title":"Asynchronous","text":""},{"location":"Languages/Javascript/asynchronous/#callbacks","title":"Callbacks","text":"<p>Callbacks are functions passed into other functions as arguments. They come in two timing varieties where they execute synchronously or asynchronously. Synchronous callbacks execute immediately, while asynchronous callbacks execute at a later time.</p> <pre><code>function callback() {\n  console.log(\"Hello, World!\");\n}\n\nfunction higherOrderFunction(callback: () =&gt; void) {\n  callback();\n}\n\nhigherOrderFunction(callback);\n</code></pre> <p>Event handlers are commonly used to handle interactions with the user interface in browser, and are a type of callback.</p>"},{"location":"Languages/Javascript/asynchronous/#callback-hell","title":"Callback Hell","text":"<p>When we write synchronous code we can easiliy string functions together in a way that is easy to follow, but if we have a series of asynchronous functions that depend on the result of the previous function, we can end up with a pyramid of doom.</p> <pre><code>function callback1(callback2: () =&gt; void) {\n  setTimeout(() =&gt; {\n    console.log(\"First callback\");\n    callback2();\n  }, 1000);\n}\n\nfunction callback2(callback3: () =&gt; void) {\n  setTimeout(() =&gt; {\n    console.log(\"Second callback\");\n    callback3();\n  }, 1000);\n}\n\nfunction callback3() {\n  setTimeout(() =&gt; {\n    console.log(\"Third callback\");\n  }, 1000);\n}\n\ncallback1(() =&gt; {\n  callback2(() =&gt; {\n    callback3();\n  });\n});\n</code></pre> <p>The code can be much harder to follow, and error handling becomes more difficult as we must handle errors at each level of the pyramid.</p> <pre><code>function callback1(callback2: () =&gt; void) {\n  setTimeout(() =&gt; {\n    console.log(\"First callback\");\n    callback2();\n  }, 1000);\n}\n\nfunction callback2(callback3: () =&gt; void) {\n  setTimeout(() =&gt; {\n    console.log(\"Second callback\");\n    callback3();\n  }, 1000);\n}\n\nfunction callback3() {\n  setTimeout(() =&gt; {\n    console.log(\"Third callback\");\n    throw new Error(\"Error in callback3\");\n  }, 1000);\n}\n\ncallback1(() =&gt; {\n  callback2(() =&gt; {\n    try {\n      callback3();\n    } catch (error) {\n      console.error(error);\n    }\n  });\n});\n</code></pre>"},{"location":"Languages/Javascript/asynchronous/#promises","title":"Promises","text":"<p>Promises were introduced to have an easier to read and write way of handling asynchronous code. A promise is an object. That object will produce a single value some time in the future. It could be a resolved value, or a reason that it\u2019s not resolved (rejected).</p> <pre><code>function promise1() {\n  return new Promise((resolve, reject) =&gt; {\n    setTimeout(() =&gt; {\n      console.log(\"First promise\");\n      resolve();\n    }, 1000);\n  });\n}\n\nfunction promise2() {\n  return new Promise((resolve, reject) =&gt; {\n    setTimeout(() =&gt; {\n      console.log(\"Second promise\");\n      resolve();\n    }, 1000);\n  });\n}\n\nfunction promise3() {\n  return new Promise((resolve, reject) =&gt; {\n    setTimeout(() =&gt; {\n      console.log(\"Third promise\");\n      resolve();\n    }, 1000);\n  });\n}\n\npromise1()\n  .then(() =&gt; promise2())\n  .then(() =&gt; promise3())\n  .catch((error) =&gt; console.error(error));\n</code></pre> <p>There are a few key terms about promises that are important to understand:</p> <p>Verbs:</p> <ul> <li>fulfill: to settle a promise with a fulfillment value</li> <li>reject: to settle a promise with a rejection reason</li> <li>settle: to either fulfill or reject a promise</li> <li>resolve: either</li> <li>to fulfill a promise with a fulfillment value (resolve with)</li> <li>make a promise follow another promise, adopting its eventual state and value (resolve to)</li> </ul> <p>State:</p> <ul> <li>pending: initial state, neither fulfilled nor rejected.</li> <li>fulfilled: meaning that the operation completed successfully. The promise has been fulfilled and now has a value.</li> <li>rejected: meaning that the operation failed.</li> </ul> <p>Other:</p> <ul> <li>settled: The promise is either fulfilled or rejected, but not pending.</li> <li>resolved: either settled or following another promise that will determine its state.</li> <li>unresolved: not settled, meaning it is pending.</li> </ul>"},{"location":"Languages/Javascript/asynchronous/#asyncawait","title":"Async/Await","text":"<p>The async keyword can be applied to a function to make it return a promise. You can also use the async keyword in a function expression so that it executes an Immediatelly Invoked Function Expression (IIFE).</p> <p>The await keyword is used within async functions to pause the execution of the function until the promise is resolved.</p> <pre><code>function promise1() {\n  return new Promise((resolve, reject) =&gt; {\n    setTimeout(() =&gt; {\n      console.log(\"First promise\");\n      resolve();\n    }, 1000);\n  });\n}\n\nfunction promise2() {\n  return new Promise((resolve, reject) =&gt; {\n    setTimeout(() =&gt; {\n      console.log(\"Second promise\");\n      resolve();\n    }, 1000);\n  });\n}\n\nfunction promise3() {\n  return new Promise((resolve, reject) =&gt; {\n    setTimeout(() =&gt; {\n      console.log(\"Third promise\");\n      resolve();\n    }, 1000);\n  });\n}\n\nasync function main() {\n  try {\n    await promise1();\n    await promise2();\n    await promise3();\n  } catch (error) {\n    console.error(error);\n  }\n}\n\nmain();\n</code></pre>"},{"location":"Languages/Python/venv/","title":"Virtual Environments","text":"<ul> <li> <p><code>python3 -m venv name_of_venv</code> Creates the virtual environment. </p> </li> <li> <p><code>source my_project/venv/bin/activate</code> - Set up the virtual environment if it already exists</p> </li> <li> <p><code>pip freeze &gt; requirements.txt</code> Output a version list that can be used to set up an environment</p> </li> <li> <p><code>pip install -r requirements.txt file</code> Set up a new environment based on the requirements file.</p> </li> <li> <p><code>deactivate</code> Turns off the venv.</p> </li> <li> <p><code>python3 -m venv venv  --system-site-packages</code> Includes system packages in main environment in your new virtual environment.</p> </li> <li> <p><code>pip list --local</code> - Shows just the packages that were installed. Not what was brought over</p> </li> </ul> <p>Don't put your project files into the venv. </p> <p>Don't commit your venv files.</p>"},{"location":"Languages/Typescript/","title":"Index","text":""},{"location":"Languages/Typescript/#why-care-at-all","title":"Why care at all?","text":"<p>Typescript is a superset of Javascript that is ultimately compiled back to Javascript. Typescript isn't consumed natively. The big benefit that we get from using Typescript is the benefit of type-checking. All sorts of problems can occur when we aren't absolutely certain of the types we are using, and by using Typescript to enforce types, we can catch these problems before they become a problem.</p>"},{"location":"Languages/Typescript/#types","title":"Types","text":"<p>Primitive types.</p> <ul> <li>number</li> <li>string</li> <li>boolean</li> <li>void</li> <li>undefined</li> <li>null</li> </ul> <p>Object types.</p> <ul> <li>Array</li> <li>Function</li> <li>Classes</li> <li>Objects</li> </ul>"},{"location":"Languages/Typescript/#type-annotations","title":"Type Annotations","text":""},{"location":"Languages/Typescript/#type-inference","title":"Type Inference","text":"<p>The Typescript compiler is able to determine a type when the code clearly gives it away. This is possible when a variable declaration and initialization are on the same line. For example:</p> <p><code>const message = 'hello';</code> - Typescript can infer that <code>message</code> is a string. <code>const message = 10;</code> - Typescript can infer that <code>message</code> is a number.</p> <p>We should always use type inference when we can, but there will be times that the type can't be inferred.</p> <ul> <li>declaring a variable and initializing it later.</li> <li>when the variable will be of a type that can't be inferred.</li> <li>when the return value is of 'any' type and we need to specify a type.</li> </ul>"},{"location":"Languages/Typescript/#any-type","title":"Any Type","text":""},{"location":"Languages/Typescript/#functions","title":"Functions","text":"<ul> <li>arguments</li> <li>return types</li> <li>anonymous functions</li> </ul>"},{"location":"Languages/Typescript/#never-type","title":"Never Type","text":""},{"location":"Languages/Typescript/#unsorted","title":"Unsorted","text":""},{"location":"Languages/Typescript/#bang-symbol","title":"Bang Symbol","text":"<p>The bang symbol at the end of a variable indicates that the variable will not be null or undefined. This is a way to tell Typescript that we are sure that the variable will have a value. This is from the developers point of view, and if the variable is null or undefined, then the program will throw an error. You would still need to handle it if you need gracefully handle the error.</p> <pre><code>let message: string | null = null;\nlet messageLength = message!.length;\n</code></pre>"},{"location":"Languages/Typescript/#nullish-coalescing-operator","title":"Nullish Coalescing Operator","text":"<p>The nullish coalescing operator is a way to check if a variable is null or undefined. If it is, then we can use a default value. This is useful when we want to set a default value for a variable.</p> <pre><code>let message: string | null = null;\nlet messageLength = message ?? \"default\";\n</code></pre>"},{"location":"Languages/Typescript/#return-type","title":"Return Type","text":"<p>We can specify the return type of a function by using a colon after the arguments and specifying the type. If the function doesn't return anything, then we can use the <code>void</code> type.</p> <pre><code>function add(a: number, b: number): number {\n  return a + b;\n}\n</code></pre>"},{"location":"Tools/AI/","title":"prompt engineering","text":"<p>zero shot</p> <p>Few shot</p> <p>chain of thought with few shot</p>"},{"location":"Tools/AI/#rag","title":"rag","text":""},{"location":"Tools/AI/#fine-tuning","title":"fine tuning","text":""},{"location":"Tools/Git/","title":"Index","text":""},{"location":"Tools/Git/#amend","title":"Amend","text":"<p>Amend the last commit with new changes. This helped me when I had some basic whitespace changes that didn't warrant a new commit. Giving the --no-edit option means we won't edit the commit message.</p> <pre><code>git commit --amend --no-edit\n</code></pre>"},{"location":"Tools/Git/#fixup","title":"Fixup","text":"<p>Combine the last commit with the previous commit.</p> <pre><code>git commit --fixup &lt;commit&gt;\n</code></pre>"},{"location":"Tools/Git/#reword","title":"Reword","text":"<p>Change the commit message of the last commit. Use <code>git rebase --continue</code> when done.</p> <pre><code>git rebase -i HEAD~2 # operate on the last two commits\n</code></pre> <pre><code>pick 1a2b3c4 Last commit\nreword 5d6e7f8 Previous commit # change the commit message\nreword 9g0h1i2 Commit 1 # change the commit message\n\n# Commands:\n# p, pick = use commit\n# r, reword = use commit, but edit the commit message\n</code></pre>"},{"location":"Tools/Git/#squash-fixup","title":"Squash &amp; Fixup","text":"<p>Squash and fixup allow us to combine multiple commits into one. We can mark commits as <code>fixup</code> or <code>squash</code> in an interactive rebase, and squash will prompt for a new commit message whereas fixup will use the previous commit message. One of the conventions at a job I had was to only have a single commit per pull request, so I would use this to combine all my commits into one before merging.</p> <p>When I first used this with I had to use a <code>git push --force</code> on Bitbucket to update the remote repository.</p> <pre><code>git rebase -i HEAD~2 # operate on the last two commits\n</code></pre>"},{"location":"Tools/Git/#with-fixup","title":"With Fixup","text":"<pre><code>pick 1a2b3c4 Last commit\nfixup 5d6e7f8 Previous commit # gets squashed into 'Last commit'\nfixup 9g0h1i2 Commit 1 # gets squashed into 'Last commit'\n\n# Commands:\n# p, pick = use commit\n# f, fixup = like \"squash\", but discard this commit's log message\n</code></pre>"},{"location":"Tools/Git/#with-squash","title":"With Squash","text":"<pre><code>pick 1a2b3c4 Last commit\nsquash 5d6e7f8 Previous commit # gets squashed into 'Last commit'\nsquash 9g0h1i2 Commit 1 # gets squashed into 'Last commit'\n\n# Commands:\n# p, pick = use commit\n# s, squash = use commit, but meld into previous commit\n</code></pre>"},{"location":"Tools/Git/#resetting-to-fix-my-booboos","title":"Resetting to fix my booboos","text":"<p>Sometimes I need to reverse through my commit history to fix a mistake I've made.</p>"},{"location":"Tools/Git/#soft","title":"Soft","text":"<p>Undoes all of the changes between HEAD and the commit, but leaves the changes staged.</p> <pre><code>git reset --soft HEAD~1\n</code></pre>"},{"location":"Tools/Git/#mixed","title":"Mixed","text":"<p>Undoes all of the changes between HEAD and the commit, but leaves the changes unstaged.</p> <pre><code>git reset --mixed HEAD~1\n</code></pre>"},{"location":"Tools/Git/#hard","title":"Hard","text":"<p>Undoes all of the changes between HEAD and the commit, and discards the changes.</p> <pre><code>git reset --hard HEAD~1\n</code></pre>"},{"location":"Tools/Git/#finding-commits","title":"Finding Commits","text":"<p>We can find all of the commits for a given file by using the <code>--follow</code> option.</p> <pre><code>git log --follow --oneline -- filename\n</code></pre> <p>Find changes to a file at a line over commits.</p> <pre><code>git log -L 1,1:filename\n</code></pre>"},{"location":"Tools/Git/#finding-something-in-commits-by-string-search","title":"Finding something in commits by string search","text":"<pre><code>git log -S\"&lt;&lt;string to search for&gt;&gt;\" --since=\"2 years ago\" --until=\"now\" -- /path/to/the/file\n</code></pre> <p>--since and --until can be specified as a date, or a relative date like \"2 years ago\".</p>"},{"location":"Tools/Git/#merging","title":"Merging","text":"<p>Often run into divergent branch issues and need to resolve with rebasing or fast forwarding. What do each of these options mean?</p>"},{"location":"Tools/Git/#fast-forward","title":"Fast Forward","text":""},{"location":"Tools/Git/#rebase","title":"Rebase","text":"<p>Change the base of the development branch to the branch we are merging into.</p>"},{"location":"Tools/Git/#merge","title":"Merge","text":"<p>Pulls in the latest changes from the branch you are merging into and creates a merge commit.</p>"},{"location":"Tools/Networking/","title":"Networking Commands","text":""},{"location":"Tools/Networking/#network-interfaces-and-configuration","title":"Network Interfaces and Configuration","text":"<ul> <li>Linux Commands: </li> <li><code>ifconfig</code> <ul> <li>Purpose: Display or configure network interfaces.</li> </ul> </li> <li><code>ip addr show</code> or <code>ip a</code><ul> <li>Purpose: Display IP addresses and property information for all interfaces.</li> </ul> </li> <li>Windows Command: </li> <li><code>ipconfig</code><ul> <li>Purpose: Display all current TCP/IP network configuration values.</li> </ul> </li> </ul>"},{"location":"Tools/Networking/#routing-and-network-traffic-management","title":"Routing and Network Traffic Management","text":"<ul> <li>IPv4 Forwarding:</li> <li><code>sysctl -w net.ipv4.ip_forward=1</code><ul> <li>Purpose: Enable IPv4 forwarding temporarily.</li> </ul> </li> <li>Editing <code>/etc/sysctl.conf</code> to include <code>net.ipv4.ip_forward=1</code><ul> <li>Purpose: Make IPv4 forwarding setting persistent across reboots.</li> </ul> </li> <li><code>sysctl -p</code><ul> <li>Purpose: Reload sysctl settings from <code>/etc/sysctl.conf</code>.</li> </ul> </li> </ul>"},{"location":"Tools/Networking/#firewall-configuration-using-iptables","title":"Firewall Configuration using iptables","text":"<ul> <li>Viewing Rules: </li> <li><code>iptables -L</code><ul> <li>Purpose: List all active rules in the default filter table.</li> </ul> </li> <li><code>iptables -L -t &lt;table&gt;</code><ul> <li>Purpose: List rules in a specific table.</li> </ul> </li> <li>Adding Rules: </li> <li><code>iptables -A &lt;Chain&gt; -s &lt;IP&gt; -j &lt;Target&gt;</code><ul> <li>Purpose: Append a rule to a chain for packets from a specific IP.</li> </ul> </li> <li>Deleting Rules: </li> <li><code>iptables -D &lt;ChainRule&gt;</code><ul> <li>Purpose: Delete a specific rule from a chain.</li> </ul> </li> <li>Setting Default Policy: </li> <li><code>iptables --policy INPUT DROP</code><ul> <li>Purpose: Set the default policy for the INPUT chain to DROP.</li> </ul> </li> <li>Deleting All Rules: </li> <li><code>iptables -F</code><ul> <li>Purpose: Flush all rules, deleting them.</li> </ul> </li> <li>Specifying Protocols and Ports: </li> <li><code>-p</code>: Specify protocol (TCP/UDP).</li> <li><code>--dport</code>: Specify destination port.</li> <li><code>--sport</code>: Specify source port.</li> <li><code>-s</code>: Specify source IP address.</li> <li><code>-d</code>: Specify destination IP address.</li> <li>Logging: </li> <li>Purpose: Log packets that match a rule; viewed with <code>journalctl</code>.</li> </ul>"},{"location":"Tools/Networking/#packet-sniffing-and-analysis","title":"Packet Sniffing and Analysis","text":"<ul> <li>tcpdump Usage: </li> <li><code>tcpdump -i &lt;interface&gt;</code><ul> <li>Purpose: Capture packets on a specific network interface.</li> </ul> </li> <li><code>tcpdump -l -i &lt;interface&gt;</code><ul> <li>Purpose: Listens to the first 10 packets on that interface.</li> </ul> </li> <li><code>tcpdump -l -i &lt;interface&gt; | grep ICMP</code><ul> <li>Purpose: Show only the ping packets generated by ICMP.</li> </ul> </li> <li><code>tcpdump -n -l -i &lt;interface&gt; &lt;protocol&gt;</code><ul> <li>-Purpose </li> </ul> </li> <li>Filtering options provide more specific capture criteria, like protocol, source, and destination.</li> </ul>"},{"location":"Tools/Networking/#service-and-protocol-specific-configuration","title":"Service and Protocol Specific Configuration","text":"<ul> <li>SSH, TFTP, FTP Configuration: </li> <li>Purpose: Instructions for configuring firewall rules to allow traffic for these services.</li> <li>TCP and UDP: </li> <li>Purpose: Discussion on handling traffic for these protocols in firewall rules.</li> </ul>"},{"location":"Tools/SSH/","title":"SSH","text":""},{"location":"Tools/SSH/#troubleshooting","title":"Troubleshooting","text":""},{"location":"Tools/SSH/#unable-to-acquire-lock","title":"Unable to acquire lock","text":"<p>For some reason, a lock was open on some of the .vscode-server files and it was  preventing me from reconnecting my SSH session. Trying to rm -rf the files  didn't work, and trying to run the Kill command from the VSCode command palette also had the same problem. </p> <p>Unfortunately, one of my longstanding processes was running and is tied up with the locked file. Seems like I will have to kill it, or if I can access that process from another SSH session maybe I can fix it there. </p> <p>Used commands:</p> <ul> <li><code>lsof | grep 681</code> used to find which processes had a lock on a file with 681 in the name.</li> <li><code>killall -9 node</code> killed node when it was tying things up. </li> <li><code>kill -9 324234</code> killed a given PID. Usually tried with -10 first.<ul> <li>used the <code>kill</code> command with a -10 to get it to come back to life with my  missing session.</li> </ul> </li> <li><code>rm -rf some-dir-name</code> trying to remove a bunch of files/folders. It revealed  what was locked.</li> <li><code>tree</code> to inspect the structure of the directories. </li> <li><code>history | grep term</code> - this was handy to search through my history of commands</li> <li><code>CTRL+R</code> lets me search for a command</li> </ul>"},{"location":"other/index_old/","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"other/index_old/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"other/index_old/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"other/markdown_latex/","title":"Markdown","text":"<p>This resource is from [https://ashki23.github.io/markdown-latex.html]</p> <p>The following provides a quick reference to the most commonly used Markdown syntax.    </p>"},{"location":"other/markdown_latex/#headers","title":"Headers","text":""},{"location":"other/markdown_latex/#h3","title":"H3","text":""},{"location":"other/markdown_latex/#h4","title":"H4","text":""},{"location":"other/markdown_latex/#h5","title":"H5","text":""},{"location":"other/markdown_latex/#h6","title":"H6","text":"<p>::: {#cb1 .sourceCode} <pre><code># Markdown\nThe following provides a quick reference to the most commonly used Markdown syntax.\n\n## Headers\n### H3\n#### H4\n##### H5\n###### H6\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#emphasis","title":"Emphasis","text":"<p>Italic and Bold</p> <p>::: {#cb2 .sourceCode} <pre><code>*Italic* and **Bold**\n</code></pre> :::</p> <p>~~Scratched Text~~</p> <p>::: {#cb3 .sourceCode} <pre><code>~~Scratched Text~~\n</code></pre> :::</p> <p>superscript^2^</p> <p>::: {#cb4 .sourceCode} <pre><code>superscript^2^\n</code></pre> :::</p> <p>Markdown doesn't support underline, but we can use [HTML Text]{.underline} instead. Also, we can render almost any [HTML]{style=\"color:red;\"} code that we [like]{.kbd} such as superscript^2^.</p> <p>::: {#cb5 .sourceCode} <pre><code>Markdown doesn't support underline, but we can use &lt;u&gt;HTML Text&lt;/u&gt; instead. Also, &lt;b&gt;we&lt;/b&gt; can &lt;i&gt;render&lt;/i&gt; almost any &lt;span style=\"color:red;\"&gt;HTML&lt;/span&gt; code that we &amp;nbsp; &lt;kbd&gt;like&lt;/kbd&gt; &amp;nbsp; such as superscript&lt;sup&gt;2&lt;/sup&gt;.\n</code></pre> :::</p> <p>For manual line or page breaks, we can use following HTML and CSS codes:</p> <ul> <li>Line breaks:</li> </ul> <p>::: {#cb6 .sourceCode} <pre><code>&lt;br /&gt;\n</code></pre> :::</p> <ul> <li>Print breaks:</li> </ul> <p>::: {#cb7 .sourceCode} <pre><code>&lt;p style=\"page-break-after:always;\"&gt;&lt;/p&gt;\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#lists","title":"Lists","text":"<ul> <li>Item 1</li> <li>Item 2<ul> <li>Item 2a</li> <li>Item 2b<ul> <li>Item 2b-1</li> <li>Item 2b-2</li> </ul> </li> </ul> </li> </ul> <p>::: {#cb8 .sourceCode} <pre><code>- Item 1\n- Item 2\n    - Item 2a (2 tabs)\n    - Item 2b\n        - Item 2b-1 (4 tabs)\n        - Item 2b-2\n</code></pre> :::</p> <ol> <li>Item 1</li> <li>Item 2</li> <li>Item 3<ul> <li>Item 3a</li> <li>Item 3b</li> </ul> </li> </ol> <p>::: {#cb9 .sourceCode} <pre><code>1. Item 1\n2. Item 2\n3. Item 3\n    - Item 3a\n    - Item 3b\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#links","title":"Links","text":"<p>Github</p> <p>::: {#cb10 .sourceCode} <pre><code>[Github](http://www.github.com/)\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#images","title":"Images","text":"<p>::: {#cb11 .sourceCode} <pre><code>&lt;p align=\"center\"&gt;\n![logo](https://www.raspberrypi.org/app/uploads/2018/03/RPi-Logo-Reg-SCREEN-199x250.png \"Raspberry pi\")\n&lt;/p&gt;\n</code></pre> :::</p> <p>Note that here we used an HTML code to align center the image. Also, we can use HTML to add more styles, for example:</p> <p>::: {#cb12 .sourceCode} <pre><code>&lt;p align=\"center\"&gt;\n&lt;img src=\"https://www.raspberrypi.org/app/uploads/2018/03/RPi-Logo-Reg-SCREEN-199x250.png\" alt=\"Raspberry pi\" style=\"width:20%; border:0;\"&gt;\n&lt;/p&gt;\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#quotes","title":"Quotes","text":"<p>Imagination is more important than knowledge.</p> <p>Albert Einstein</p> <p>::: {#cb13 .sourceCode} <pre><code>&gt; Imagination is more important than knowledge.\n&gt;\n&gt; Albert Einstein\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#hlines","title":"Hlines","text":"<p>Use three dashes <code>---</code> to draw an horizontal line like:</p> <p>::: {#cb14 .sourceCode} <pre><code>---\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#tables","title":"Tables","text":"<p>::: {style=\"margin-bottom: 1rem; overflow-x: auto;\"}   1st Header      2nd Header      3rd Header</p> <p>col 1 is       left-aligned              1   col 2 is      center-aligned             2   col 3 is      right-aligned              3 :::</p> <p>::: {#cb15 .sourceCode} <pre><code>1st Header|2nd Header|3rd Header\n---|:---:|---: \ncol 1 is|left-aligned|1\ncol 2 is|center-aligned|2\ncol 3 is|right-aligned|3\n</code></pre> :::</p> <p>Note that we can use HTML styles to hide tables' overflow by putting them in a division like:</p> <p>::: {#cb16 .sourceCode} <pre><code>&lt;div \"margin-bottom: 1rem; overflow-x: auto;\"&gt;\n...\n&lt;/div&gt;\n</code></pre> :::</p> <p>Also, we can use <code>overflow-x: scroll</code> to always scroll or <code>overflow-x: hidden</code> to hide them compeletely.</p>"},{"location":"other/markdown_latex/#code-blocks","title":"Code blocks","text":"<p>In Markdown, we can simply add plain code blocks to display (not evaluating) by inserting triple back quote i.e. <code>```</code>. For example:</p> <p>::: {#cb17 .sourceCode} <pre><code>norm = function(x) {\n  sqrt(x%*%x)\n}\nnorm(1:4)\n</code></pre> :::</p> <p>::: {#cb18 .sourceCode} <pre><code>` ``r\nnorm &lt;- function(x) {\n  sqrt(x%*%x)\n}\nnorm(1:4)\n` ``\n</code></pre> :::</p> <p>For inline plain codes use single back quote before and after the code, for example we defined <code>this codes here</code> in this way.</p>"},{"location":"other/markdown_latex/#yaml-header","title":"YAML header","text":"<p>At the top of a Markdown document, we can insert the following meta data such that:</p> <p>::: {#cb19 .sourceCode} <pre><code>---\ntitle: \"Page Title\"\nsubtitle: \"Page sub-title\"\nauthor: \"Author name\"\ndescription: \"This is a test\"\ninstitute: \"MU\"\ndate: \"20/02/2020\"\nabstract: \"YAML\"\nkeywords: \n  - key1\n  - key2\ntags:\n  - tag1\n  - tag2\n---\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#mathematical-formula","title":"Mathematical formula","text":"<p>We can use LaTeX to write mathematical equations in Markdown. To write inline LaTeX formula use a single <code>$</code> before and after the equation and use a double <code>$</code> to display equations.</p>"},{"location":"other/markdown_latex/#latex","title":"LaTeX","text":"<p>The following provides a quick reference of the most commonly used LaTeX syntax. You may find a more extensive references about mathematical formulas at LaTeX Wikibooks.</p>"},{"location":"other/markdown_latex/#latex-equations","title":"LaTeX equations","text":"<p>Inline equation: [\\(equation\\)]{.math .inline}</p> <p>::: {#cb20 .sourceCode} <pre><code>Inline equation: $equation$\n</code></pre> :::</p> <p>Display equation: [\\[equation\\]]{.math .display}</p> <p>::: {#cb21 .sourceCode} <pre><code>Display equation: $$equation$$\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#operators","title":"Operators","text":"<ul> <li>[\\(x + y\\)]{.math .inline}</li> <li>[\\(x - y\\)]{.math .inline}</li> <li>[\\(x \\times y\\)]{.math .inline}</li> <li>[\\(x \\div y\\)]{.math .inline}</li> <li>[\\(\\dfrac{x}{y}\\)]{.math .inline}</li> <li>[\\(\\sqrt{x}\\)]{.math .inline}</li> </ul> <p>::: {#cb22 .sourceCode} <pre><code>- $x + y$\n- $x - y$\n- $x \\times y$ \n- $x \\div y$\n- $\\dfrac{x}{y}$\n- $\\sqrt{x}$\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#symbols","title":"Symbols","text":"<ul> <li>[\\(\\pi \\approx 3.14159\\)]{.math .inline}</li> <li>[\\(\\pm \\, 0.2\\)]{.math .inline}</li> <li>[\\(\\dfrac{0}{1} \\neq \\infty\\)]{.math .inline}</li> <li>[\\(0 \\&lt; x \\&lt; 1\\)]{.math .inline}</li> <li>[\\(0 \\leq x \\leq 1\\)]{.math .inline}</li> <li>[\\(x \\geq 10\\)]{.math .inline}</li> <li>[\\(\\forall \\, x \\in (1,2)\\)]{.math .inline}</li> <li>[\\(\\exists \\, x \\notin [0,1]\\)]{.math .inline}</li> <li>[\\(A \\subset B\\)]{.math .inline}</li> <li>[\\(A \\subseteq B\\)]{.math .inline}</li> <li>[\\(A \\cup B\\)]{.math .inline}</li> <li>[\\(A \\cap B\\)]{.math .inline}</li> <li>[\\(X \\implies Y\\)]{.math .inline}</li> <li>[\\(X \\impliedby Y\\)]{.math .inline}</li> <li>[\\(a \\to b\\)]{.math .inline}</li> <li>[\\(a \\longrightarrow b\\)]{.math .inline}</li> <li>[\\(a \\Rightarrow b\\)]{.math .inline}</li> <li>[\\(a \\Longrightarrow b\\)]{.math .inline}</li> <li>[\\(a \\propto b\\)]{.math .inline}</li> </ul> <p>::: {#cb23 .sourceCode} <pre><code>- $\\pi \\approx 3.14159$\n- $\\pm \\, 0.2$\n- $\\dfrac{0}{1} \\neq \\infty$\n- $0 &lt; x &lt; 1$\n- $0 \\leq x \\leq 1$\n- $x \\geq 10$\n- $\\forall \\, x \\in (1,2)$\n- $\\exists \\, x \\notin [0,1]$\n- $A \\subset B$\n- $A \\subseteq B$\n- $A \\cup B$\n- $A \\cap B$\n- $X \\implies Y$\n- $X \\impliedby Y$\n- $a \\to b$\n- $a \\longrightarrow b$\n- $a \\Rightarrow b$\n- $a \\Longrightarrow b$\n- $a \\propto b$\n</code></pre> :::</p> <ul> <li>[\\(\\bar a\\)]{.math .inline}</li> <li>[\\(\\tilde a\\)]{.math .inline}</li> <li>[\\(\\breve a\\)]{.math .inline}</li> <li>[\\(\\hat a\\)]{.math .inline}</li> <li>[\\(a\\^ \\prime\\)]{.math .inline}</li> <li>[\\(a\\^ \\dagger\\)]{.math .inline}</li> <li>[\\(a\\^ \\ast\\)]{.math .inline}</li> <li>[\\(a\\^ \\star\\)]{.math .inline}</li> <li>[\\(\\mathcal A\\)]{.math .inline}</li> <li>[\\(\\mathrm a\\)]{.math .inline}</li> <li>[\\(\\cdots\\)]{.math .inline}</li> <li>[\\(\\vdots\\)]{.math .inline}</li> <li>[\\(\\#\\)]{.math .inline}</li> <li>[\\(\\$\\)]{.math .inline}</li> <li>[\\(\\%\\)]{.math .inline}</li> <li>[\\(\\&amp;\\)]{.math .inline}</li> <li>[\\(\\{ \\}\\)]{.math .inline}</li> <li>[\\(\\_\\)]{.math .inline}</li> </ul> <p>::: {#cb24 .sourceCode} <pre><code>- $\\bar a$\n- $\\tilde a$\n- $\\breve a$\n- $\\hat a$\n- $a^ \\prime$\n- $a^ \\dagger$\n- $a^ \\ast$\n- $a^ \\star$\n- $\\mathcal A$\n- $\\mathrm a$\n- $\\cdots$\n- $\\vdots$\n- $\\#$\n- $\\$$\n- $\\%$\n- $\\&amp;$\n- $\\{ \\}$\n- $\\_$\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#space","title":"Space","text":"<ul> <li>Horizontal space: <code>\\quad</code></li> <li>Large horizontal space: <code>\\qquad</code></li> <li>Small space: <code>\\,</code></li> <li>Medium space: <code>\\:</code></li> <li>Large space: <code>\\;</code></li> <li>Negative space: <code>\\!</code></li> </ul>"},{"location":"other/markdown_latex/#greek-alphabets","title":"Greek alphabets","text":"<p>::: {style=\"margin-bottom: 1rem; overflow-x: auto;\"}   Small Letter                                  Capital Letter                                Alternative</p> <p>[\\(\\alpha\\)]{.math .inline} <code>\\alpha</code>       [\\(A\\)]{.math .inline} <code>A</code>    [\\(\\beta\\)]{.math .inline} <code>\\beta</code>         [\\(B\\)]{.math .inline} <code>B</code>    [\\(\\gamma\\)]{.math .inline} <code>\\gamma</code>       [\\(\\Gamma\\)]{.math .inline} <code>\\Gamma</code>    [\\(\\delta\\)]{.math .inline} <code>\\delta</code>       [\\(\\Delta\\)]{.math .inline} <code>\\Delta</code>    [\\(\\epsilon\\)]{.math .inline} <code>\\epsilon</code>   [\\(E\\)]{.math .inline} <code>E</code>                  [\\(\\varepsilon\\)]{.math .inline} <code>\\varepsilon</code>   [\\(\\zeta\\)]{.math .inline} <code>\\zeta</code>         [\\(Z\\)]{.math .inline} <code>Z</code>    [\\(\\eta\\)]{.math .inline} <code>\\eta</code>           [\\(H\\)]{.math .inline} <code>H</code>    [\\(\\theta\\)]{.math .inline} <code>\\theta</code>       [\\(\\Theta\\)]{.math .inline} <code>\\Theta</code>       [\\(\\vartheta\\)]{.math .inline} <code>\\vartheta</code>   [\\(\\iota\\)]{.math .inline} <code>\\zeta</code>         [\\(I\\)]{.math .inline} <code>I</code>    [\\(\\kappa\\)]{.math .inline} <code>\\kappa</code>       [\\(K\\)]{.math .inline} <code>K</code>                  [\\(\\varkappa\\)]{.math .inline} <code>\\varkappa</code>   [\\(\\lambda\\)]{.math .inline} <code>\\lambda</code>     [\\(\\Lambda\\)]{.math .inline} <code>\\Lambda</code>    [\\(\\mu\\)]{.math .inline} <code>\\mu</code>             [\\(M\\)]{.math .inline} <code>M</code>    [\\(\\nu\\)]{.math .inline} <code>\\nu</code>             [\\(N\\)]{.math .inline} <code>N</code>    [\\(\\xi\\)]{.math .inline} <code>\\xi</code>             [\\(\\Xi\\)]{.math .inline} <code>\\Xi</code>    [\\(\\omicron\\)]{.math .inline} <code>\\omicron</code>   [\\(O\\)]{.math .inline} <code>O</code>    [\\(\\pi\\)]{.math .inline} <code>\\pi</code>             [\\(\\Pi\\)]{.math .inline} <code>\\Pi</code>             [\\(\\varpi\\)]{.math .inline} <code>\\varpi</code>   [\\(\\rho\\)]{.math .inline} <code>\\rho</code>           [\\(P\\)]{.math .inline} <code>P</code>                  [\\(\\varrho\\)]{.math .inline} <code>\\varrho</code>   [\\(\\sigma\\)]{.math .inline} <code>\\sigma</code>       [\\(\\Sigma\\)]{.math .inline} <code>\\Sigma</code>       [\\(\\varsigma\\)]{.math .inline} <code>\\varsigma</code>   [\\(\\tau\\)]{.math .inline} <code>\\tau</code>           [\\(T\\)]{.math .inline} <code>T</code>    [\\(\\upsilon\\)]{.math .inline} <code>\\upsilon</code>   [\\(\\Upsilon\\)]{.math .inline} <code>\\Upsilon</code>    [\\(\\phi\\)]{.math .inline} <code>\\phi</code>           [\\(\\Phi\\)]{.math .inline} <code>\\Phi</code>           [\\(\\varphi\\)]{.math .inline} <code>\\varphi</code>   [\\(\\chi\\)]{.math .inline} <code>\\chi</code>           [\\(X\\)]{.math .inline} <code>X</code>    [\\(\\psi\\)]{.math .inline} <code>\\psi</code>           [\\(\\Psi\\)]{.math .inline} <code>\\Psi</code>    [\\(\\omega\\)]{.math .inline} <code>\\omega</code>       [\\(\\Omega\\)]{.math .inline} <code>\\Omega</code>  :::</p>"},{"location":"other/markdown_latex/#equations","title":"Equations","text":"<p>[\\[\\mathbb{N} = \\{ a \\in \\mathbb{Z} : a &gt; 0 \\}\\]]{.math .display}</p> <p>::: {#cb25 .sourceCode} <pre><code>$$\\mathbb{N} = \\{ a \\in \\mathbb{Z} : a &gt; 0 \\}$$\n</code></pre> :::</p> <p>[\\[\\forall \\; x \\in X \\quad \\exists \\; y \\leq \\epsilon\\]]{.math .display}</p> <p>::: {#cb26 .sourceCode} <pre><code>$$\\forall \\; x \\in X \\quad \\exists \\; y \\leq \\epsilon$$\n</code></pre> :::</p> <p>[\\[\\color{blue}{X \\sim Normal \\; (\\mu,\\sigma\\^2)}\\]]{.math .display}</p> <p>::: {#cb27 .sourceCode} <pre><code>$$\\color{blue}{X \\sim Normal \\; (\\mu,\\sigma^2)}$$\n</code></pre> :::</p> <p>[\\[P \\left( A=2 \\, \\middle| \\, \\dfrac{A\\^2}{B}&gt;4 \\right)\\]]{.math .display}</p> <p>::: {#cb28 .sourceCode} <pre><code>$$P \\left( A=2 \\, \\middle| \\, \\dfrac{A^2}{B}&gt;4 \\right)$$\n</code></pre> :::</p> <p>[\\[f(x) = x\\^2 - x\\^\\frac{1}{\\pi}\\]]{.math .display}</p> <p>::: {#cb29 .sourceCode} <pre><code>$$f(x) = x^2 - x^\\frac{1}{\\pi}$$\n</code></pre> :::</p> <p>[\\[f(X,n) = X_n + X_{n-1}\\]]{.math .display}</p> <p>::: {#cb30 .sourceCode} <pre><code>$$f(X,n) = X_n + X_{n-1}$$\n</code></pre> :::</p> <p>[\\[f(x) = \\sqrt[3]{2x} + \\sqrt{x-2}\\]]{.math .display}</p> <p>::: {#cb31 .sourceCode} <pre><code>$$f(x) = \\sqrt[3]{2x} + \\sqrt{x-2}$$\n</code></pre> :::</p> <p>[\\[\\mathrm{e} = \\sum_{n=0}\\^{\\infty} \\dfrac{1}{n!}\\]]{.math .display}</p> <p>::: {#cb32 .sourceCode} <pre><code>$$\\mathrm{e} = \\sum_{n=0}^{\\infty} \\dfrac{1}{n!}$$\n</code></pre> :::</p> <p>[\\[\\prod_{i=1}\\^{n} x_i - 1\\]]{.math .display}</p> <p>::: {#cb33 .sourceCode} <pre><code>$$\\prod_{i=1}^{n} x_i - 1$$\n</code></pre> :::</p> <p>[\\[\\lim_{x \\to 0\\^+} \\dfrac{1}{x} = \\infty\\]]{.math .display}</p> <p>::: {#cb34 .sourceCode} <pre><code>$$\\lim_{x \\to 0^+} \\dfrac{1}{x} = \\infty$$\n</code></pre> :::</p> <p>[\\[\\int_a\\^b y \\: \\mathrm{d}x\\]]{.math .display}</p> <p>::: {#cb35 .sourceCode} <pre><code>$$\\int_a^b y \\: \\mathrm{d}x$$\n</code></pre> :::</p> <p>[\\[\\log_a b = 1\\]]{.math .display}</p> <p>::: {#cb36 .sourceCode} <pre><code>$$\\log_a b = 1$$\n</code></pre> :::</p> <p>[\\[\\min(P) = \\max_{i:S_i \\in S} S_i\\]]{.math .display}</p> <p>::: {#cb37 .sourceCode} <pre><code>$$\\max(S) = \\max_{i:S_i \\in S} S_i$$\n</code></pre> :::</p> <p>[\\[\\dfrac{n!}{k!(n-k)!} = \\binom{n}{k}\\]]{.math .display}</p> <p>::: {#cb38 .sourceCode} <pre><code>$$\\dfrac{n!}{k!(n-k)!} = \\binom{n}{k}$$\n</code></pre> :::</p> <p>[\\[\\small \\text{$\\dfrac{b}{a+b}=3, \\:$ therefore we can set $\\: a=6$}\\]]{.math .display}</p> <p>::: {#cb39 .sourceCode} <pre><code>$$\\text{$\\dfrac{b}{a+b}=3, \\:$ therefore we can set $\\: a=6$}$$\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#functions","title":"Functions","text":"<p>[\\[ f(x)= \\begin{cases} 1/d_{ij} &amp; \\quad \\text{when $d_{ij} \\leq 160$}\\\\ 0 &amp; \\quad \\text{otherwise} \\end{cases} \\]]{.math .display}</p> <p>::: {#cb40 .sourceCode} <pre><code>$$\nf(x)=\n\\begin{cases}\n1/d_{ij} &amp; \\quad \\text{when $d_{ij} \\leq 160$}\\\\ \n0 &amp; \\quad \\text{otherwise}\n\\end{cases}\n$$\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#matrices","title":"Matrices","text":"<p>[\\[ \\begin{matrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\\\ 7 &amp; 8 &amp; 9 \\end{matrix} \\]]{.math .display}</p> <p>::: {#cb41 .sourceCode} <pre><code>$$\n\\begin{matrix}\n1 &amp; 2 &amp; 3 \\\\\n4 &amp; 5 &amp; 6 \\\\\n7 &amp; 8 &amp; 9\n\\end{matrix}\n$$\n</code></pre> :::</p> <p>[\\[ M = \\begin{bmatrix} \\frac{5}{6} &amp; \\frac{1}{6} &amp; 0 \\\\[0.3em] \\frac{5}{6} &amp; 0 &amp; \\frac{1}{6} \\\\[0.3em] 0 &amp; \\frac{5}{6} &amp; \\frac{1}{6} \\end{bmatrix} \\]]{.math .display}</p> <p>::: {#cb42 .sourceCode} <pre><code>$$\nM = \n\\begin{bmatrix}\n\\frac{5}{6} &amp; \\frac{1}{6} &amp; 0 \\\\[0.3em]\n\\frac{5}{6} &amp; 0 &amp; \\frac{1}{6} \\\\[0.3em]\n0 &amp; \\frac{5}{6} &amp; \\frac{1}{6}\n\\end{bmatrix}\n$$\n</code></pre> :::</p> <p>[\\[ M = \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} \\]]{.math .display}</p> <p>::: {#cb43 .sourceCode} <pre><code>$$ \nM =\n\\begin{bmatrix}\n1 &amp; 0 \\\\\n0 &amp; 1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 &amp; 0 \\\\\n0 &amp; 1\n\\end{bmatrix}\n$$\n</code></pre> :::</p> <p>[\\[ M = \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix} \\]]{.math .display}</p> <p>::: {#cb44 .sourceCode} <pre><code>$$ \nM =\n\\begin{pmatrix}\n1 &amp; 0 \\\\\n0 &amp; 1\n\\end{pmatrix}\n\\begin{pmatrix}\n1 &amp; 0 \\\\\n0 &amp; 1\n\\end{pmatrix}\n$$\n</code></pre> :::</p> <p>[\\[ A_{m,n} = \\begin{pmatrix} a_{1,1} &amp; a_{1,2} &amp; \\cdots &amp; a_{1,n} \\\\ a_{2,1} &amp; a_{2,2} &amp; \\cdots &amp; a_{2,n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{m,1} &amp; a_{m,2} &amp; \\cdots &amp; a_{m,n} \\end{pmatrix} \\]]{.math .display}</p> <p>::: {#cb45 .sourceCode} <pre><code>$$\nA_{m,n} = \n\\begin{pmatrix}\na_{1,1} &amp; a_{1,2} &amp; \\cdots &amp; a_{1,n} \\\\\na_{2,1} &amp; a_{2,2} &amp; \\cdots &amp; a_{2,n} \\\\\n\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\na_{m,1} &amp; a_{m,2} &amp; \\cdots &amp; a_{m,n} \n\\end{pmatrix}\n$$\n</code></pre> :::</p>"},{"location":"other/markdown_latex/#font-sizes","title":"Font sizes","text":"<p>[\\(\\Huge Hello!\\)]{.math .inline}\\ [\\(\\huge Hello!\\)]{.math .inline}\\ [\\(\\LARGE Hello!\\)]{.math .inline}\\ [\\(\\Large Hello!\\)]{.math .inline}\\ [\\(\\large Hello!\\)]{.math .inline}\\ [\\(\\normalsize Hello!\\)]{.math .inline}\\ [\\(\\small Hello!\\)]{.math .inline}\\ [\\(\\scriptsize Hello!\\)]{.math .inline}\\ [\\(\\tiny Hello!\\)]{.math .inline}\\</p> <p>::: {#cb46 .sourceCode} <pre><code>$\\Huge Hello!$\n$\\huge Hello!$\n$\\LARGE Hello!$\n$\\Large Hello!$\n$\\large Hello!$\n$\\normalsize Hello!$\n$\\small Hello!$\n$\\scriptsize Hello!$\n$\\tiny Hello!$\n</code></pre> :::</p> <p>Example: [\\[\\small \\text{Font size is small, eg. $\\sum{x_i = 10}$}\\]]{.math .display}</p> <p>::: {#cb47 .sourceCode} <pre><code>$$\\small \\text{Font size is small, eg. $\\sum{x_i = 10}$}$$\n</code></pre> ::: :::</p> <p>::: {.d-none .d-xl-block .col-xl-2 .bd-toc} -   -   Markdown         -   Headers         -   Emphasis         -   Lists         -   Links         -   Images         -   Quotes         -   Hlines         -   Tables         -   Code blocks         -   YAML header         -   Mathematical formula     -   LaTeX         -   LaTeX equations         -   Operators         -   Symbols         -   Space         -   Greek alphabets         -   Equations         -   Functions         -   Matrices         -   Font sizes</p> <p>:::</p>"},{"location":"other/studyStrategies/","title":"Study Strategies","text":""},{"location":"other/studyStrategies/#wake-up","title":"Wake up","text":"<p>Do some deep breathing for a minute or two. Wim Hof Method</p>"},{"location":"other/studyStrategies/#settle-focus","title":"Settle focus","text":"<p>Look at some point for a little while, or sit and meditate for a bit.</p>"},{"location":"other/studyStrategies/#references","title":"References","text":"<p>Based Huberman take</p>"}]}